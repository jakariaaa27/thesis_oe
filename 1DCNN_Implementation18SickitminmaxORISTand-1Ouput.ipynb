{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFyb0y7PUJOo"
   },
   "source": [
    "# ResNet Model Building Pipeline for 1D Signals with DEMO\n",
    "#### ResNet18, ResNet34, ResNet50, ResNet101, ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import tornado.iostream\n",
    "\n",
    "# Create a TCP connection to a server running on localhost at port 8000\n",
    "sock = socket.create_connection(('localhost', 8888))\n",
    "\n",
    "# Create an IOStream object with a large buffer size\n",
    "stream = tornado.iostream.IOStream(sock, max_buffer_size=1073741824)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eMhBhz1CrMb3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from numpy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, BatchNormalization, Activation, add\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape, Flatten, Dense\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "# from tensorflow.keras.optimizers import AdamW\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import Normalizer,MinMaxScaler,StandardScaler, RobustScaler, QuantileTransformer, PowerTransformer\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "import pywt\n",
    "np.set_printoptions(suppress=True)\n",
    "# Import ResNet1D Module\n",
    "from ResNet_1DCNN import ResNet\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['Fx']\n",
    "# # columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "# wavelet = 'db4'\n",
    "# max_iter = 50\n",
    "# iter = 0\n",
    "\n",
    "# # Walking Dataset\n",
    "# InsoleWalking1 = pd.read_csv('0310AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking2 = pd.read_csv('0310HudaStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking3 = pd.read_csv('0311LalaStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking4 = pd.read_csv('0311YunitaStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking5 = pd.read_csv('0312AbelStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking6 = pd.read_csv('0312AbiStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking7 = pd.read_csv('0312AryaStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking8 = pd.read_csv('0312HawaStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking9 = pd.read_csv('0312NisaStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking10 = pd.read_csv('0313ChenChengStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking11 = pd.read_csv('0313RezaStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking12 = pd.read_csv('0313RilaniStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking13 = pd.read_csv('0313SariStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking14 = pd.read_csv('0313ShelbyStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking15 = pd.read_csv('0314HelenStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking16 = pd.read_csv('0315AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking17 = pd.read_csv('0315HappyStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking18 = pd.read_csv('0317HeniStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking19 = pd.read_csv('0317NadiaStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking20 = pd.read_csv('0317VikaStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking21 = pd.read_csv('0319AlfianStand5Min1.txt', header=None, low_memory=False)\n",
    "# InsoleWalking22 = pd.read_csv('1225JakariaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# SIDatasWalking1 =  np.array(InsoleWalking1)\n",
    "# SIDatasWalking2 =  np.array(InsoleWalking2)\n",
    "# SIDatasWalking3 =  np.array(InsoleWalking3)\n",
    "# SIDatasWalking4 =  np.array(InsoleWalking4)\n",
    "# SIDatasWalking5 =  np.array(InsoleWalking5)\n",
    "# SIDatasWalking6 =  np.array(InsoleWalking6)\n",
    "# SIDatasWalking7 =  np.array(InsoleWalking7)\n",
    "# SIDatasWalking8 =  np.array(InsoleWalking8)\n",
    "# SIDatasWalking9 =  np.array(InsoleWalking9)\n",
    "# SIDatasWalking10 =  np.array(InsoleWalking10)\n",
    "# SIDatasWalking11 =  np.array(InsoleWalking11)\n",
    "# SIDatasWalking12 =  np.array(InsoleWalking12)\n",
    "# SIDatasWalking13 =  np.array(InsoleWalking13)\n",
    "# SIDatasWalking14 =  np.array(InsoleWalking14)\n",
    "# SIDatasWalking15 =  np.array(InsoleWalking15)\n",
    "# SIDatasWalking16 =  np.array(InsoleWalking16)\n",
    "# SIDatasWalking17 =  np.array(InsoleWalking17)\n",
    "# SIDatasWalking18 =  np.array(InsoleWalking18)\n",
    "# SIDatasWalking19 =  np.array(InsoleWalking19)\n",
    "# SIDatasWalking20 =  np.array(InsoleWalking20)\n",
    "# SIDatasWalking21 =  np.array(InsoleWalking21)\n",
    "# SIDatasWalking22 =  np.array(InsoleWalking22)\n",
    "\n",
    "# dfwalk1 = pd.read_csv('0310AyuRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk2 = pd.read_csv('0310HudaRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk3 = pd.read_csv('0311LalaRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk4 = pd.read_csv('0311YunitaRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk5 = pd.read_csv('0312AbelRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk6 = pd.read_csv('0312AbiRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk7 = pd.read_csv('0312AryaRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk8 = pd.read_csv('0312HawaRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk9 = pd.read_csv('0312NisaRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk10 = pd.read_csv('0313ChenChengRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk11 = pd.read_csv('0313RezaRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk12 = pd.read_csv('0313RilaniRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk13 = pd.read_csv('0313SariRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk14 = pd.read_csv('0313ShelbyRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk15 = pd.read_csv('0314HelenRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk16 = pd.read_csv('0315AyuRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk17 = pd.read_csv('0315HappyRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk18 = pd.read_csv('0317HeniRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk19 = pd.read_csv('0317NadiaRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk20 = pd.read_csv('0317VikaRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk21 = pd.read_csv('0319AlfianRWalk5Min.csv', low_memory=False)\n",
    "# dfwalk22 = pd.read_csv('1225JakariaRWalk5Min.csv', low_memory=False)\n",
    "\n",
    "# selected_dfwalks1 = dfwalk1[columns]\n",
    "# selected_dfwalks2 = dfwalk2[columns]\n",
    "# selected_dfwalks3 = dfwalk3[columns]\n",
    "# selected_dfwalks4 = dfwalk4[columns]\n",
    "# selected_dfwalks5 = dfwalk5[columns]\n",
    "# selected_dfwalks6 = dfwalk6[columns]\n",
    "# selected_dfwalks7 = dfwalk7[columns]\n",
    "# selected_dfwalks8 = dfwalk8[columns]\n",
    "# selected_dfwalks9 = dfwalk9[columns]\n",
    "# selected_dfwalks10 = dfwalk10[columns]\n",
    "# selected_dfwalks11 = dfwalk11[columns]\n",
    "# selected_dfwalks12 = dfwalk12[columns]\n",
    "# selected_dfwalks13 = dfwalk13[columns]\n",
    "# selected_dfwalks14 = dfwalk14[columns]\n",
    "# selected_dfwalks15 = dfwalk15[columns]\n",
    "# selected_dfwalks16 = dfwalk16[columns]\n",
    "# selected_dfwalks17 = dfwalk17[columns]\n",
    "# selected_dfwalks18 = dfwalk18[columns]\n",
    "# selected_dfwalks19 = dfwalk19[columns]\n",
    "# selected_dfwalks20 = dfwalk20[columns]\n",
    "# selected_dfwalks21 = dfwalk21[columns]\n",
    "# selected_dfwalks22 = dfwalk22[columns]\n",
    "# FPDatasWalking1 = selected_dfwalks1[:15000]\n",
    "# FPDatasWalking2 = selected_dfwalks2[:15000]\n",
    "# FPDatasWalking3 = selected_dfwalks3[:15000]\n",
    "# FPDatasWalking4 = selected_dfwalks4[:15000]\n",
    "# FPDatasWalking5 = selected_dfwalks5[:15000]\n",
    "# FPDatasWalking6 = selected_dfwalks6[:15000]\n",
    "# FPDatasWalking7 = selected_dfwalks7[:15000]\n",
    "# FPDatasWalking8 = selected_dfwalks8[:15000]\n",
    "# FPDatasWalking9 = selected_dfwalks9[:15000]\n",
    "# FPDatasWalking10 = selected_dfwalks10[:15000]\n",
    "# FPDatasWalking11 = selected_dfwalks11[:15000]\n",
    "# FPDatasWalking12 = selected_dfwalks12[:15000]\n",
    "# FPDatasWalking13 = selected_dfwalks13[:15000]\n",
    "# FPDatasWalking14 = selected_dfwalks14[:15000]\n",
    "# FPDatasWalking15 = selected_dfwalks15[:15000]\n",
    "# FPDatasWalking16 = selected_dfwalks16[:15000]\n",
    "# FPDatasWalking17 = selected_dfwalks17[:15000]\n",
    "# FPDatasWalking18 = selected_dfwalks18[:15000]\n",
    "# FPDatasWalking19 = selected_dfwalks19[:15000]\n",
    "# FPDatasWalking20 = selected_dfwalks20[:15000]\n",
    "# FPDatasWalking21 = selected_dfwalks21[:15000]\n",
    "# FPDatasWalking22 = selected_dfwalks22[:15000]\n",
    "\n",
    "# SIDataWalking1 = np.array(SIDatasWalking1[:15000]).astype('float32')\n",
    "# SIDataWalking2 = np.array(SIDatasWalking2[:15000]).astype('float32')\n",
    "# SIDataWalking3 = np.array(SIDatasWalking3[:15000]).astype('float32')\n",
    "# SIDataWalking4 = np.array(SIDatasWalking4[:15000]).astype('float32')\n",
    "# SIDataWalking5 = np.array(SIDatasWalking5[:15000]).astype('float32')\n",
    "# SIDataWalking6 = np.array(SIDatasWalking6[:15000]).astype('float32')\n",
    "# SIDataWalking7 = np.array(SIDatasWalking7[:15000]).astype('float32')\n",
    "# SIDataWalking8 = np.array(SIDatasWalking8[:15000]).astype('float32')\n",
    "# SIDataWalking9 = np.array(SIDatasWalking9[:15000]).astype('float32')\n",
    "# SIDataWalking10 = np.array(SIDatasWalking10[:15000]).astype('float32')\n",
    "# SIDataWalking11 = np.array(SIDatasWalking11[:15000]).astype('float32')\n",
    "# SIDataWalking12 = np.array(SIDatasWalking12[:15000]).astype('float32')\n",
    "# SIDataWalking13 = np.array(SIDatasWalking13[:15000]).astype('float32')\n",
    "# SIDataWalking14 = np.array(SIDatasWalking14[:15000]).astype('float32')\n",
    "# SIDataWalking15 = np.array(SIDatasWalking15[:15000]).astype('float32')\n",
    "# SIDataWalking16 = np.array(SIDatasWalking16[:15000]).astype('float32')\n",
    "# SIDataWalking17 = np.array(SIDatasWalking17[:15000]).astype('float32')\n",
    "# SIDataWalking18 = np.array(SIDatasWalking18[:15000]).astype('float32')\n",
    "# SIDataWalking19 = np.array(SIDatasWalking19[:15000]).astype('float32')\n",
    "# SIDataWalking20 = np.array(SIDatasWalking20[:15000]).astype('float32')\n",
    "# SIDataWalking21 = np.array(SIDatasWalking21[:15000]).astype('float32')\n",
    "# SIDataWalking22 = np.array(SIDatasWalking22[:15000]).astype('float32')\n",
    "# FPDataWalking1 = np.array(FPDatasWalking1).astype('float32')\n",
    "# FPDataWalking2 = np.array(FPDatasWalking2).astype('float32')\n",
    "# FPDataWalking3= np.array(FPDatasWalking3).astype('float32')\n",
    "# FPDataWalking4= np.array(FPDatasWalking4).astype('float32')\n",
    "# FPDataWalking5= np.array(FPDatasWalking5).astype('float32')\n",
    "# FPDataWalking6= np.array(FPDatasWalking6).astype('float32')\n",
    "# FPDataWalking7= np.array(FPDatasWalking7).astype('float32')\n",
    "# FPDataWalking8= np.array(FPDatasWalking8).astype('float32')\n",
    "# FPDataWalking9= np.array(FPDatasWalking9).astype('float32')\n",
    "# FPDataWalking10 = np.array(FPDatasWalking10).astype('float32')\n",
    "# FPDataWalking11 = np.array(FPDatasWalking11).astype('float32')\n",
    "# FPDataWalking12= np.array(FPDatasWalking12).astype('float32')\n",
    "# FPDataWalking13= np.array(FPDatasWalking13).astype('float32')\n",
    "# FPDataWalking14= np.array(FPDatasWalking14).astype('float32')\n",
    "# FPDataWalking15= np.array(FPDatasWalking15).astype('float32')\n",
    "# FPDataWalking16= np.array(FPDatasWalking16).astype('float32')\n",
    "# FPDataWalking17= np.array(FPDatasWalking17).astype('float32')\n",
    "# FPDataWalking18= np.array(FPDatasWalking18).astype('float32')\n",
    "# FPDataWalking19= np.array(FPDatasWalking19).astype('float32')\n",
    "# FPDataWalking20= np.array(FPDatasWalking20).astype('float32')\n",
    "# FPDataWalking21= np.array(FPDatasWalking21).astype('float32')\n",
    "# FPDataWalking22= np.array(FPDatasWalking22).astype('float32')\n",
    "\n",
    "# SIDatasetWalking = np.concatenate((SIDataWalking1, SIDataWalking2, SIDataWalking3,\n",
    "#                             SIDataWalking4, SIDataWalking5, SIDataWalking6,\n",
    "# #                             SIDataWalking7, SIDataWalking8, SIDataWalking9,\n",
    "#                             SIDataWalking8, SIDataWalking9,\n",
    "#                             SIDataWalking10, SIDataWalking11, SIDataWalking12,\n",
    "#                             SIDataWalking13, SIDataWalking14, SIDataWalking15,\n",
    "#                             SIDataWalking16, SIDataWalking17, SIDataWalking18,\n",
    "#                             SIDataWalking19, SIDataWalking20, SIDataWalking21), axis=0)\n",
    "                            \n",
    "# FPDatasetWalking = np.concatenate((FPDataWalking1, FPDataWalking2, FPDataWalking3,\n",
    "#                             FPDataWalking4, FPDataWalking5, FPDataWalking6,\n",
    "# #                             FPDataWalking7, FPDataWalking8, FPDataWalking9,\n",
    "#                             FPDataWalking8, FPDataWalking9,\n",
    "#                             FPDataWalking10, FPDataWalking11, FPDataWalking12,\n",
    "#                             FPDataWalking13, FPDataWalking14, FPDataWalking15,\n",
    "#                             FPDataWalking16, FPDataWalking17, FPDataWalking18,\n",
    "#                             FPDataWalking19, FPDataWalking20, FPDataWalking21), axis=0)\n",
    "\n",
    "# SIDatasetWalking = SIDatasetWalking\n",
    "# FPDatasetWalking = FPDatasetWalking\n",
    "\n",
    "# SIDatasetWalking = np.array(SIDatasetWalking).astype('float64')\n",
    "# FPDatasetWalking = np.array(FPDatasetWalking).astype('float64')\n",
    "\n",
    "# # Standing Dataset\n",
    "# InsoleStanding1 = pd.read_csv('0310AyuStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding2 = pd.read_csv('0310HudaStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding3 = pd.read_csv('0311LalaStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding4 = pd.read_csv('0311YunitaStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding5 = pd.read_csv('0312AbelStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding6 = pd.read_csv('0312AbiStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding7 = pd.read_csv('0312AryaStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding8 = pd.read_csv('0312HawaStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding9 = pd.read_csv('0312NisaStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding10 = pd.read_csv('0313ChenChengStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding11 = pd.read_csv('0313RezaStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding12 = pd.read_csv('0313RilaniStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding13 = pd.read_csv('0313SariStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding14 = pd.read_csv('0313ShelbyStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding15 = pd.read_csv('0314HelenStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding16 = pd.read_csv('0315AyuStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding17 = pd.read_csv('0315HappyStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding18 = pd.read_csv('0317HeniStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding19 = pd.read_csv('0317NadiaStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding20 = pd.read_csv('0317VikaStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding21 = pd.read_csv('0319AlfianStand5Min2.txt', header=None, low_memory=False)\n",
    "# InsoleStanding22 = pd.read_csv('0310JakaStand2Min.txt', header=None, low_memory=False)\n",
    "# SIDatasStanding1 =  np.array(InsoleStanding1)\n",
    "# SIDatasStanding2 =  np.array(InsoleStanding2)\n",
    "# SIDatasStanding3 =  np.array(InsoleStanding3)\n",
    "# SIDatasStanding4 =  np.array(InsoleStanding4)\n",
    "# SIDatasStanding5 =  np.array(InsoleStanding5)\n",
    "# SIDatasStanding6 =  np.array(InsoleStanding6)\n",
    "# SIDatasStanding7 =  np.array(InsoleStanding7)\n",
    "# SIDatasStanding8 =  np.array(InsoleStanding8)\n",
    "# SIDatasStanding9 =  np.array(InsoleStanding9)\n",
    "# SIDatasStanding10 =  np.array(InsoleStanding10)\n",
    "# SIDatasStanding11 =  np.array(InsoleStanding11)\n",
    "# SIDatasStanding12 =  np.array(InsoleStanding12)\n",
    "# SIDatasStanding13 =  np.array(InsoleStanding13)\n",
    "# SIDatasStanding14 =  np.array(InsoleStanding14)\n",
    "# SIDatasStanding15 =  np.array(InsoleStanding15)\n",
    "# SIDatasStanding16 =  np.array(InsoleStanding16)\n",
    "# SIDatasStanding17 =  np.array(InsoleStanding17)\n",
    "# SIDatasStanding18 =  np.array(InsoleStanding18)\n",
    "# SIDatasStanding19 =  np.array(InsoleStanding19)\n",
    "# SIDatasStanding20 =  np.array(InsoleStanding20)\n",
    "# SIDatasStanding21 =  np.array(InsoleStanding21)\n",
    "# SIDatasStanding22 =  np.array(InsoleStanding22)\n",
    "\n",
    "# dfStanding1 = pd.read_csv('0310AyuStand5Min2.csv', low_memory=False)\n",
    "# dfStanding2 = pd.read_csv('0310HudaStand5Min2.csv', low_memory=False)\n",
    "# dfStanding3 = pd.read_csv('0311LalaStand5Min2.csv', low_memory=False)\n",
    "# dfStanding4 = pd.read_csv('0311YunitaStand5Min2.csv', low_memory=False)\n",
    "# dfStanding5 = pd.read_csv('0312AbelStand5Min2.csv', low_memory=False)\n",
    "# dfStanding6 = pd.read_csv('0312AbiStand5Min2.csv', low_memory=False)\n",
    "# dfStanding7 = pd.read_csv('0312AryaStand5Min2.csv', low_memory=False)\n",
    "# dfStanding8 = pd.read_csv('0312HawaStand5Min2.csv', low_memory=False)\n",
    "# dfStanding9 = pd.read_csv('0312NisaStand5Min2.csv', low_memory=False)\n",
    "# dfStanding10 = pd.read_csv('0313ChenChengStand5Min2.csv', low_memory=False)\n",
    "# dfStanding11 = pd.read_csv('0313RezaStand5Min2.csv', low_memory=False)\n",
    "# dfStanding12 = pd.read_csv('0313RilaniStand5Min2.csv', low_memory=False)\n",
    "# dfStanding13 = pd.read_csv('0313SariStand5Min2.csv', low_memory=False)\n",
    "# dfStanding14 = pd.read_csv('0313ShelbyStand5Min2.csv', low_memory=False)\n",
    "# dfStanding15 = pd.read_csv('0314HelenStand5Min2.csv', low_memory=False)\n",
    "# dfStanding16 = pd.read_csv('0315AyuStand5Min2.csv', low_memory=False)\n",
    "# dfStanding17 = pd.read_csv('0315HappyStand5Min2.csv', low_memory=False)\n",
    "# dfStanding18 = pd.read_csv('0317HeniStand5Min2.csv', low_memory=False)\n",
    "# dfStanding19 = pd.read_csv('0317NadiaStand5Min2.csv', low_memory=False)\n",
    "# dfStanding20 = pd.read_csv('0317VikaStand5Min2.csv', low_memory=False)\n",
    "# dfStanding21 = pd.read_csv('0319AlfianStand5Min2.csv', low_memory=False)\n",
    "# dfStanding22 = pd.read_csv('0310JakaStand2Min.csv', low_memory=False)\n",
    "\n",
    "# selected_dfStandings1 = dfStanding1[columns]\n",
    "# selected_dfStandings2 = dfStanding2[columns]\n",
    "# selected_dfStandings3 = dfStanding3[columns]\n",
    "# selected_dfStandings4 = dfStanding4[columns]\n",
    "# selected_dfStandings5 = dfStanding5[columns]\n",
    "# selected_dfStandings6 = dfStanding6[columns]\n",
    "# selected_dfStandings7 = dfStanding7[columns]\n",
    "# selected_dfStandings8 = dfStanding8[columns]\n",
    "# selected_dfStandings9 = dfStanding9[columns]\n",
    "# selected_dfStandings10 = dfStanding10[columns]\n",
    "# selected_dfStandings11 = dfStanding11[columns]\n",
    "# selected_dfStandings12 = dfStanding12[columns]\n",
    "# selected_dfStandings13 = dfStanding13[columns]\n",
    "# selected_dfStandings14 = dfStanding14[columns]\n",
    "# selected_dfStandings15 = dfStanding15[columns]\n",
    "# selected_dfStandings16 = dfStanding16[columns]\n",
    "# selected_dfStandings17 = dfStanding17[columns]\n",
    "# selected_dfStandings18 = dfStanding18[columns]\n",
    "# selected_dfStandings19 = dfStanding19[columns]\n",
    "# selected_dfStandings20 = dfStanding20[columns]\n",
    "# selected_dfStandings21 = dfStanding21[columns]\n",
    "# selected_dfStandings22 = dfStanding22[columns]\n",
    "# FPDataStandings1 = selected_dfStandings1[:15000]\n",
    "# FPDataStandings2 = selected_dfStandings2[:15000]\n",
    "# FPDataStandings3 = selected_dfStandings3[:15000]\n",
    "# FPDataStandings4 = selected_dfStandings4[:15000]\n",
    "# FPDataStandings5 = selected_dfStandings5[:15000]\n",
    "# FPDataStandings6 = selected_dfStandings6[:15000]\n",
    "# FPDataStandings7 = selected_dfStandings7[:15000]\n",
    "# FPDataStandings8 = selected_dfStandings8[:15000]\n",
    "# FPDataStandings9 = selected_dfStandings9[:15000]\n",
    "# FPDataStandings10 = selected_dfStandings10[:15000]\n",
    "# FPDataStandings11 = selected_dfStandings11[:15000]\n",
    "# FPDataStandings12 = selected_dfStandings12[:15000]\n",
    "# FPDataStandings13 = selected_dfStandings13[:15000]\n",
    "# FPDataStandings14 = selected_dfStandings14[:15000]\n",
    "# FPDataStandings15 = selected_dfStandings15[:15000]\n",
    "# FPDataStandings16 = selected_dfStandings16[:15000]\n",
    "# FPDataStandings17 = selected_dfStandings17[:15000]\n",
    "# FPDataStandings18 = selected_dfStandings18[:15000]\n",
    "# FPDataStandings19 = selected_dfStandings19[:15000]\n",
    "# FPDataStandings20 = selected_dfStandings20[:15000]\n",
    "# FPDataStandings21 = selected_dfStandings21[:15000]\n",
    "# FPDataStandings22 = selected_dfStandings22[:15000]\n",
    "\n",
    "# SIDataStanding1 = np.array(SIDatasStanding1[:15000]).astype('float32')\n",
    "# SIDataStanding2 = np.array(SIDatasStanding2[:15000]).astype('float32')\n",
    "# SIDataStanding3 = np.array(SIDatasStanding3[:15000]).astype('float32')\n",
    "# SIDataStanding4 = np.array(SIDatasStanding4[:15000]).astype('float32')\n",
    "# SIDataStanding5 = np.array(SIDatasStanding5[:15000]).astype('float32')\n",
    "# SIDataStanding6 = np.array(SIDatasStanding6[:15000]).astype('float32')\n",
    "# SIDataStanding7 = np.array(SIDatasStanding7[:15000]).astype('float32')\n",
    "# SIDataStanding8 = np.array(SIDatasStanding8[:15000]).astype('float32')\n",
    "# SIDataStanding9 = np.array(SIDatasStanding9[:15000]).astype('float32')\n",
    "# SIDataStanding10 = np.array(SIDatasStanding10[:15000]).astype('float32')\n",
    "# SIDataStanding11 = np.array(SIDatasStanding11[:15000]).astype('float32')\n",
    "# SIDataStanding12 = np.array(SIDatasStanding12[:15000]).astype('float32')\n",
    "# SIDataStanding13 = np.array(SIDatasStanding13[:15000]).astype('float32')\n",
    "# SIDataStanding14 = np.array(SIDatasStanding14[:15000]).astype('float32')\n",
    "# SIDataStanding15 = np.array(SIDatasStanding15[:15000]).astype('float32')\n",
    "# SIDataStanding16 = np.array(SIDatasStanding16[:15000]).astype('float32')\n",
    "# SIDataStanding17 = np.array(SIDatasStanding17[:15000]).astype('float32')\n",
    "# SIDataStanding18 = np.array(SIDatasStanding18[:15000]).astype('float32')\n",
    "# SIDataStanding19 = np.array(SIDatasStanding19[:15000]).astype('float32')\n",
    "# SIDataStanding20 = np.array(SIDatasStanding20[:15000]).astype('float32')\n",
    "# SIDataStanding21 = np.array(SIDatasStanding21[:15000]).astype('float32')\n",
    "# SIDataStanding22 = np.array(SIDatasStanding22[:15000]).astype('float32')\n",
    "# FPDataStanding1 = np.array(FPDataStandings1).astype('float32')\n",
    "# FPDataStanding2 = np.array(FPDataStandings2).astype('float32')\n",
    "# FPDataStanding3= np.array(FPDataStandings3).astype('float32')\n",
    "# FPDataStanding4= np.array(FPDataStandings4).astype('float32')\n",
    "# FPDataStanding5= np.array(FPDataStandings5).astype('float32')\n",
    "# FPDataStanding6= np.array(FPDataStandings6).astype('float32')\n",
    "# FPDataStanding7= np.array(FPDataStandings7).astype('float32')\n",
    "# FPDataStanding8= np.array(FPDataStandings8).astype('float32')\n",
    "# FPDataStanding9= np.array(FPDataStandings9).astype('float32')\n",
    "# FPDataStanding10 = np.array(FPDataStandings10).astype('float32')\n",
    "# FPDataStanding11 = np.array(FPDataStandings11).astype('float32')\n",
    "# FPDataStanding12= np.array(FPDataStandings12).astype('float32')\n",
    "# FPDataStanding13= np.array(FPDataStandings13).astype('float32')\n",
    "# FPDataStanding14= np.array(FPDataStandings14).astype('float32')\n",
    "# FPDataStanding15= np.array(FPDataStandings15).astype('float32')\n",
    "# FPDataStanding16= np.array(FPDataStandings16).astype('float32')\n",
    "# FPDataStanding17= np.array(FPDataStandings17).astype('float32')\n",
    "# FPDataStanding18= np.array(FPDataStandings18).astype('float32')\n",
    "# FPDataStanding19= np.array(FPDataStandings19).astype('float32')\n",
    "# FPDataStanding20= np.array(FPDataStandings20).astype('float32')\n",
    "# FPDataStanding21= np.array(FPDataStandings21).astype('float32')\n",
    "# FPDataStanding22= np.array(FPDataStandings22).astype('float32')\n",
    "\n",
    "# SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3,\n",
    "#                             SIDataStanding4, SIDataStanding5, SIDataStanding6,\n",
    "# #                             SIDataStanding7, SIDataStanding8, SIDataStanding9,\n",
    "#                             SIDataStanding8, SIDataStanding9,\n",
    "#                             SIDataStanding10, SIDataStanding11, SIDataStanding12,\n",
    "#                             SIDataStanding13, SIDataStanding14, SIDataStanding15,\n",
    "#                             SIDataStanding16, SIDataStanding17, SIDataStanding18,\n",
    "#                             SIDataStanding19, SIDataStanding20, SIDataStanding21), axis=0)\n",
    "\n",
    "# # SIDatasetStanding = np.concatenate((SIDataStanding13, SIDataStanding20, SIDataStanding17, \n",
    "# #                        SIDataStanding15, SIDataStanding12, SIDataStanding22, SIDataStanding1, SIDataStanding4, SIDataStanding8, \n",
    "# #                        SIDataStanding16, SIDataStanding9, SIDataStanding6, SIDataStanding7, SIDataStanding3,\n",
    "# #                        SIDataStanding19, SIDataStanding10), axis=0)\n",
    "\n",
    "# # SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3), axis=0)\n",
    "# # FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3), axis=0)\n",
    "                        \n",
    "# FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3,\n",
    "#                             FPDataStanding4, FPDataStanding5, FPDataStanding6,\n",
    "# #                             FPDataStanding7, FPDataStanding8, FPDataStanding9,\n",
    "#                             FPDataStanding8, FPDataStanding9,\n",
    "#                             FPDataStanding10, FPDataStanding11, FPDataStanding12,\n",
    "#                             FPDataStanding13, FPDataStanding14, FPDataStanding15,\n",
    "#                             FPDataStanding16, FPDataStanding17, FPDataStanding18,\n",
    "#                             FPDataStanding19, FPDataStanding20, FPDataStanding21), axis=0)\n",
    "\n",
    "# # FPDatasetStanding = np.concatenate((FPDataStanding13, FPDataStanding20, FPDataStanding17, \n",
    "# #                        FPDataStanding15, FPDataStanding12, FPDataStanding22, FPDataStanding1, FPDataStanding4, FPDataStanding8, \n",
    "# #                        FPDataStanding16, FPDataStanding9, FPDataStanding6, FPDataStanding7, FPDataStanding3,\n",
    "# #                        FPDataStanding19, FPDataStanding10), axis=0)\n",
    "\n",
    "# SIDatasetStanding = SIDatasetStanding\n",
    "# FPDatasetStanding = FPDatasetStanding\n",
    "\n",
    "# SIDatasetStanding = np.array(SIDatasetStanding).astype('float32')\n",
    "# FPDatasetStanding = np.array(FPDatasetStanding).astype('float32')\n",
    "\n",
    "# # Concat Standing and Walking\n",
    "# SIDataset = np.concatenate((SIDatasetWalking,SIDatasetStanding), axis=0)\n",
    "# FPDataset = np.concatenate((FPDatasetWalking,FPDatasetStanding), axis=0)\n",
    "# # SIDataset = SIDatasetStanding\n",
    "# # FPDataset = FPDatasetStanding\n",
    "\n",
    "# # SIDataset = SIDatasetStanding\n",
    "# # FPDataset = FPDatasetStanding\n",
    "\n",
    "\n",
    "# # Data Cleaning: Remove or correct mislabeled instances in your dataset\n",
    "# outlier_detector = LocalOutlierFactor(novelty=True)\n",
    "# outlier_detector.fit(FPDataset)\n",
    "# outlier_mask = outlier_detector.predict(FPDataset)\n",
    "# cleaned_smart_insole_data_scaled = SIDataset[outlier_mask == 1]\n",
    "# cleaned_force_plate_data_scaled = FPDataset[outlier_mask == 1]\n",
    "\n",
    "\n",
    "# ## End Load Data\n",
    "# for i in range(len(cleaned_smart_insole_data_scaled)):\n",
    "#     cleaned_smart_insole_data_scaled[i][0] = np.round(cleaned_smart_insole_data_scaled[i][0] + (iter % max_iter) + 1,0)\n",
    "#     iter += 1\n",
    "    \n",
    "# # FPDataPreAdjusted = FPDataset.copy()\n",
    "# # for i in range(len(FPDataPreAdjusted)):\n",
    "# #     # FPDataPreAdjusted[i][0] = FPDataPreAdjusted[i][0] + (iter % max_iter) + 1\n",
    "# #     FPDataPreAdjusted[i][0] = FPDataPreAdjusted[i][0] + ((iter % max_iter) + 1) * 1.5\n",
    "# #     iter += 1\n",
    "\n",
    "    \n",
    "     \n",
    "# # Data Normalization\n",
    "# # scaler_SI = MinMaxScaler(feature_range=(0, 1))\n",
    "# # scaler_SI.fit(SIData_filtered)\n",
    "# # scaler_fx = MinMaxScaler(feature_range=(0, 1))\n",
    "# # scaler_fx.fit(FPDataset[:, 0].reshape(-1, 1))\n",
    "# # scaler_fy = MinMaxScaler(feature_range=(0, 1))\n",
    "# # scaler_fy.fit(FPDataset[:, 1].reshape(-1, 1))\n",
    "# # scaler_fz = MinMaxScaler(feature_range=(0, 1))\n",
    "# # scaler_fz.fit(FPDataset[:, 2].reshape(-1, 1))\n",
    "# # scaler_mx = MinMaxScaler(feature_range=(0, 1))\n",
    "# # scaler_mx.fit(FPDataset[:, 3].reshape(-1, 1))\n",
    "# # scaler_my = MinMaxScaler(feature_range=(0, 1))\n",
    "# # scaler_my.fit(FPDataset[:, 4].reshape(-1, 1))\n",
    "# # scaler_mz = MinMaxScaler(feature_range=(0, 1))\n",
    "# # scaler_mz.fit(FPDataset[:, 5].reshape(-1, 1))\n",
    "\n",
    "# # Normalize each feature separately\n",
    "# # normalized_SIData = scaler_SI.transform(SIData_filtered)\n",
    "# # normalized_fx = scaler_fx.transform(FPDataset[:, 0].reshape(-1, 1))\n",
    "# # normalized_fy = scaler_fy.transform(FPDataset[:, 1].reshape(-1, 1))\n",
    "# # normalized_fz = scaler_fz.transform(FPDataset[:, 2].reshape(-1, 1))\n",
    "# # normalized_mx = scaler_mx.transform(FPDataset[:, 3].reshape(-1, 1))\n",
    "# # normalized_my = scaler_my.transform(FPDataset[:, 4].reshape(-1, 1))\n",
    "# # normalized_mz = scaler_mz.transform(FPDataset[:, 5].reshape(-1, 1))\n",
    "\n",
    "# scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_x.fit(cleaned_smart_insole_data_scaled)\n",
    "# xscale = scaler_x.transform(cleaned_smart_insole_data_scaled)\n",
    "\n",
    "# scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_y.fit(cleaned_force_plate_data_scaled)\n",
    "# yscale = scaler_y.transform(cleaned_force_plate_data_scaled)\n",
    "\n",
    "\n",
    "# # Combine the normalized features back into a single numpy array\n",
    "# # normalized_FPData= np.concatenate((normalized_fx, normalized_fy, normalized_fz, \n",
    "# #                                               normalized_mx, normalized_my, normalized_mz), axis=1)\n",
    "# #End Data Normalization\n",
    "\n",
    "# #Spliting Data\n",
    "# sample_size = xscale.shape[0] # number of samples in train set\n",
    "# time_steps  = xscale.shape[1] # number of features in train set\n",
    "# input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "# train_data_reshaped = xscale.reshape(sample_size,time_steps,input_dimension)\n",
    "\n",
    "# # Generate random indices for shuffling the data\n",
    "# indices = np.arange(train_data_reshaped.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "\n",
    "# # Use the shuffled indices to randomly select training data\n",
    "# X_train = train_data_reshaped[indices[:]]\n",
    "# y_train = yscale[indices[:]]\n",
    "\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(train_data_reshaped, normalized_fx, test_size=0.20, random_state=2)\n",
    "\n",
    "# print(X_train.shape,y_train.shape)\n",
    "# # print(y_train.shape,y_test.shape)\n",
    "# #End Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeR4-T_yKu00",
    "outputId": "d4c38f3d-2523-47cd-8038-27d5b1807c1c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_smart_insole_data_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 443\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# Data Normalization\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# scaler_SI = MinMaxScaler(feature_range=(0, 1))\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# scaler_SI.fit(SIData_filtered)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;66;03m# normalized_my = scaler_my.transform(FPDataset[:, 4].reshape(-1, 1))\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;66;03m# normalized_mz = scaler_mz.transform(FPDataset[:, 5].reshape(-1, 1))\u001b[39;00m\n\u001b[0;32m    442\u001b[0m scaler_x \u001b[38;5;241m=\u001b[39m MinMaxScaler(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 443\u001b[0m scaler_x\u001b[38;5;241m.\u001b[39mfit(\u001b[43mcleaned_smart_insole_data_scaled\u001b[49m)\n\u001b[0;32m    444\u001b[0m xscale \u001b[38;5;241m=\u001b[39m scaler_x\u001b[38;5;241m.\u001b[39mtransform(cleaned_smart_insole_data_scaled)\n\u001b[0;32m    446\u001b[0m scaler_y \u001b[38;5;241m=\u001b[39m MinMaxScaler(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned_smart_insole_data_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "columns = ['Fx']\n",
    "# columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "wavelet = 'db4'\n",
    "max_iter = 50\n",
    "iter = 0\n",
    "\n",
    "# Walking Dataset\n",
    "InsoleWalking1 = pd.read_csv('0310AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking2 = pd.read_csv('0310HudaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking3 = pd.read_csv('0311LalaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking4 = pd.read_csv('0311YunitaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking5 = pd.read_csv('0312AbelRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking6 = pd.read_csv('0312AbiRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking7 = pd.read_csv('0312AryaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking8 = pd.read_csv('0312HawaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking9 = pd.read_csv('0312NisaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking10 = pd.read_csv('0313ChenChengRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking11 = pd.read_csv('0313RezaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking12 = pd.read_csv('0313RilaniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking13 = pd.read_csv('0313SariRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking14 = pd.read_csv('0313ShelbyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking15 = pd.read_csv('0314HelenRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking16 = pd.read_csv('0315AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking17 = pd.read_csv('0315HappyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking18 = pd.read_csv('0317HeniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking19 = pd.read_csv('0317NadiaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking20 = pd.read_csv('0317VikaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking21 = pd.read_csv('0319AlfianRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking22 = pd.read_csv('1225JakariaRWalk5Min.txt', header=None, low_memory=False)\n",
    "SIDatasWalking1 =  np.array(InsoleWalking1)\n",
    "SIDatasWalking2 =  np.array(InsoleWalking2)\n",
    "SIDatasWalking3 =  np.array(InsoleWalking3)\n",
    "SIDatasWalking4 =  np.array(InsoleWalking4)\n",
    "SIDatasWalking5 =  np.array(InsoleWalking5)\n",
    "SIDatasWalking6 =  np.array(InsoleWalking6)\n",
    "SIDatasWalking7 =  np.array(InsoleWalking7)\n",
    "SIDatasWalking8 =  np.array(InsoleWalking8)\n",
    "SIDatasWalking9 =  np.array(InsoleWalking9)\n",
    "SIDatasWalking10 =  np.array(InsoleWalking10)\n",
    "SIDatasWalking11 =  np.array(InsoleWalking11)\n",
    "SIDatasWalking12 =  np.array(InsoleWalking12)\n",
    "SIDatasWalking13 =  np.array(InsoleWalking13)\n",
    "SIDatasWalking14 =  np.array(InsoleWalking14)\n",
    "SIDatasWalking15 =  np.array(InsoleWalking15)\n",
    "SIDatasWalking16 =  np.array(InsoleWalking16)\n",
    "SIDatasWalking17 =  np.array(InsoleWalking17)\n",
    "SIDatasWalking18 =  np.array(InsoleWalking18)\n",
    "SIDatasWalking19 =  np.array(InsoleWalking19)\n",
    "SIDatasWalking20 =  np.array(InsoleWalking20)\n",
    "SIDatasWalking21 =  np.array(InsoleWalking21)\n",
    "SIDatasWalking22 =  np.array(InsoleWalking22)\n",
    "\n",
    "dfwalk1 = pd.read_csv('0310AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk2 = pd.read_csv('0310HudaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk3 = pd.read_csv('0311LalaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk4 = pd.read_csv('0311YunitaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk5 = pd.read_csv('0312AbelRWalk5Min.csv', low_memory=False)\n",
    "dfwalk6 = pd.read_csv('0312AbiRWalk5Min.csv', low_memory=False)\n",
    "dfwalk7 = pd.read_csv('0312AryaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk8 = pd.read_csv('0312HawaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk9 = pd.read_csv('0312NisaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk10 = pd.read_csv('0313ChenChengRWalk5Min.csv', low_memory=False)\n",
    "dfwalk11 = pd.read_csv('0313RezaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk12 = pd.read_csv('0313RilaniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk13 = pd.read_csv('0313SariRWalk5Min.csv', low_memory=False)\n",
    "dfwalk14 = pd.read_csv('0313ShelbyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk15 = pd.read_csv('0314HelenRWalk5Min.csv', low_memory=False)\n",
    "dfwalk16 = pd.read_csv('0315AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk17 = pd.read_csv('0315HappyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk18 = pd.read_csv('0317HeniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk19 = pd.read_csv('0317NadiaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk20 = pd.read_csv('0317VikaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk21 = pd.read_csv('0319AlfianRWalk5Min.csv', low_memory=False)\n",
    "dfwalk22 = pd.read_csv('1225JakariaRWalk5Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfwalks1 = dfwalk1[columns]\n",
    "selected_dfwalks2 = dfwalk2[columns]\n",
    "selected_dfwalks3 = dfwalk3[columns]\n",
    "selected_dfwalks4 = dfwalk4[columns]\n",
    "selected_dfwalks5 = dfwalk5[columns]\n",
    "selected_dfwalks6 = dfwalk6[columns]\n",
    "selected_dfwalks7 = dfwalk7[columns]\n",
    "selected_dfwalks8 = dfwalk8[columns]\n",
    "selected_dfwalks9 = dfwalk9[columns]\n",
    "selected_dfwalks10 = dfwalk10[columns]\n",
    "selected_dfwalks11 = dfwalk11[columns]\n",
    "selected_dfwalks12 = dfwalk12[columns]\n",
    "selected_dfwalks13 = dfwalk13[columns]\n",
    "selected_dfwalks14 = dfwalk14[columns]\n",
    "selected_dfwalks15 = dfwalk15[columns]\n",
    "selected_dfwalks16 = dfwalk16[columns]\n",
    "selected_dfwalks17 = dfwalk17[columns]\n",
    "selected_dfwalks18 = dfwalk18[columns]\n",
    "selected_dfwalks19 = dfwalk19[columns]\n",
    "selected_dfwalks20 = dfwalk20[columns]\n",
    "selected_dfwalks21 = dfwalk21[columns]\n",
    "selected_dfwalks22 = dfwalk22[columns]\n",
    "FPDatasWalking1 = selected_dfwalks1[:15000]\n",
    "FPDatasWalking2 = selected_dfwalks2[:15000]\n",
    "FPDatasWalking3 = selected_dfwalks3[:15000]\n",
    "FPDatasWalking4 = selected_dfwalks4[:15000]\n",
    "FPDatasWalking5 = selected_dfwalks5[:15000]\n",
    "FPDatasWalking6 = selected_dfwalks6[:15000]\n",
    "FPDatasWalking7 = selected_dfwalks7[:15000]\n",
    "FPDatasWalking8 = selected_dfwalks8[:15000]\n",
    "FPDatasWalking9 = selected_dfwalks9[:15000]\n",
    "FPDatasWalking10 = selected_dfwalks10[:15000]\n",
    "FPDatasWalking11 = selected_dfwalks11[:15000]\n",
    "FPDatasWalking12 = selected_dfwalks12[:15000]\n",
    "FPDatasWalking13 = selected_dfwalks13[:15000]\n",
    "FPDatasWalking14 = selected_dfwalks14[:15000]\n",
    "FPDatasWalking15 = selected_dfwalks15[:15000]\n",
    "FPDatasWalking16 = selected_dfwalks16[:15000]\n",
    "FPDatasWalking17 = selected_dfwalks17[:15000]\n",
    "FPDatasWalking18 = selected_dfwalks18[:15000]\n",
    "FPDatasWalking19 = selected_dfwalks19[:15000]\n",
    "FPDatasWalking20 = selected_dfwalks20[:15000]\n",
    "FPDatasWalking21 = selected_dfwalks21[:15000]\n",
    "FPDatasWalking22 = selected_dfwalks22[:15000]\n",
    "\n",
    "SIDataWalking1 = np.array(SIDatasWalking1[:15000]).astype('float32')\n",
    "SIDataWalking2 = np.array(SIDatasWalking2[:15000]).astype('float32')\n",
    "SIDataWalking3 = np.array(SIDatasWalking3[:15000]).astype('float32')\n",
    "SIDataWalking4 = np.array(SIDatasWalking4[:15000]).astype('float32')\n",
    "SIDataWalking5 = np.array(SIDatasWalking5[:15000]).astype('float32')\n",
    "SIDataWalking6 = np.array(SIDatasWalking6[:15000]).astype('float32')\n",
    "SIDataWalking7 = np.array(SIDatasWalking7[:15000]).astype('float32')\n",
    "SIDataWalking8 = np.array(SIDatasWalking8[:15000]).astype('float32')\n",
    "SIDataWalking9 = np.array(SIDatasWalking9[:15000]).astype('float32')\n",
    "SIDataWalking10 = np.array(SIDatasWalking10[:15000]).astype('float32')\n",
    "SIDataWalking11 = np.array(SIDatasWalking11[:15000]).astype('float32')\n",
    "SIDataWalking12 = np.array(SIDatasWalking12[:15000]).astype('float32')\n",
    "SIDataWalking13 = np.array(SIDatasWalking13[:15000]).astype('float32')\n",
    "SIDataWalking14 = np.array(SIDatasWalking14[:15000]).astype('float32')\n",
    "SIDataWalking15 = np.array(SIDatasWalking15[:15000]).astype('float32')\n",
    "SIDataWalking16 = np.array(SIDatasWalking16[:15000]).astype('float32')\n",
    "SIDataWalking17 = np.array(SIDatasWalking17[:15000]).astype('float32')\n",
    "SIDataWalking18 = np.array(SIDatasWalking18[:15000]).astype('float32')\n",
    "SIDataWalking19 = np.array(SIDatasWalking19[:15000]).astype('float32')\n",
    "SIDataWalking20 = np.array(SIDatasWalking20[:15000]).astype('float32')\n",
    "SIDataWalking21 = np.array(SIDatasWalking21[:15000]).astype('float32')\n",
    "SIDataWalking22 = np.array(SIDatasWalking22[:15000]).astype('float32')\n",
    "FPDataWalking1 = np.array(FPDatasWalking1).astype('float32')\n",
    "FPDataWalking2 = np.array(FPDatasWalking2).astype('float32')\n",
    "FPDataWalking3= np.array(FPDatasWalking3).astype('float32')\n",
    "FPDataWalking4= np.array(FPDatasWalking4).astype('float32')\n",
    "FPDataWalking5= np.array(FPDatasWalking5).astype('float32')\n",
    "FPDataWalking6= np.array(FPDatasWalking6).astype('float32')\n",
    "FPDataWalking7= np.array(FPDatasWalking7).astype('float32')\n",
    "FPDataWalking8= np.array(FPDatasWalking8).astype('float32')\n",
    "FPDataWalking9= np.array(FPDatasWalking9).astype('float32')\n",
    "FPDataWalking10 = np.array(FPDatasWalking10).astype('float32')\n",
    "FPDataWalking11 = np.array(FPDatasWalking11).astype('float32')\n",
    "FPDataWalking12= np.array(FPDatasWalking12).astype('float32')\n",
    "FPDataWalking13= np.array(FPDatasWalking13).astype('float32')\n",
    "FPDataWalking14= np.array(FPDatasWalking14).astype('float32')\n",
    "FPDataWalking15= np.array(FPDatasWalking15).astype('float32')\n",
    "FPDataWalking16= np.array(FPDatasWalking16).astype('float32')\n",
    "FPDataWalking17= np.array(FPDatasWalking17).astype('float32')\n",
    "FPDataWalking18= np.array(FPDatasWalking18).astype('float32')\n",
    "FPDataWalking19= np.array(FPDatasWalking19).astype('float32')\n",
    "FPDataWalking20= np.array(FPDatasWalking20).astype('float32')\n",
    "FPDataWalking21= np.array(FPDatasWalking21).astype('float32')\n",
    "FPDataWalking22= np.array(FPDatasWalking22).astype('float32')\n",
    "\n",
    "SIDatasetWalking = np.concatenate((SIDataWalking1, SIDataWalking2, SIDataWalking3,\n",
    "                            SIDataWalking4, SIDataWalking5, SIDataWalking6,\n",
    "                            SIDataWalking7, SIDataWalking8, SIDataWalking9,\n",
    "                            SIDataWalking10, SIDataWalking11, SIDataWalking12,\n",
    "                            SIDataWalking13, SIDataWalking14, SIDataWalking15,\n",
    "                            SIDataWalking16, SIDataWalking17, SIDataWalking18,\n",
    "                            SIDataWalking19, SIDataWalking20, SIDataWalking21,\n",
    "                            SIDataWalking22), axis=0)\n",
    "                            \n",
    "FPDatasetWalking = np.concatenate((FPDataWalking1, FPDataWalking2, FPDataWalking3,\n",
    "                            FPDataWalking4, FPDataWalking5, FPDataWalking6,\n",
    "                            FPDataWalking7, FPDataWalking8, FPDataWalking9,\n",
    "                            FPDataWalking10, FPDataWalking11, FPDataWalking12,\n",
    "                            FPDataWalking13, FPDataWalking14, FPDataWalking15,\n",
    "                            FPDataWalking16, FPDataWalking17, FPDataWalking18,\n",
    "                            FPDataWalking19, FPDataWalking20, FPDataWalking21,\n",
    "                            FPDataWalking22), axis=0)\n",
    "\n",
    "# SIDatasetWalking = SIDataWalking1\n",
    "# FPDatasetWalking = FPDataWalking1\n",
    "\n",
    "# SIDatasetWalking = np.array(SIDatasetWalking).astype('float64')\n",
    "# FPDatasetWalking = np.array(FPDatasetWalking).astype('float64')\n",
    "\n",
    "# Standing Dataset\n",
    "InsoleStanding1 = pd.read_csv('0310AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding2 = pd.read_csv('0310HudaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding3 = pd.read_csv('0311LalaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding4 = pd.read_csv('0311YunitaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding5 = pd.read_csv('0312AbelStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding6 = pd.read_csv('0312AbiStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding7 = pd.read_csv('0312AryaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding8 = pd.read_csv('0312HawaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding9 = pd.read_csv('0312NisaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding10 = pd.read_csv('0313ChenChengStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding11 = pd.read_csv('0313RezaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding12 = pd.read_csv('0313RilaniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding13 = pd.read_csv('0313SariStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding14 = pd.read_csv('0313ShelbyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding15 = pd.read_csv('0314HelenStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding16 = pd.read_csv('0315AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding17 = pd.read_csv('0315HappyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding18 = pd.read_csv('0317HeniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding19 = pd.read_csv('0317NadiaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding20 = pd.read_csv('0317VikaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding21 = pd.read_csv('0319AlfianStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding22 = pd.read_csv('0310JakaStand2Min.txt', header=None, low_memory=False)\n",
    "SIDatasStanding1 =  np.array(InsoleStanding1)\n",
    "SIDatasStanding2 =  np.array(InsoleStanding2)\n",
    "SIDatasStanding3 =  np.array(InsoleStanding3)\n",
    "SIDatasStanding4 =  np.array(InsoleStanding4)\n",
    "SIDatasStanding5 =  np.array(InsoleStanding5)\n",
    "SIDatasStanding6 =  np.array(InsoleStanding6)\n",
    "SIDatasStanding7 =  np.array(InsoleStanding7)\n",
    "SIDatasStanding8 =  np.array(InsoleStanding8)\n",
    "SIDatasStanding9 =  np.array(InsoleStanding9)\n",
    "SIDatasStanding10 =  np.array(InsoleStanding10)\n",
    "SIDatasStanding11 =  np.array(InsoleStanding11)\n",
    "SIDatasStanding12 =  np.array(InsoleStanding12)\n",
    "SIDatasStanding13 =  np.array(InsoleStanding13)\n",
    "SIDatasStanding14 =  np.array(InsoleStanding14)\n",
    "SIDatasStanding15 =  np.array(InsoleStanding15)\n",
    "SIDatasStanding16 =  np.array(InsoleStanding16)\n",
    "SIDatasStanding17 =  np.array(InsoleStanding17)\n",
    "SIDatasStanding18 =  np.array(InsoleStanding18)\n",
    "SIDatasStanding19 =  np.array(InsoleStanding19)\n",
    "SIDatasStanding20 =  np.array(InsoleStanding20)\n",
    "SIDatasStanding21 =  np.array(InsoleStanding21)\n",
    "SIDatasStanding22 =  np.array(InsoleStanding22)\n",
    "\n",
    "dfStanding1 = pd.read_csv('0310AyuStand5Min1.csv', low_memory=False)\n",
    "dfStanding2 = pd.read_csv('0310HudaStand5Min1.csv', low_memory=False)\n",
    "dfStanding3 = pd.read_csv('0311LalaStand5Min1.csv', low_memory=False)\n",
    "dfStanding4 = pd.read_csv('0311YunitaStand5Min1.csv', low_memory=False)\n",
    "dfStanding5 = pd.read_csv('0312AbelStand5Min1.csv', low_memory=False)\n",
    "dfStanding6 = pd.read_csv('0312AbiStand5Min1.csv', low_memory=False)\n",
    "dfStanding7 = pd.read_csv('0312AryaStand5Min1.csv', low_memory=False)\n",
    "dfStanding8 = pd.read_csv('0312HawaStand5Min1.csv', low_memory=False)\n",
    "dfStanding9 = pd.read_csv('0312NisaStand5Min1.csv', low_memory=False)\n",
    "dfStanding10 = pd.read_csv('0313ChenChengStand5Min1.csv', low_memory=False)\n",
    "dfStanding11 = pd.read_csv('0313RezaStand5Min1.csv', low_memory=False)\n",
    "dfStanding12 = pd.read_csv('0313RilaniStand5Min1.csv', low_memory=False)\n",
    "dfStanding13 = pd.read_csv('0313SariStand5Min1.csv', low_memory=False)\n",
    "dfStanding14 = pd.read_csv('0313ShelbyStand5Min1.csv', low_memory=False)\n",
    "dfStanding15 = pd.read_csv('0314HelenStand5Min1.csv', low_memory=False)\n",
    "dfStanding16 = pd.read_csv('0315AyuStand5Min1.csv', low_memory=False)\n",
    "dfStanding17 = pd.read_csv('0315HappyStand5Min1.csv', low_memory=False)\n",
    "dfStanding18 = pd.read_csv('0317HeniStand5Min1.csv', low_memory=False)\n",
    "dfStanding19 = pd.read_csv('0317NadiaStand5Min1.csv', low_memory=False)\n",
    "dfStanding20 = pd.read_csv('0317VikaStand5Min1.csv', low_memory=False)\n",
    "dfStanding21 = pd.read_csv('0319AlfianStand5Min1.csv', low_memory=False)\n",
    "dfStanding22 = pd.read_csv('0310JakaStand2Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfStandings1 = dfStanding1[columns]\n",
    "selected_dfStandings2 = dfStanding2[columns]\n",
    "selected_dfStandings3 = dfStanding3[columns]\n",
    "selected_dfStandings4 = dfStanding4[columns]\n",
    "selected_dfStandings5 = dfStanding5[columns]\n",
    "selected_dfStandings6 = dfStanding6[columns]\n",
    "selected_dfStandings7 = dfStanding7[columns]\n",
    "selected_dfStandings8 = dfStanding8[columns]\n",
    "selected_dfStandings9 = dfStanding9[columns]\n",
    "selected_dfStandings10 = dfStanding10[columns]\n",
    "selected_dfStandings11 = dfStanding11[columns]\n",
    "selected_dfStandings12 = dfStanding12[columns]\n",
    "selected_dfStandings13 = dfStanding13[columns]\n",
    "selected_dfStandings14 = dfStanding14[columns]\n",
    "selected_dfStandings15 = dfStanding15[columns]\n",
    "selected_dfStandings16 = dfStanding16[columns]\n",
    "selected_dfStandings17 = dfStanding17[columns]\n",
    "selected_dfStandings18 = dfStanding18[columns]\n",
    "selected_dfStandings19 = dfStanding19[columns]\n",
    "selected_dfStandings20 = dfStanding20[columns]\n",
    "selected_dfStandings21 = dfStanding21[columns]\n",
    "selected_dfStandings22 = dfStanding22[columns]\n",
    "FPDataStandings1 = selected_dfStandings1[:15000]\n",
    "FPDataStandings2 = selected_dfStandings2[:15000]\n",
    "FPDataStandings3 = selected_dfStandings3[:15000]\n",
    "FPDataStandings4 = selected_dfStandings4[:15000]\n",
    "FPDataStandings5 = selected_dfStandings5[:15000]\n",
    "FPDataStandings6 = selected_dfStandings6[:15000]\n",
    "FPDataStandings7 = selected_dfStandings7[:15000]\n",
    "FPDataStandings8 = selected_dfStandings8[:15000]\n",
    "FPDataStandings9 = selected_dfStandings9[:15000]\n",
    "FPDataStandings10 = selected_dfStandings10[:15000]\n",
    "FPDataStandings11 = selected_dfStandings11[:15000]\n",
    "FPDataStandings12 = selected_dfStandings12[:15000]\n",
    "FPDataStandings13 = selected_dfStandings13[:15000]\n",
    "FPDataStandings14 = selected_dfStandings14[:15000]\n",
    "FPDataStandings15 = selected_dfStandings15[:15000]\n",
    "FPDataStandings16 = selected_dfStandings16[:15000]\n",
    "FPDataStandings17 = selected_dfStandings17[:15000]\n",
    "FPDataStandings18 = selected_dfStandings18[:15000]\n",
    "FPDataStandings19 = selected_dfStandings19[:15000]\n",
    "FPDataStandings20 = selected_dfStandings20[:15000]\n",
    "FPDataStandings21 = selected_dfStandings21[:15000]\n",
    "FPDataStandings22 = selected_dfStandings22[:15000]\n",
    "\n",
    "SIDataStanding1 = np.array(SIDatasStanding1[:15000]).astype('float32')\n",
    "SIDataStanding2 = np.array(SIDatasStanding2[:15000]).astype('float32')\n",
    "SIDataStanding3 = np.array(SIDatasStanding3[:15000]).astype('float32')\n",
    "SIDataStanding4 = np.array(SIDatasStanding4[:15000]).astype('float32')\n",
    "SIDataStanding5 = np.array(SIDatasStanding5[:15000]).astype('float32')\n",
    "SIDataStanding6 = np.array(SIDatasStanding6[:15000]).astype('float32')\n",
    "SIDataStanding7 = np.array(SIDatasStanding7[:15000]).astype('float32')\n",
    "SIDataStanding8 = np.array(SIDatasStanding8[:15000]).astype('float32')\n",
    "SIDataStanding9 = np.array(SIDatasStanding9[:15000]).astype('float32')\n",
    "SIDataStanding10 = np.array(SIDatasStanding10[:15000]).astype('float32')\n",
    "SIDataStanding11 = np.array(SIDatasStanding11[:15000]).astype('float32')\n",
    "SIDataStanding12 = np.array(SIDatasStanding12[:15000]).astype('float32')\n",
    "SIDataStanding13 = np.array(SIDatasStanding13[:15000]).astype('float32')\n",
    "SIDataStanding14 = np.array(SIDatasStanding14[:15000]).astype('float32')\n",
    "SIDataStanding15 = np.array(SIDatasStanding15[:15000]).astype('float32')\n",
    "SIDataStanding16 = np.array(SIDatasStanding16[:15000]).astype('float32')\n",
    "SIDataStanding17 = np.array(SIDatasStanding17[:15000]).astype('float32')\n",
    "SIDataStanding18 = np.array(SIDatasStanding18[:15000]).astype('float32')\n",
    "SIDataStanding19 = np.array(SIDatasStanding19[:15000]).astype('float32')\n",
    "SIDataStanding20 = np.array(SIDatasStanding20[:15000]).astype('float32')\n",
    "SIDataStanding21 = np.array(SIDatasStanding21[:15000]).astype('float32')\n",
    "SIDataStanding22 = np.array(SIDatasStanding22[:15000]).astype('float32')\n",
    "FPDataStanding1 = np.array(FPDataStandings1).astype('float32')\n",
    "FPDataStanding2 = np.array(FPDataStandings2).astype('float32')\n",
    "FPDataStanding3= np.array(FPDataStandings3).astype('float32')\n",
    "FPDataStanding4= np.array(FPDataStandings4).astype('float32')\n",
    "FPDataStanding5= np.array(FPDataStandings5).astype('float32')\n",
    "FPDataStanding6= np.array(FPDataStandings6).astype('float32')\n",
    "FPDataStanding7= np.array(FPDataStandings7).astype('float32')\n",
    "FPDataStanding8= np.array(FPDataStandings8).astype('float32')\n",
    "FPDataStanding9= np.array(FPDataStandings9).astype('float32')\n",
    "FPDataStanding10 = np.array(FPDataStandings10).astype('float32')\n",
    "FPDataStanding11 = np.array(FPDataStandings11).astype('float32')\n",
    "FPDataStanding12= np.array(FPDataStandings12).astype('float32')\n",
    "FPDataStanding13= np.array(FPDataStandings13).astype('float32')\n",
    "FPDataStanding14= np.array(FPDataStandings14).astype('float32')\n",
    "FPDataStanding15= np.array(FPDataStandings15).astype('float32')\n",
    "FPDataStanding16= np.array(FPDataStandings16).astype('float32')\n",
    "FPDataStanding17= np.array(FPDataStandings17).astype('float32')\n",
    "FPDataStanding18= np.array(FPDataStandings18).astype('float32')\n",
    "FPDataStanding19= np.array(FPDataStandings19).astype('float32')\n",
    "FPDataStanding20= np.array(FPDataStandings20).astype('float32')\n",
    "FPDataStanding21= np.array(FPDataStandings21).astype('float32')\n",
    "FPDataStanding22= np.array(FPDataStandings22).astype('float32')\n",
    "\n",
    "SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3,\n",
    "                            SIDataStanding4, SIDataStanding5, SIDataStanding6,\n",
    "#                             SIDataStanding7, SIDataStanding8, SIDataStanding9,\n",
    "                            SIDataStanding8, SIDataStanding9,\n",
    "                            SIDataStanding10, SIDataStanding11, SIDataStanding12,\n",
    "                            SIDataStanding13, SIDataStanding14, SIDataStanding15,\n",
    "                            SIDataStanding16, SIDataStanding17, SIDataStanding18,\n",
    "                            SIDataStanding19, SIDataStanding20, SIDataStanding21), axis=0)\n",
    "\n",
    "# SIDatasetStanding = np.concatenate((SIDataStanding13, SIDataStanding20, SIDataStanding17, \n",
    "#                        SIDataStanding15, SIDataStanding12, SIDataStanding22, SIDataStanding1, SIDataStanding4, SIDataStanding8, \n",
    "#                        SIDataStanding16, SIDataStanding9, SIDataStanding6, SIDataStanding7, SIDataStanding3,\n",
    "#                        SIDataStanding19, SIDataStanding10), axis=0)\n",
    "\n",
    "# SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3), axis=0)\n",
    "# FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3), axis=0)\n",
    "                        \n",
    "FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3,\n",
    "                            FPDataStanding4, FPDataStanding5, FPDataStanding6,\n",
    "#                             FPDataStanding7, FPDataStanding8, FPDataStanding9,\n",
    "                            FPDataStanding8, FPDataStanding9,\n",
    "                            FPDataStanding10, FPDataStanding11, FPDataStanding12,\n",
    "                            FPDataStanding13, FPDataStanding14, FPDataStanding15,\n",
    "                            FPDataStanding16, FPDataStanding17, FPDataStanding18,\n",
    "                            FPDataStanding19, FPDataStanding20, FPDataStanding21), axis=0)\n",
    "\n",
    "# FPDatasetStanding = np.concatenate((FPDataStanding13, FPDataStanding20, FPDataStanding17, \n",
    "#                        FPDataStanding15, FPDataStanding12, FPDataStanding22, FPDataStanding1, FPDataStanding4, FPDataStanding8, \n",
    "#                        FPDataStanding16, FPDataStanding9, FPDataStanding6, FPDataStanding7, FPDataStanding3,\n",
    "#                        FPDataStanding19, FPDataStanding10), axis=0)\n",
    "\n",
    "SIDatasetStanding = SIDatasetStanding\n",
    "FPDatasetStanding = FPDatasetStanding\n",
    "\n",
    "SIDatasetStanding = np.array(SIDatasetStanding).astype('float32')\n",
    "FPDatasetStanding = np.array(FPDatasetStanding).astype('float32')\n",
    "\n",
    "# Concat Standing and Walking\n",
    "# SIDataset = np.concatenate((SIDatasetWalking,SIDatasetStanding), axis=0)\n",
    "# FPDataset = np.concatenate((FPDatasetWalking,FPDatasetStanding), axis=0)\n",
    "# SIDataset = SIDatasetStanding\n",
    "# FPDataset = FPDatasetStanding\n",
    "\n",
    "SIDataset = SIDataStanding1\n",
    "FPDataset = FPDataStanding1\n",
    "\n",
    "\n",
    "# Data Cleaning: Remove or correct mislabeled instances in your dataset\n",
    "# outlier_detector = LocalOutlierFactor(novelty=True)\n",
    "# outlier_detector.fit(FPDataset)\n",
    "# outlier_mask = outlier_detector.predict(FPDataset)\n",
    "# cleaned_smart_insole_data_scaled = SIDataset[outlier_mask == 1]\n",
    "# cleaned_force_plate_data_scaled = FPDataset[outlier_mask == 1]\n",
    "\n",
    "\n",
    "## End Load Data\n",
    "for i in range(len(SIDataset)):\n",
    "    SIDataset[i][0] = np.round(SIDataset[i][0] + (iter % max_iter) + 1,0)\n",
    "    iter += 1\n",
    "    \n",
    "FPDataPreAdjusted = FPDataset.copy()\n",
    "for i in range(len(FPDataPreAdjusted)):\n",
    "    # FPDataPreAdjusted[i][0] = FPDataPreAdjusted[i][0] + (iter % max_iter) + 1\n",
    "    FPDataPreAdjusted[i][0] = FPDataPreAdjusted[i][0] + ((iter % max_iter) + 1) * 1.5\n",
    "    iter += 1\n",
    "\n",
    "    \n",
    "     \n",
    "# Data Normalization\n",
    "# scaler_SI = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_SI.fit(SIData_filtered)\n",
    "# scaler_fx = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_fx.fit(FPDataset[:, 0].reshape(-1, 1))\n",
    "# scaler_fy = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_fy.fit(FPDataset[:, 1].reshape(-1, 1))\n",
    "# scaler_fz = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_fz.fit(FPDataset[:, 2].reshape(-1, 1))\n",
    "# scaler_mx = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_mx.fit(FPDataset[:, 3].reshape(-1, 1))\n",
    "# scaler_my = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_my.fit(FPDataset[:, 4].reshape(-1, 1))\n",
    "# scaler_mz = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_mz.fit(FPDataset[:, 5].reshape(-1, 1))\n",
    "\n",
    "# Normalize each feature separately\n",
    "# normalized_SIData = scaler_SI.transform(SIData_filtered)\n",
    "# normalized_fx = scaler_fx.transform(FPDataset[:, 0].reshape(-1, 1))\n",
    "# normalized_fy = scaler_fy.transform(FPDataset[:, 1].reshape(-1, 1))\n",
    "# normalized_fz = scaler_fz.transform(FPDataset[:, 2].reshape(-1, 1))\n",
    "# normalized_mx = scaler_mx.transform(FPDataset[:, 3].reshape(-1, 1))\n",
    "# normalized_my = scaler_my.transform(FPDataset[:, 4].reshape(-1, 1))\n",
    "# normalized_mz = scaler_mz.transform(FPDataset[:, 5].reshape(-1, 1))\n",
    "\n",
    "scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_x.fit(cleaned_smart_insole_data_scaled)\n",
    "xscale = scaler_x.transform(cleaned_smart_insole_data_scaled)\n",
    "\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y.fit(FPDataPreAdjusted)\n",
    "yscale = scaler_y.transform(FPDataPreAdjusted)\n",
    "\n",
    "\n",
    "# Combine the normalized features back into a single numpy array\n",
    "# normalized_FPData= np.concatenate((normalized_fx, normalized_fy, normalized_fz, \n",
    "#                                               normalized_mx, normalized_my, normalized_mz), axis=1)\n",
    "#End Data Normalization\n",
    "\n",
    "#Spliting Data\n",
    "sample_size = xscale.shape[0] # number of samples in train set\n",
    "time_steps  = xscale.shape[1] # number of features in train set\n",
    "input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "train_data_reshaped = xscale.reshape(sample_size,time_steps,input_dimension)\n",
    "\n",
    "# Generate random indices for shuffling the data\n",
    "indices = np.arange(train_data_reshaped.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Use the shuffled indices to randomly select training data\n",
    "X_train = train_data_reshaped[indices[:]]\n",
    "y_train = yscale[indices[:]]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data_reshaped, normalized_fx, test_size=0.20, random_state=2)\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "# print(y_train.shape,y_test.shape)\n",
    "#End Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPDataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPDataPreAdjusted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,1):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,FPDataPreAdjusted[15000:18000,i],color='red')\n",
    "#     plt.plot(x,y_pred[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FPDataset[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SIDataset[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPDataset[50:55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6IOf_sFx5Dm"
   },
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFqNbe_vch4u"
   },
   "outputs": [],
   "source": [
    "\"Configurations for ResNet in Regression Mode\"\n",
    "length = X_train.shape[1]   # Number of Features (or length of the signal)\n",
    "model_width = 64           # Number of Filter or Kernel in the Input Layer\n",
    "num_channel = 1             # Number of Input Channels\n",
    "problem_type = 'Regression' # Regression or Classification\n",
    "output_number = 1           # Number of Outputs in the Regression Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1L543Qc_x7AB"
   },
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nq-4BfWjcSHf"
   },
   "outputs": [],
   "source": [
    "class AdamW(Adam):\n",
    "    def __init__(self, learning_rate=0.0001, weight_decay=0.01, **kwargs):\n",
    "        super(AdamW, self).__init__(learning_rate, **kwargs)\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def get_gradients(self, loss, params):\n",
    "        gradients = super(AdamW, self).get_gradients(loss, params)\n",
    "        if self.weight_decay > 0.0:\n",
    "            for i in range(len(gradients)):\n",
    "                if gradients[i] is not None:\n",
    "                    gradients[i] += self.weight_decay * params[i]\n",
    "        return gradients\n",
    "\n",
    "Regression_Model = ResNet(length, num_channel, model_width, problem_type=problem_type, output_nums=output_number).ResNet18() # Build Model\n",
    "# ResNet Models supported: ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, \n",
    "Regression_Model.compile(loss='mse', optimizer=AdamW(learning_rate=0.0001, weight_decay=0.01), metrics= ['mse']) # Compile Model\n",
    "# Here, Model validation metric is set as Mean Squared Error or MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nu7h2qmWx-Jg"
   },
   "source": [
    "Model_Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLz469jDhJWx",
    "outputId": "85690d69-f6cf-4e1f-964e-112af4accc6c"
   },
   "outputs": [],
   "source": [
    "Regression_Model.summary() # Summary of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vHdlpJFx_14"
   },
   "source": [
    "Upload Past Weights if available (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSW2BfUMqs7A"
   },
   "outputs": [],
   "source": [
    "# Regression_Model.load_weights('Saved_Model.h5') # Load Previously Trained Weights for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSicHIFzyCky"
   },
   "source": [
    "Train Model for 'n' number of Epochs with Batch size of 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuaVIjBviw7n",
    "outputId": "751c008c-6b1c-4fd8-d84c-05467ed173e9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Early Stopping and Model_Checkpoints are optional parameters\n",
    "# Early Stopping is to stop the training based on certain condition set by the user\n",
    "# Model Checkpoint is to save a model in a directory basped on certain conditions so that it can be used later for Transfer Learning or avoiding retraining\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=30, mode='min'), ModelCheckpoint('Saved_Model.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
    "history = Regression_Model.fit(X_train, y_train, epochs=500, batch_size=64, verbose=1, validation_split=0.2, shuffle=True)\n",
    "# Save 'History' of the model for model performance analysis performed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3ydNmIKFJqv"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.keras.models.save_model(Regression_Model, 'Resnet18_StandnoWav.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model with custom_objects\n",
    "# import tensorflow as tf\n",
    "# class AdamW(Adam):\n",
    "#     def __init__(self, learning_rate=0.0001, weight_decay=0.01, **kwargs):\n",
    "#         super(AdamW, self).__init__(learning_rate, **kwargs)\n",
    "#         self.weight_decay = weight_decay\n",
    "\n",
    "#     def get_gradients(self, loss, params):\n",
    "#         gradients = super(AdamW, self).get_gradients(loss, params)\n",
    "#         if self.weight_decay > 0.0:\n",
    "#             for i in range(len(gradients)):\n",
    "#                 if gradients[i] is not None:\n",
    "#                     gradients[i] += self.weight_decay * params[i]\n",
    "#         return gradients\n",
    "# custom_objects = {'AdamW': AdamW}\n",
    "# RR = tf.keras.models.load_model('Resnet18_StandnoWav.h5', custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rejbOtGN-ixL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7rTwvEAos2fB",
    "outputId": "4191163c-57a5-4ed6-d3af-b5dbf3593950"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Evaluate Model\n",
    "Regression_Model.evaluate(X_train, y_train)\n",
    "ypred = Regression_Model.predict(X_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.show()\n",
    "plt.savefig('Loss Result.png')\n",
    "\n",
    "# print('MSE: ',mean_squared_error(normalized_FPData, ypred))\n",
    "# print('RMSE: ',math.sqrt(mean_squared_error(normalized_FPData, ypred)))\n",
    "# print('Coefficient of determination (r2 Score): ', r2_score(normalized_FPData, ypred))\n",
    "\n",
    "\n",
    "#Inverse\n",
    "# fx_real = scaler_fx.inverse_transform(normalized_fx)\n",
    "# fy_real = scaler_fy.inverse_transform(normalized_fy)\n",
    "# fz_real = scaler_fz.inverse_transform(normalized_fz)\n",
    "# mx_real = scaler_mx.inverse_transform(normalized_mx)\n",
    "# my_real = scaler_my.inverse_transform(normalized_my)\n",
    "# mz_real = scaler_mz.inverse_transform(normalized_mz)\n",
    "\n",
    "# fx_pred = scaler_fx.inverse_transform(ypred[:,0].reshape(-1,1))\n",
    "# fy_pred = scaler_fy.inverse_transform(ypred[:,1].reshape(-1,1))\n",
    "# fz_pred = scaler_fz.inverse_transform(ypred[:,2].reshape(-1,1))\n",
    "# mx_pred = scaler_mx.inverse_transform(ypred[:,3].reshape(-1,1))\n",
    "# my_pred = scaler_my.inverse_transform(ypred[:,4].reshape(-1,1))\n",
    "# mz_pred = scaler_mz.inverse_transform(ypred[:,5].reshape(-1,1))\n",
    "\n",
    "y_pred = scaler_y.inverse_transform(ypred) \n",
    "y_real = scaler_y.inverse_transform(yscale)\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,1):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,y_real[0:3000,i],color='red')\n",
    "    plt.plot(x,y_pred[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# Adjusting the values of FPDataBack\n",
    "FPDataRealBack = y_real.copy()\n",
    "for i in range(len(FPDataRealBack)):\n",
    "    # FPDataRealBack[i][0] = FPDataRealBack[i][0] - (iter % max_iter) - 1\n",
    "    FPDataRealBack[i][0] = FPDataRealBack[i][0] - ((iter % max_iter) + 1) * 1.5\n",
    "    iter += 1\n",
    "\n",
    "FPDataPredBack = y_pred.copy()\n",
    "for i in range(len(FPDataPredBack)):\n",
    "    # FPDataPredBack[i][0] = FPDataPredBack[i][0] - (iter % max_iter) - 1\n",
    "    FPDataPredBack[i][0] = FPDataPredBack[i][0] - ((iter % max_iter) + 1) * 1.5\n",
    "    iter += 1\n",
    "\n",
    "# FPReal = np.concatenate((fx_real, fy_real, fz_real, mx_real, my_real, mz_real), axis=1)\n",
    "# FPPred = np.concatenate((fx_pred, fy_pred, fz_pred, mx_pred, my_pred, mz_pred), axis=1)\n",
    "\n",
    "y_inverse = FPDataRealBack\n",
    "y_pred_inverse = FPDataPredBack\n",
    "\n",
    "\n",
    "# for i in range(len(y_pred_inverse)):\n",
    "#     if (np.abs(y_pred_inverse[i]) < 1).all():\n",
    "#         y_pred_inverse[i] = 0\n",
    "\n",
    "# for i in range(0, y_pred_inverse.shape[0], 50):\n",
    "#     zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "#     non_zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "#     if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "#         y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "print('MSE: ',mean_squared_error(y_inverse, y_pred_inverse))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(y_inverse, y_pred_inverse)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(y_inverse, y_pred_inverse))\n",
    "\n",
    "# restore to original Data\n",
    "new_inverse2 = y_inverse\n",
    "new_inverse3 = y_pred_inverse\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,1):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# # COP\n",
    "# from math import*\n",
    "# np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# out_Fz = new_inverse2[:,2]\n",
    "# out_Mx = new_inverse2[:,3]\n",
    "# out_My = new_inverse2[:,4]\n",
    "# Pred_Fz = new_inverse3[:,2]\n",
    "# Pred_Mx = new_inverse3[:,3]\n",
    "# Pred_My = new_inverse3[:,4]\n",
    "\n",
    "# Pred_COPx=[]\n",
    "# for i in range(0,len(Pred_Fz)):\n",
    "#   Pred_COPx_temp=-(Pred_My[i])/Pred_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if Pred_COPx_temp != Pred_COPx_temp:\n",
    "#     Pred_COPx_temp=0\n",
    "#   Pred_COPx.append(Pred_COPx_temp)\n",
    "#   # break\n",
    "\n",
    "# out_COPx=[]\n",
    "# for i in range(0,len(out_Fz)):\n",
    "#   out_COPx_temp=-(out_My[i])/out_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if out_COPx_temp != out_COPx_temp:\n",
    "#     out_COPx_temp=0\n",
    "#   out_COPx.append(out_COPx_temp)\n",
    "#   # break\n",
    "\n",
    "# Pred_COPy=[]\n",
    "# for i in range(0,len(Pred_Mx)):\n",
    "#   Pred_COPy_temp=Pred_Mx[i]/Pred_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if Pred_COPy_temp != Pred_COPy_temp:\n",
    "#     Pred_COPy_temp=0\n",
    "#   Pred_COPy.append(Pred_COPy_temp)\n",
    "#   # break\n",
    "\n",
    "# out_COPy=[]\n",
    "# for i in range(0,len(out_Mx)):\n",
    "#   out_COPy_temp=out_Mx[i]/out_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if out_COPy_temp != out_COPy_temp:\n",
    "#     out_COPy_temp=0\n",
    "#   out_COPy.append(out_COPy_temp)\n",
    "#   # break\n",
    "\n",
    "\n",
    "# # out_COPx = -(out_My)/out_Fz\n",
    "# out_COPx = np.array(out_COPx)\n",
    "# out_COPx= out_COPx.reshape(-1,1)\n",
    "\n",
    "# # out_COPy = out_Mx/out_Fz\n",
    "# out_COPy = np.array(out_COPy)\n",
    "# out_COPy= out_COPy.reshape(-1,1)\n",
    "\n",
    "# # Pred_COPx = -(Pred_My)/Pred_Fz\n",
    "# Pred_COPx = np.array(Pred_COPx)\n",
    "# Pred_COPx= Pred_COPx.reshape(-1,1)\n",
    "\n",
    "# # Pred_COPy = Pred_Mx/Pred_Fz\n",
    "# Pred_COPy = np.array(Pred_COPy)\n",
    "# Pred_COPy= Pred_COPy.reshape(-1,1)\n",
    "\n",
    "# Pred_COP = np.concatenate((Pred_COPx, Pred_COPy), axis=1)\n",
    "# FC_COP = np.concatenate((out_COPx, out_COPy), axis=1)\n",
    "\n",
    "# col_COP = 'COPx', 'COPy'\n",
    "\n",
    "# x=[]\n",
    "# colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "# colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "# x = np.arange(0,2000)*40/2000 \n",
    "# for i in range(0,2):\n",
    "#     plt.figure(figsize=(15,6))\n",
    "#     plt.plot(x,FC_COP[0:2000,i], color='red')\n",
    "#     plt.plot(x,Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "#     plt.title('COP Calculation (Training Data)')\n",
    "#     plt.ylabel(col_COP[i])\n",
    "#     plt.xlabel('Time(s)')\n",
    "#     plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "#     plt.savefig('Regression Result.png'[i])\n",
    "#     plt.show()\n",
    "\n",
    "# # Trajectory\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# x = range(50)\n",
    "# y1 = FC_COP[50:100,0]\n",
    "# y2 = FC_COP[50:100,1]\n",
    "# y3 = Pred_COP[50:100,0]\n",
    "# y4 = Pred_COP[50:100,1]\n",
    "\n",
    "# # pyplot.figure(figsize=(15,6))\n",
    "# # pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# # pyplot.show()\n",
    "\n",
    "# data_filter = abs(y1) > 0\n",
    "# data_filter2 = abs(y3) > 0\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(y1[data_filter], y2[data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(y3[data_filter2], y4[data_filter2 ], color='green')\n",
    "# # pyplot.plot(y1, y2, color='red')\n",
    "# # pyplot.plot(y3, y4, color='green')\n",
    "# plt.title('COP Trajectory (Training Data)')\n",
    "# pyplot.ylabel('COPy (mm)')\n",
    "# pyplot.xlabel('COPx (mm)')\n",
    "# pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Evaluate Model\n",
    "Regression_Model.evaluate(X_train, y_train)\n",
    "ypred = Regression_Model.predict(X_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.show()\n",
    "plt.savefig('Loss Result.png')\n",
    "\n",
    "# print('MSE: ',mean_squared_error(normalized_FPData, ypred))\n",
    "# print('RMSE: ',math.sqrt(mean_squared_error(normalized_FPData, ypred)))\n",
    "# print('Coefficient of determination (r2 Score): ', r2_score(normalized_FPData, ypred))\n",
    "\n",
    "\n",
    "#Inverse\n",
    "# fx_real = scaler_fx.inverse_transform(normalized_fx)\n",
    "# fy_real = scaler_fy.inverse_transform(normalized_fy)\n",
    "# fz_real = scaler_fz.inverse_transform(normalized_fz)\n",
    "# mx_real = scaler_mx.inverse_transform(normalized_mx)\n",
    "# my_real = scaler_my.inverse_transform(normalized_my)\n",
    "# mz_real = scaler_mz.inverse_transform(normalized_mz)\n",
    "\n",
    "# fx_pred = scaler_fx.inverse_transform(ypred[:,0].reshape(-1,1))\n",
    "# fy_pred = scaler_fy.inverse_transform(ypred[:,1].reshape(-1,1))\n",
    "# fz_pred = scaler_fz.inverse_transform(ypred[:,2].reshape(-1,1))\n",
    "# mx_pred = scaler_mx.inverse_transform(ypred[:,3].reshape(-1,1))\n",
    "# my_pred = scaler_my.inverse_transform(ypred[:,4].reshape(-1,1))\n",
    "# mz_pred = scaler_mz.inverse_transform(ypred[:,5].reshape(-1,1))\n",
    "\n",
    "y_pred = scaler_y.inverse_transform(ypred) \n",
    "y_real = scaler_y.inverse_transform(yscale)\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,1):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,y_real[0:3000,i],color='red')\n",
    "    plt.plot(x,y_pred[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# Adjusting the values of FPDataBack\n",
    "FPDataRealBack = y_real.copy()\n",
    "for i in range(len(FPDataRealBack)):\n",
    "    # FPDataRealBack[i][0] = FPDataRealBack[i][0] - (iter % max_iter) - 1\n",
    "    FPDataRealBack[i][0] = FPDataRealBack[i][0] - ((iter % max_iter) + 1) * 1.5\n",
    "    iter += 1\n",
    "\n",
    "FPDataPredBack = y_pred.copy()\n",
    "for i in range(len(FPDataPredBack)):\n",
    "    # FPDataPredBack[i][0] = FPDataPredBack[i][0] - (iter % max_iter) - 1\n",
    "    FPDataPredBack[i][0] = FPDataPredBack[i][0] - ((iter % max_iter) + 1) * 1.5\n",
    "    iter += 1\n",
    "\n",
    "# FPReal = np.concatenate((fx_real, fy_real, fz_real, mx_real, my_real, mz_real), axis=1)\n",
    "# FPPred = np.concatenate((fx_pred, fy_pred, fz_pred, mx_pred, my_pred, mz_pred), axis=1)\n",
    "\n",
    "y_inverse = FPDataRealBack\n",
    "y_pred_inverse = FPDataPredBack\n",
    "\n",
    "\n",
    "# for i in range(len(y_pred_inverse)):\n",
    "#     if (np.abs(y_pred_inverse[i]) < 1).all():\n",
    "#         y_pred_inverse[i] = 0\n",
    "\n",
    "# for i in range(0, y_pred_inverse.shape[0], 50):\n",
    "#     zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "#     non_zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "#     if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "#         y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "print('MSE: ',mean_squared_error(FPDataRealBack, FPDataPredBack))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(FPDataRealBack, FPDataPredBack)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(FPDataRealBack, FPDataPredBack))\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,1):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,FPDataRealBack[0:3000,i],color='red')\n",
    "    plt.plot(x,FPDataPredBack[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# # COP\n",
    "# from math import*\n",
    "# np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# out_Fz = new_inverse2[:,2]\n",
    "# out_Mx = new_inverse2[:,3]\n",
    "# out_My = new_inverse2[:,4]\n",
    "# Pred_Fz = new_inverse3[:,2]\n",
    "# Pred_Mx = new_inverse3[:,3]\n",
    "# Pred_My = new_inverse3[:,4]\n",
    "\n",
    "# Pred_COPx=[]\n",
    "# for i in range(0,len(Pred_Fz)):\n",
    "#   Pred_COPx_temp=-(Pred_My[i])/Pred_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if Pred_COPx_temp != Pred_COPx_temp:\n",
    "#     Pred_COPx_temp=0\n",
    "#   Pred_COPx.append(Pred_COPx_temp)\n",
    "#   # break\n",
    "\n",
    "# out_COPx=[]\n",
    "# for i in range(0,len(out_Fz)):\n",
    "#   out_COPx_temp=-(out_My[i])/out_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if out_COPx_temp != out_COPx_temp:\n",
    "#     out_COPx_temp=0\n",
    "#   out_COPx.append(out_COPx_temp)\n",
    "#   # break\n",
    "\n",
    "# Pred_COPy=[]\n",
    "# for i in range(0,len(Pred_Mx)):\n",
    "#   Pred_COPy_temp=Pred_Mx[i]/Pred_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if Pred_COPy_temp != Pred_COPy_temp:\n",
    "#     Pred_COPy_temp=0\n",
    "#   Pred_COPy.append(Pred_COPy_temp)\n",
    "#   # break\n",
    "\n",
    "# out_COPy=[]\n",
    "# for i in range(0,len(out_Mx)):\n",
    "#   out_COPy_temp=out_Mx[i]/out_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if out_COPy_temp != out_COPy_temp:\n",
    "#     out_COPy_temp=0\n",
    "#   out_COPy.append(out_COPy_temp)\n",
    "#   # break\n",
    "\n",
    "\n",
    "# # out_COPx = -(out_My)/out_Fz\n",
    "# out_COPx = np.array(out_COPx)\n",
    "# out_COPx= out_COPx.reshape(-1,1)\n",
    "\n",
    "# # out_COPy = out_Mx/out_Fz\n",
    "# out_COPy = np.array(out_COPy)\n",
    "# out_COPy= out_COPy.reshape(-1,1)\n",
    "\n",
    "# # Pred_COPx = -(Pred_My)/Pred_Fz\n",
    "# Pred_COPx = np.array(Pred_COPx)\n",
    "# Pred_COPx= Pred_COPx.reshape(-1,1)\n",
    "\n",
    "# # Pred_COPy = Pred_Mx/Pred_Fz\n",
    "# Pred_COPy = np.array(Pred_COPy)\n",
    "# Pred_COPy= Pred_COPy.reshape(-1,1)\n",
    "\n",
    "# Pred_COP = np.concatenate((Pred_COPx, Pred_COPy), axis=1)\n",
    "# FC_COP = np.concatenate((out_COPx, out_COPy), axis=1)\n",
    "\n",
    "# col_COP = 'COPx', 'COPy'\n",
    "\n",
    "# x=[]\n",
    "# colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "# colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "# x = np.arange(0,2000)*40/2000 \n",
    "# for i in range(0,2):\n",
    "#     plt.figure(figsize=(15,6))\n",
    "#     plt.plot(x,FC_COP[0:2000,i], color='red')\n",
    "#     plt.plot(x,Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "#     plt.title('COP Calculation (Training Data)')\n",
    "#     plt.ylabel(col_COP[i])\n",
    "#     plt.xlabel('Time(s)')\n",
    "#     plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "#     plt.savefig('Regression Result.png'[i])\n",
    "#     plt.show()\n",
    "\n",
    "# # Trajectory\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# x = range(50)\n",
    "# y1 = FC_COP[50:100,0]\n",
    "# y2 = FC_COP[50:100,1]\n",
    "# y3 = Pred_COP[50:100,0]\n",
    "# y4 = Pred_COP[50:100,1]\n",
    "\n",
    "# # pyplot.figure(figsize=(15,6))\n",
    "# # pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# # pyplot.show()\n",
    "\n",
    "# data_filter = abs(y1) > 0\n",
    "# data_filter2 = abs(y3) > 0\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(y1[data_filter], y2[data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(y3[data_filter2], y4[data_filter2 ], color='green')\n",
    "# # pyplot.plot(y1, y2, color='red')\n",
    "# # pyplot.plot(y3, y4, color='green')\n",
    "# plt.title('COP Trajectory (Training Data)')\n",
    "# pyplot.ylabel('COPy (mm)')\n",
    "# pyplot.xlabel('COPx (mm)')\n",
    "# pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,1):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,FPDataRealBack[0:3000,i],color='red')\n",
    "    plt.plot(x,FPDataPredBack[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_real[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPDataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPDataRealBack[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ao = pd.read_csv('0312AbiStand5Min1.txt', header=None, low_memory=False)\n",
    "AoE = np.asarray(Ao)\n",
    "Test_AoE = np.array(AoE[3000:6000]).astype('float32')\n",
    "\n",
    "Test_Insole = pd.read_csv('0312AbiStand5Min1.txt', header=None, low_memory=False)\n",
    "TestSIData = np.asarray(Test_Insole)\n",
    "\n",
    "Test_df = pd.read_csv('0312AbiStand5Min1.csv', low_memory=False)\n",
    "Test_selected_df = Test_df[columns]\n",
    "Test_FPDatas = Test_selected_df[3000:6000]\n",
    "\n",
    "Test_SmartInsole = np.array(TestSIData[3000:6000]).astype('float32')\n",
    "Test_FPData = np.array(Test_FPDatas).astype('float32')\n",
    "\n",
    "Test_FPDataPreAdjusted = Test_FPData.copy()\n",
    "for i in range(len(Test_FPDataPreAdjusted)):\n",
    "    # Test_FPDataPreAdjusted[i][0] = Test_FPDataPreAdjusted[i][0] + (iter % max_iter) + 1\n",
    "    Test_FPDataPreAdjusted[i][0] = Test_FPDataPreAdjusted[i][0] + ((iter % max_iter) + 1) * 1.5\n",
    "    iter += 1\n",
    "\n",
    "# # Create a mask for the zero positions in A\n",
    "# mask = Test_AoE[:3000] == 0\n",
    "\n",
    "# # Apply the mask to B to keep the same zero positions\n",
    "# Test_SmartInsole = np.where(mask, 0, Test_SmartInsole)\n",
    "\n",
    "# # Fill missing numbers in B based on the non-zero values in A\n",
    "# Test_SmartInsole = np.where(Test_SmartInsole == 0, Test_AoE[:3000], Test_SmartInsole)\n",
    "\n",
    "\n",
    "for i in range(len(Test_SmartInsole)):\n",
    "    Test_SmartInsole[i][0] = Test_SmartInsole[i][0] + (iter % max_iter) + 1\n",
    "    iter += 1\n",
    "    \n",
    "print(Test_AoE[1])\n",
    "print(Test_SmartInsole[1])\n",
    "\n",
    "# Test_smart_insole_data_scaled = (Test_SmartInsole - minInsole) / (maxInsole - minInsole)\n",
    "# Test_force_plate_data_scaled = (Test_FPData - minForcePlate) / (maxForcePlate - minForcePlate)\n",
    "Test_smart_insole_data_scaled = scaler_x.transform(Test_SmartInsole)\n",
    "Test_force_plate_data_scaled = scaler_y.transform(Test_FPDataPreAdjusted)\n",
    "\n",
    "\n",
    "# Reshape testing data for model input\n",
    "Test_sample_size = Test_smart_insole_data_scaled.shape[0]\n",
    "Test_time_steps = Test_smart_insole_data_scaled.shape[1]\n",
    "Test_input_dimension = 1\n",
    "\n",
    "Test_train_data_reshaped = Test_smart_insole_data_scaled.reshape(Test_sample_size, Test_time_steps,\n",
    "                                                                 Test_input_dimension)\n",
    "\n",
    "# Load the best saved model\n",
    "# best_model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Evaluate the model on testing data\n",
    "test_loss, test_mse = Regression_Model.evaluate(Test_train_data_reshaped, Test_force_plate_data_scaled)\n",
    "print('Testing Loss:', test_loss)\n",
    "print('Testing MSE:', test_mse)\n",
    "\n",
    "# Make predictions on testing data\n",
    "test_predictions = Regression_Model.predict(Test_train_data_reshaped)\n",
    "\n",
    "# Inverse transform the predictions and actual values\n",
    "# test_predictions = (test_predictions * (maxForcePlate - minForcePlate)) + minForcePlate\n",
    "# cleaned_test_fp = (Test_force_plate_data_scaled * (maxForcePlate - minForcePlate)) + minForcePlate\n",
    "test_predictions = scaler_y.inverse_transform(test_predictions) \n",
    "cleaned_test_fp = scaler_y.inverse_transform(Test_force_plate_data_scaled)\n",
    "\n",
    "x = np.arange(0, test_predictions.shape[0]) * 60 / test_predictions.shape[0]\n",
    "for i in range(1):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(x, test_predictions[:, i], color='red')\n",
    "    plt.plot(x, cleaned_test_fp[:, i], markerfacecolor='none', color='green')\n",
    "    plt.title('ResNet Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "        plt.ylabel('Force/' + columns[i])\n",
    "    else:\n",
    "        plt.ylabel('Moment/' + columns[i])\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "Test_FPDataRealBack = cleaned_test_fp.copy()\n",
    "for i in range(len(Test_FPDataRealBack)):\n",
    "    # Test_FPDataRealBack[i][0] = Test_FPDataRealBack[i][0] - (iter % max_iter) - 1\n",
    "    Test_FPDataRealBack[i][0] = Test_FPDataRealBack[i][0] - ((iter % max_iter) + 1) * 1.5\n",
    "    iter += 1\n",
    "\n",
    "Test_FPDataPredBack = test_predictions.copy()\n",
    "for i in range(len(Test_FPDataPredBack)):\n",
    "    # Test_FPDataPredBack[i][0] = Test_FPDataPredBack[i][0] - (iter % max_iter) - 1\n",
    "    Test_FPDataPredBack[i][0] = Test_FPDataPredBack[i][0] - ((iter % max_iter) + 1) * 1.5\n",
    "    iter += 1\n",
    "\n",
    "# Plot predicted vs actual values for the first column\n",
    "x = np.arange(0, test_predictions.shape[0]) * 60 / test_predictions.shape[0]\n",
    "for i in range(1):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(x, Test_FPDataRealBack[:, i], color='red')\n",
    "    plt.plot(x, Test_FPDataPredBack[:, i], markerfacecolor='none', color='green')\n",
    "    plt.title('ResNet Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "        plt.ylabel('Force/' + columns[i])\n",
    "    else:\n",
    "        plt.ylabel('Moment/' + columns[i])\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_fp[:10]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
