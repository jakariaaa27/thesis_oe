{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zO2Iga6ra5G"
   },
   "source": [
    "# Training Data without adding number of sequnces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwJLcB8LrhkW",
    "outputId": "408bfc13-ea91-4d5b-ec5b-af3f7b1a6dd2"
   },
   "source": [
    "!pip install tensorflow-addons==0.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3R-37q8nadJS",
    "outputId": "2830d363-65c9-49c4-d99a-335a539114fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-addons==0.16.1\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer,MinMaxScaler,StandardScaler, RobustScaler, QuantileTransformer, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape,TimeDistributed,Input,LSTM,Activation,Dense,BatchNormalization, LeakyReLU, Conv2D, GlobalAveragePooling1D,MaxPooling2D, MaxPooling1D, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adadelta, Adagrad\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import zeros, newaxis\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import mutual_info_regression,SelectKBest\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import callbacks\n",
    "from keras.initializers import random_uniform\n",
    "np.set_printoptions(suppress=True)\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "%matplotlib inline\n",
    "from ResNet_1DCNN import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C9ZjsXWuZLRs"
   },
   "outputs": [],
   "source": [
    "## Load Data\n",
    "Insole = pd.read_csv('1225JakariaRWalk5Min.txt', header=None, low_memory=False)\n",
    "SIData =  np.array(Insole)\n",
    "\n",
    "df = pd.read_csv('1225JakariaRWalk5Min.csv', low_memory=False)\n",
    "columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "selected_df = df[columns]\n",
    "FPDatas = selected_df[:15000]\n",
    "\n",
    "SmartInsole = np.array(SIData[:15000]).astype('float64')\n",
    "FPData = np.array(FPDatas).astype('float64')\n",
    "\n",
    "FXData = FPData[:,0]\n",
    "FXData =  np.array(FXData)\n",
    "FXData = FXData.reshape(-1,1)\n",
    "FYData = FPData[:,1]\n",
    "FYData =  np.array(FYData)\n",
    "FYData = FYData.reshape(-1,1)\n",
    "FZData = (FPData[:,2])/10\n",
    "FZData =  np.array(FZData)\n",
    "FZData = FZData.reshape(-1,1)\n",
    "MXData = (FPData[:,3])/1000\n",
    "MXData =  np.array(MXData)\n",
    "MXData = MXData.reshape(-1,1)\n",
    "MYData = (FPData[:,4])/10000\n",
    "MYData =  np.array(MYData)\n",
    "MYData = MYData.reshape(-1,1)\n",
    "MZData = (FPData[:,5])/100\n",
    "MZData =  np.array(MZData)\n",
    "MZData = MZData.reshape(-1,1)\n",
    "\n",
    "newFPData = np.concatenate((FXData, FYData, FZData, MXData, MYData, MZData), axis=1)\n",
    "## End Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1XOmNRbry85T"
   },
   "outputs": [],
   "source": [
    "# # Jittering by adding random noise\n",
    "# n = 50\n",
    "\n",
    "# # create n random values\n",
    "# noise = np.random.normal(loc=0, scale=0.1, size=n)\n",
    "# noise = np.array(noise)\n",
    "# for i in range(n):\n",
    "#   noise[i] = noise[i] + i\n",
    "\n",
    "# # loop through rows in steps of n\n",
    "# for i in range(0, SmartInsole.shape[0], n):\n",
    "#     SmartInsole[i:i + n, 0] = np.clip(SmartInsole[i:i + 1, 0] + noise, a_min=0.0, a_max=None)\n",
    "\n",
    "max_iter = 50\n",
    "iter = 0\n",
    "for i in range(len(SmartInsole)):\n",
    "    SmartInsole[i][0] = SmartInsole[i][0] + (iter % max_iter) + 1\n",
    "    iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GruQ2Mw5Ptwu"
   },
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "minInsole = SmartInsole.min()\n",
    "maxInsole = SmartInsole.max()\n",
    "xscale = (SmartInsole - minInsole) / ( maxInsole - minInsole )\n",
    "\n",
    "FPmax = []\n",
    "FPmin = []\n",
    "yscale = []\n",
    "\n",
    "for i in range(0,6):\n",
    "    minFP = FPData[:,i].min()\n",
    "    maxFP = FPData[:,i].max()\n",
    "    FPmin.append(minFP)\n",
    "    FPmax.append(maxFP)\n",
    "\n",
    "FPmin = np.array(FPmin)\n",
    "FPmax = np.array(FPmax)\n",
    "\n",
    "for i in range(0,6):\n",
    "  scale = (FPData[:,i] - FPmin[i]) / ( FPmax[i] - FPmin[i] )\n",
    "  yscale.append(scale)\n",
    "yscale = np.array(yscale)\n",
    "yscale = yscale.transpose()\n",
    "#End Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-n_V9MYgPwac",
    "outputId": "3be98594-a09c-40ef-ce5a-3b6baf96c2d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 89, 1) (3000, 89, 1)\n",
      "(12000, 6) (3000, 6)\n"
     ]
    }
   ],
   "source": [
    "#Spliting Data\n",
    "sample_size = xscale.shape[0] # number of samples in train set\n",
    "time_steps  = xscale.shape[1] # number of features in train set\n",
    "input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "train_data_reshaped = xscale.reshape(sample_size,time_steps,input_dimension)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_reshaped, yscale, test_size=0.20, random_state=2)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n",
    "#End Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Configurations for ResNet in Regression Mode\"\n",
    "length = X_train.shape[1]   # Number of Features (or length of the signal)\n",
    "model_width = 64           # Number of Filter or Kernel in the Input Layer\n",
    "num_channel = 1             # Number of Input Channels\n",
    "problem_type = 'Regression' # Regression or Classification\n",
    "output_number = 6           # Number of Outputs in the Regression Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression_Model = ResNet(length, num_channel, model_width, problem_type=problem_type, output_nums=output_number).ResNet18() # Build Model\n",
    "# ResNet Models supported: ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, \n",
    "Regression_Model.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics= ['mse']) # Compile Model\n",
    "# Here, Model validation metric is set as Mean Squared Error or MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 89, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 45, 64)       512         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 45, 64)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 22, 64)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 22, 64)       12352       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 22, 64)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 22, 64)       12352       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 22, 64)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 22, 64)       0           ['activation_2[0][0]',           \n",
      "                                                                  'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 22, 64)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 22, 64)       12352       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 22, 64)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 22, 64)       12352       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 22, 64)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 22, 64)       0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 22, 64)       0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 11, 128)      24704       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 11, 128)      0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 11, 128)      49280       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 11, 128)      0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 11, 128)      49280       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 11, 128)      0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 11, 128)      49280       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 11, 128)      0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 11, 128)      0           ['activation_10[0][0]',          \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 11, 128)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 6, 256)       98560       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 6, 256)       0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 6, 256)       196864      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 6, 256)       0           ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 6, 256)       196864      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 6, 256)       0           ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 6, 256)       196864      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 6, 256)       0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 6, 256)       0           ['activation_15[0][0]',          \n",
      "                                                                  'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 6, 256)       0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 3, 512)       393728      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 3, 512)       0           ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_14 (Conv1D)             (None, 3, 512)       786944      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 3, 512)       0           ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 3, 512)       786944      ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 3, 512)       0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 3, 512)       786944      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 3, 512)       0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 3, 512)       0           ['activation_20[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 3, 512)       0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['activation_21[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            3078        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,669,254\n",
      "Trainable params: 3,669,254\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Regression_Model.summary() # Summary of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 4s 14ms/step - loss: 0.1946 - mse: 0.1946 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 23/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 24/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 25/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 26/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 27/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 28/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 29/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 30/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 31/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 32/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 33/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 34/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 35/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 36/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 37/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 38/500\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 39/500\n",
      " 37/150 [======>.......................] - ETA: 1s - loss: 0.0043 - mse: 0.0043"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=30, mode='min'), ModelCheckpoint('1Person_Walking_ResNet18.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
    "history = Regression_Model.fit(X_train, y_train, epochs=500, batch_size=64,\n",
    "                               verbose=1, validation_split=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "# history = Regression_Model.fit(X_train, y_train, batch_size=64, epochs=500,\n",
    "#                     validation_data=(X_test, y_test), verbose=2,\n",
    "#                     callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=30,verbose=2, mode='auto')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Model\n",
    "Regression_Model.evaluate(train_data_reshaped, yscale)\n",
    "ypred = Regression_Model.predict(train_data_reshaped)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.show()\n",
    "plt.savefig('Loss Result.png')\n",
    "\n",
    "print('MSE: ',mean_squared_error(yscale, ypred))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(yscale, ypred)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(yscale, ypred))\n",
    "\n",
    "\n",
    "#Inverse\n",
    "y_inverse = []\n",
    "y_pred_inverse = []\n",
    "\n",
    "for i in range(0,6):\n",
    "  Y_inver =  yscale[0:15000, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Pred_inver = ypred[0:15000, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  y_inverse.append(Y_inver)\n",
    "  y_pred_inverse.append(Pred_inver)\n",
    "y_inverse = np.array(y_inverse)\n",
    "y_inverse = y_inverse.transpose()\n",
    "y_pred_inverse = np.array(y_pred_inverse)\n",
    "y_pred_inverse = y_pred_inverse.transpose()\n",
    "\n",
    "for i in range(len(y_pred_inverse)):\n",
    "    if (np.abs(y_pred_inverse[i]) < 1).all():\n",
    "        y_pred_inverse[i] = 0\n",
    "\n",
    "print('MSE: ',mean_squared_error(y_inverse, y_pred_inverse))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(y_inverse, y_pred_inverse)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(y_inverse, y_pred_inverse))\n",
    "\n",
    "# restore to original Data\n",
    "# FXData2 = y_inverse[:,0]\n",
    "# FXData2=  np.array(FXData2)\n",
    "# FXData2 = FXData2.reshape(-1,1)\n",
    "\n",
    "# FYData2 = y_inverse[:,1]\n",
    "# FYData2 =  np.array(FYData2)\n",
    "# FYData2 = FYData2.reshape(-1,1)\n",
    "\n",
    "# FZData2 = (y_inverse[:,2]*10)\n",
    "# FZData2 =  np.array(FZData2)\n",
    "# FZData2 = FZData2.reshape(-1,1)\n",
    "\n",
    "# MXData2 = (y_inverse[:,3]*1000)\n",
    "# MXData2 =  np.array(MXData2)\n",
    "# MXData2 = MXData2.reshape(-1,1)\n",
    "\n",
    "# MYData2 = (y_inverse[:,4]*10000)\n",
    "# MYData2 =  np.array(MYData2)\n",
    "# MYData2 = MYData2.reshape(-1,1\n",
    "#                           )\n",
    "# MZData2 = (y_inverse[:,5]*100)\n",
    "# MZData2 =  np.array(MZData2)\n",
    "# MZData2 = MZData2.reshape(-1,1)\n",
    "\n",
    "# new_inverse2 = np.concatenate((FXData2, FYData2, FZData2, MXData2, MYData2, MZData2), axis=1)\n",
    "\n",
    "# FXData3 = y_pred_inverse[:,0]\n",
    "# FXData3=  np.array(FXData3)\n",
    "# FXData3 = FXData3.reshape(-1,1)\n",
    "\n",
    "# FYData3 = y_pred_inverse[:,1]\n",
    "# FYData3 =  np.array(FYData3)\n",
    "# FYData3 = FYData3.reshape(-1,1)\n",
    "\n",
    "# FZData3 = (y_pred_inverse[:,2]*10)\n",
    "# FZData3 =  np.array(FZData3)\n",
    "# FZData3 = FZData3.reshape(-1,1)\n",
    "\n",
    "# MXData3 = (y_pred_inverse[:,3]*1000)\n",
    "# MXData3 =  np.array(MXData3)\n",
    "# MXData3 = MXData3.reshape(-1,1)\n",
    "\n",
    "# MYData3 = (y_pred_inverse[:,4]*10000)\n",
    "# MYData3 =  np.array(MYData3)\n",
    "# MYData3 = MYData3.reshape(-1,1)\n",
    "\n",
    "# MZData3 = (y_pred_inverse[:,5]*100)\n",
    "# MZData3 =  np.array(MZData3)\n",
    "# MZData3 = MZData3.reshape(-1,1)\n",
    "\n",
    "# new_inverse3 = np.concatenate((FXData3, FYData3, FZData3, MXData3, MYData3, MZData3), axis=1)\n",
    "\n",
    "new_inverse2 = y_inverse\n",
    "new_inverse3 = y_pred_inverse\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000\n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('CNN Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Real value', 'Predicted Value'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "out_Fz = new_inverse2[0:15000,2]\n",
    "out_Mx = new_inverse2[0:15000,3]\n",
    "out_My = new_inverse2[0:15000,4]\n",
    "Pred_Fz = new_inverse3[0:15000,2]\n",
    "Pred_Mx = new_inverse3[0:15000,3]\n",
    "Pred_My = new_inverse3[0:15000,4]\n",
    "\n",
    "Pred_COPx=[]\n",
    "for i in range(0,len(Pred_Fz)):\n",
    "  Pred_COPx_temp=-(Pred_My[i])/Pred_Fz[i]\n",
    "  # print(temp)\n",
    "  if Pred_COPx_temp != Pred_COPx_temp:\n",
    "    Pred_COPx_temp=0\n",
    "  Pred_COPx.append(Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "out_COPx=[]\n",
    "for i in range(0,len(out_Fz)):\n",
    "  out_COPx_temp=-(out_My[i])/out_Fz[i]\n",
    "  # print(temp)\n",
    "  if out_COPx_temp != out_COPx_temp:\n",
    "    out_COPx_temp=0\n",
    "  out_COPx.append(out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Pred_COPy=[]\n",
    "for i in range(0,len(Pred_Mx)):\n",
    "  Pred_COPy_temp=Pred_Mx[i]/Pred_Fz[i]\n",
    "  # print(temp)\n",
    "  if Pred_COPy_temp != Pred_COPy_temp:\n",
    "    Pred_COPy_temp=0\n",
    "  Pred_COPy.append(Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "out_COPy=[]\n",
    "for i in range(0,len(out_Mx)):\n",
    "  out_COPy_temp=out_Mx[i]/out_Fz[i]\n",
    "  # print(temp)\n",
    "  if out_COPy_temp != out_COPy_temp:\n",
    "    out_COPy_temp=0\n",
    "  out_COPy.append(out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "# out_COPx = -(out_My)/out_Fz\n",
    "out_COPx = np.array(out_COPx)\n",
    "out_COPx= out_COPx.reshape(-1,1)\n",
    "\n",
    "# out_COPy = out_Mx/out_Fz\n",
    "out_COPy = np.array(out_COPy)\n",
    "out_COPy= out_COPy.reshape(-1,1)\n",
    "\n",
    "# Pred_COPx = -(Pred_My)/Pred_Fz\n",
    "Pred_COPx = np.array(Pred_COPx)\n",
    "Pred_COPx= Pred_COPx.reshape(-1,1)\n",
    "\n",
    "# Pred_COPy = Pred_Mx/Pred_Fz\n",
    "Pred_COPy = np.array(Pred_COPy)\n",
    "Pred_COPy= Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Pred_COP = np.concatenate((Pred_COPx, Pred_COPy), axis=1)\n",
    "FC_COP = np.concatenate((out_COPx, out_COPy), axis=1)\n",
    "\n",
    "col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000\n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Training Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "y1 = FC_COP[50:100,0]\n",
    "y2 = FC_COP[50:100,1]\n",
    "y3 = Pred_COP[50:100,0]\n",
    "y4 = Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "data_filter = abs(y1) > 0\n",
    "data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1[data_filter], y2[data_filter ], color='red', alpha=0.3)\n",
    "pyplot.plot(y3[data_filter2], y4[data_filter2 ], color='green')\n",
    "# pyplot.plot(y1, y2, color='red')\n",
    "# pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqtHd4TCMSmb",
    "outputId": "87c8864a-cf47-4c04-fef3-61f55013f533"
   },
   "outputs": [],
   "source": [
    "print(y_inverse[0],y_pred_inverse[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "mGqaBi7w87tS",
    "outputId": "4e82aad3-8627-4ced-cdaa-65c11cd648bf"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[100:200,0]\n",
    "y2 = FC_COP[100:200,1]\n",
    "y3 = Pred_COP[100:200,0]\n",
    "y4 = Pred_COP[100:200,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DM_iSERrk9L"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v-xfJBLJru0-",
    "outputId": "c071af6b-adde-40ae-95d0-331506b0abce"
   },
   "outputs": [],
   "source": [
    "## Model Validation\n",
    "Test_Insole = pd.read_csv('1225JakariaRWalk2Min.txt', header=None, low_memory=False)\n",
    "TestSIData =  np.asarray(Test_Insole)\n",
    "\n",
    "Test_df = pd.read_csv('1225JakariaRWalk2Min.csv', low_memory=False)\n",
    "Test_columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "Test_selected_df = Test_df[Test_columns]\n",
    "Test_FPDatas = Test_selected_df[:4200]\n",
    "\n",
    "\n",
    "test_SmartInsole = np.array(TestSIData[:4200]).astype('float32')\n",
    "Test_FPData = np.array(Test_FPDatas).astype('float32')\n",
    "\n",
    "Test_FXData = Test_FPData[:,0]\n",
    "Test_FXData =  np.array(Test_FXData)\n",
    "Test_FXData = Test_FXData.reshape(-1,1)\n",
    "Test_FYData = Test_FPData[:,1]\n",
    "Test_FYData =  np.array(Test_FYData)\n",
    "Test_FYData = Test_FYData.reshape(-1,1)\n",
    "Test_FZData = (Test_FPData[:,2])/10\n",
    "Test_FZData =  np.array(Test_FZData)\n",
    "Test_FZData = Test_FZData.reshape(-1,1)\n",
    "Test_MXData = (Test_FPData[:,3])/1000\n",
    "Test_MXData =  np.array(Test_MXData)\n",
    "Test_MXData = Test_MXData.reshape(-1,1)\n",
    "Test_MYData = (Test_FPData[:,4])/10000\n",
    "Test_MYData =  np.array(Test_MYData)\n",
    "Test_MYData =Test_MYData.reshape(-1,1)\n",
    "Test_MZData = (Test_FPData[:,5])/100\n",
    "Test_MZData =  np.array(Test_MZData)\n",
    "Test_MZData = Test_MZData.reshape(-1,1)\n",
    "\n",
    "Test_newFPData = np.concatenate((Test_FXData, Test_FYData, Test_FZData, Test_MXData, Test_MYData, Test_MZData), axis=1)\n",
    "## End Load Data\n",
    "\n",
    "# loop through rows in steps of n\n",
    "# for i in range(0, test_SmartInsole.shape[0], n):\n",
    "#     test_SmartInsole[i:i + n, 0] = np.clip(test_SmartInsole[i:i + 1, 0] + noise, a_min=0.0, a_max=None)\n",
    "\n",
    "for i in range(len(test_SmartInsole)):\n",
    "    test_SmartInsole[i][0] = test_SmartInsole[i][0] + (iter % max_iter) + 1\n",
    "    iter += 1\n",
    "\n",
    "Test_xscale = (test_SmartInsole - minInsole) / ( maxInsole - minInsole )\n",
    "\n",
    "Test_yscale = []\n",
    "for i in range(0,6):\n",
    "  Test_scale = (Test_FPData[:,i] - FPmin[i]) / ( FPmax[i] - FPmin[i] )\n",
    "  Test_yscale.append(Test_scale)\n",
    "Test_yscale = np.array(Test_yscale)\n",
    "Test_yscale = Test_yscale.transpose()\n",
    "\n",
    "test_sample_size = Test_xscale.shape[0] # number of samples in train set\n",
    "test_time_steps  = Test_xscale.shape[1] # number of features in train set\n",
    "test_input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "test_train_data_reshaped = Test_xscale.reshape(test_sample_size,test_time_steps,test_input_dimension)\n",
    "\n",
    "Regression_Model.evaluate(test_train_data_reshaped, Test_yscale)\n",
    "Test_xX_model = Regression_Model.predict(test_train_data_reshaped)\n",
    "\n",
    "print('MSE: ',mean_squared_error(Test_yscale, ypred))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(Test_yscale, ypred)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(Test_yscale, ypred))\n",
    "\n",
    "\n",
    "#invert normalize\n",
    "Test_y_inverse = []\n",
    "Test_y_pred_inverse = []\n",
    "\n",
    "for i in range(0,6):\n",
    "  Test_Y_inver =  Test_yscale[0:15000, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_Pred_inver = Test_xX_model[0:15000, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_y_inverse.append(Test_Y_inver)\n",
    "  Test_y_pred_inverse.append(Test_Pred_inver)\n",
    "Test_y_inverse = np.array(Test_y_inverse)\n",
    "Test_y_inverse = Test_y_inverse.transpose()\n",
    "Test_y_pred_inverse = np.array(Test_y_pred_inverse)\n",
    "Test_y_pred_inverse = Test_y_pred_inverse.transpose()\n",
    "\n",
    "for i in range(len(Test_y_pred_inverse)):\n",
    "    if (np.abs(Test_y_pred_inverse[i]) < 1).all():\n",
    "        Test_y_pred_inverse[i] = 0\n",
    "\n",
    "# # make to original Data\n",
    "# Test_FXData2 = Test_y_inverse[:,0]\n",
    "# Test_FXData2=  np.array(Test_FXData2)\n",
    "# Test_FXData2 = Test_FXData2.reshape(-1,1)\n",
    "\n",
    "# Test_FYData2 = Test_y_inverse[:,1]\n",
    "# Test_FYData2 =  np.array(Test_FYData2)\n",
    "# Test_FYData2 = Test_FYData2.reshape(-1,1)\n",
    "\n",
    "# Test_FZData2 = (Test_y_inverse[:,2]*10)\n",
    "# Test_FZData2 =  np.array(Test_FZData2)\n",
    "# Test_FZData2 = Test_FZData2.reshape(-1,1)\n",
    "\n",
    "# Test_MXData2 = (Test_y_inverse[:,3]*1000)\n",
    "# Test_MXData2 =  np.array(Test_MXData2)\n",
    "# Test_MXData2 = Test_MXData2.reshape(-1,1)\n",
    "\n",
    "# Test_MYData2 = (Test_y_inverse[:,4]*10000)\n",
    "# Test_MYData2 =  np.array(Test_MYData2)\n",
    "# Test_MYData2 = Test_MYData2.reshape(-1,1\n",
    "#                           )\n",
    "# Test_MZData2 = (Test_y_inverse[:,5]*100)\n",
    "# Test_MZData2 =  np.array(Test_MZData2)\n",
    "# Test_MZData2 = Test_MZData2.reshape(-1,1)\n",
    "\n",
    "# Test_new_inverse2 = np.concatenate((Test_FXData2, Test_FYData2, Test_FZData2, Test_MXData2, Test_MYData2, Test_MZData2), axis=1)\n",
    "\n",
    "# Test_FXData3 = Test_y_pred_inverse[:,0]\n",
    "# Test_FXData3=  np.array(Test_FXData3)\n",
    "# Test_FXData3 = Test_FXData3.reshape(-1,1)\n",
    "\n",
    "# Test_FYData3 = Test_y_pred_inverse[:,1]\n",
    "# Test_FYData3 =  np.array(Test_FYData3)\n",
    "# Test_FYData3 = Test_FYData3.reshape(-1,1)\n",
    "\n",
    "# Test_FZData3 = (Test_y_pred_inverse[:,2]*10)\n",
    "# Test_FZData3 =  np.array(Test_FZData3)\n",
    "# Test_FZData3 = Test_FZData3.reshape(-1,1)\n",
    "\n",
    "# Test_MXData3 = (Test_y_pred_inverse[:,3]*1000)\n",
    "# Test_MXData3 =  np.array(Test_MXData3)\n",
    "# Test_MXData3 = Test_MXData3.reshape(-1,1)\n",
    "\n",
    "# Test_MYData3 = (Test_y_pred_inverse[:,4]*10000)\n",
    "# Test_MYData3 =  np.array(Test_MYData3)\n",
    "# Test_MYData3 = Test_MYData3.reshape(-1,1)\n",
    "\n",
    "# Test_MZData3 = (Test_y_pred_inverse[:,5]*100)\n",
    "# Test_MZData3 =  np.array(Test_MZData3)\n",
    "# Test_MZData3 = Test_MZData3.reshape(-1,1)\n",
    "\n",
    "# Test_new_inverse3 = np.concatenate((Test_FXData3, Test_FYData3, Test_FZData3, Test_MXData3, Test_MYData3, Test_MZData3), axis=1)\n",
    "\n",
    "Test_new_inverse2 = Test_y_inverse\n",
    "Test_new_inverse3 = Test_y_pred_inverse\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000\n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('CNN Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "Test_out_Fz = Test_new_inverse2[0:15000,2]\n",
    "Test_out_Mx = Test_new_inverse2[0:15000,3]\n",
    "Test_out_My = Test_new_inverse2[0:15000,4]\n",
    "Test_Pred_Fz = Test_new_inverse3[0:15000,2]\n",
    "Test_Pred_Mx = Test_new_inverse3[0:15000,3]\n",
    "Test_Pred_My = Test_new_inverse3[0:15000,4]\n",
    "\n",
    "Test_Pred_COPx=[]\n",
    "for i in range(0,len(Test_Pred_Fz)):\n",
    "  Test_Pred_COPx_temp=-(Test_Pred_My[i])/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPx_temp != Test_Pred_COPx_temp:\n",
    "    Test_Pred_COPx_temp=0\n",
    "  Test_Pred_COPx.append(Test_Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPx=[]\n",
    "for i in range(0,len(Test_out_Fz)):\n",
    "  Test_out_COPx_temp=-(Test_out_My[i])/Test_out_Fz[i]\n",
    "  if Test_out_COPx_temp != Test_out_COPx_temp:\n",
    "    Test_out_COPx_temp=0\n",
    "  Test_out_COPx.append(Test_out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_Pred_COPy=[]\n",
    "for i in range(0,len(Test_Pred_Mx)):\n",
    "  Test_Pred_COPy_temp=Test_Pred_Mx[i]/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPy_temp != Test_Pred_COPy_temp:\n",
    "    Test_Pred_COPy_temp=0\n",
    "  Test_Pred_COPy.append(Test_Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPy=[]\n",
    "for i in range(0,len(Test_out_Mx)):\n",
    "  Test_out_COPy_temp=Test_out_Mx[i]/Test_out_Fz[i]\n",
    "  if Test_out_COPy_temp != Test_out_COPy_temp:\n",
    "    Test_out_COPy_temp=0\n",
    "  Test_out_COPy.append(Test_out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "Test_out_COPx = np.array(Test_out_COPx)\n",
    "Test_out_COPx= Test_out_COPx.reshape(-1,1)\n",
    "\n",
    "Test_out_COPy = np.array(Test_out_COPy)\n",
    "Test_out_COPy= Test_out_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPx = np.array(Test_Pred_COPx)\n",
    "Test_Pred_COPx= Test_Pred_COPx.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPy = np.array(Test_Pred_COPy)\n",
    "Test_Pred_COPy= Test_Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COP = np.concatenate((Test_Pred_COPx, Test_Pred_COPy), axis=1)\n",
    "Test_FC_COP = np.concatenate((Test_out_COPx, Test_out_COPy), axis=1)\n",
    "\n",
    "Test_col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000\n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,Test_FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Test_Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Testing Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "Test_y1 = Test_FC_COP[50:100,0]\n",
    "Test_y2 = Test_FC_COP[50:100,1]\n",
    "Test_y3 = Test_Pred_COP[50:100,0]\n",
    "Test_y4 = Test_Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "# Test_data_filter = abs(y1) > 0\n",
    "# Test_data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(Test_y1[Test_data_filter], Test_y2[Test_data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(Test_y3[Test_data_filter2], Test_y4[Test_data_filter2 ], color='green')\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Testing Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "xkt9yX-69KXZ",
    "outputId": "611fb531-15fb-4647-d0b9-d086116cfe3b"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[100:200,0]\n",
    "Test_y2 = Test_FC_COP[100:200,1]\n",
    "Test_y3 = Test_Pred_COP[100:200,0]\n",
    "Test_y4 = Test_Pred_COP[100:200,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "2x7LVsR5DT4_",
    "outputId": "6a73f142-20bc-4f84-b703-af06372ca676"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[0:100,0]\n",
    "Test_y2 = Test_FC_COP[0:100,1]\n",
    "Test_y3 = Test_Pred_COP[0:100,0]\n",
    "Test_y4 = Test_Pred_COP[0:100,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
