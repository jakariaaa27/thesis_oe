{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFyb0y7PUJOo"
   },
   "source": [
    "# ResNet Model Building Pipeline for 1D Signals with DEMO\n",
    "#### ResNet18, ResNet34, ResNet50, ResNet101, ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import tornado.iostream\n",
    "\n",
    "# Create a TCP connection to a server running on localhost at port 8000\n",
    "sock = socket.create_connection(('localhost', 8888))\n",
    "\n",
    "# Create an IOStream object with a large buffer size\n",
    "stream = tornado.iostream.IOStream(sock, max_buffer_size=1073741824)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eMhBhz1CrMb3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from numpy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, BatchNormalization, Activation, add\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape, Flatten, Dense\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "# from tensorflow.keras.optimizers import AdamW\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import Normalizer,MinMaxScaler,StandardScaler, RobustScaler, QuantileTransformer, PowerTransformer\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "import pywt\n",
    "np.set_printoptions(suppress=True)\n",
    "# Import ResNet1D Module\n",
    "from ResNet_1DCNN import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeR4-T_yKu00",
    "outputId": "d4c38f3d-2523-47cd-8038-27d5b1807c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 89, 1) (3000, 89, 1)\n",
      "(12000, 1) (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "wavelet = 'db4'\n",
    "max_iter = 50\n",
    "iter = 0\n",
    "\n",
    "# Walking Dataset\n",
    "InsoleWalking1 = pd.read_csv('0310AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking2 = pd.read_csv('0310HudaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking3 = pd.read_csv('0311LalaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking4 = pd.read_csv('0311YunitaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking5 = pd.read_csv('0312AbelRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking6 = pd.read_csv('0312AbiRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking7 = pd.read_csv('0312AryaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking8 = pd.read_csv('0312HawaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking9 = pd.read_csv('0312NisaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking10 = pd.read_csv('0313ChenChengRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking11 = pd.read_csv('0313RezaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking12 = pd.read_csv('0313RilaniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking13 = pd.read_csv('0313SariRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking14 = pd.read_csv('0313ShelbyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking15 = pd.read_csv('0314HelenRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking16 = pd.read_csv('0315AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking17 = pd.read_csv('0315HappyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking18 = pd.read_csv('0317HeniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking19 = pd.read_csv('0317NadiaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking20 = pd.read_csv('0317VikaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking21 = pd.read_csv('0319AlfianRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking22 = pd.read_csv('1225JakariaRWalk5Min.txt', header=None, low_memory=False)\n",
    "SIDatasWalking1 =  np.array(InsoleWalking1)\n",
    "SIDatasWalking2 =  np.array(InsoleWalking2)\n",
    "SIDatasWalking3 =  np.array(InsoleWalking3)\n",
    "SIDatasWalking4 =  np.array(InsoleWalking4)\n",
    "SIDatasWalking5 =  np.array(InsoleWalking5)\n",
    "SIDatasWalking6 =  np.array(InsoleWalking6)\n",
    "SIDatasWalking7 =  np.array(InsoleWalking7)\n",
    "SIDatasWalking8 =  np.array(InsoleWalking8)\n",
    "SIDatasWalking9 =  np.array(InsoleWalking9)\n",
    "SIDatasWalking10 =  np.array(InsoleWalking10)\n",
    "SIDatasWalking11 =  np.array(InsoleWalking11)\n",
    "SIDatasWalking12 =  np.array(InsoleWalking12)\n",
    "SIDatasWalking13 =  np.array(InsoleWalking13)\n",
    "SIDatasWalking14 =  np.array(InsoleWalking14)\n",
    "SIDatasWalking15 =  np.array(InsoleWalking15)\n",
    "SIDatasWalking16 =  np.array(InsoleWalking16)\n",
    "SIDatasWalking17 =  np.array(InsoleWalking17)\n",
    "SIDatasWalking18 =  np.array(InsoleWalking18)\n",
    "SIDatasWalking19 =  np.array(InsoleWalking19)\n",
    "SIDatasWalking20 =  np.array(InsoleWalking20)\n",
    "SIDatasWalking21 =  np.array(InsoleWalking21)\n",
    "SIDatasWalking22 =  np.array(InsoleWalking22)\n",
    "\n",
    "dfwalk1 = pd.read_csv('0310AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk2 = pd.read_csv('0310HudaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk3 = pd.read_csv('0311LalaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk4 = pd.read_csv('0311YunitaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk5 = pd.read_csv('0312AbelRWalk5Min.csv', low_memory=False)\n",
    "dfwalk6 = pd.read_csv('0312AbiRWalk5Min.csv', low_memory=False)\n",
    "dfwalk7 = pd.read_csv('0312AryaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk8 = pd.read_csv('0312HawaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk9 = pd.read_csv('0312NisaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk10 = pd.read_csv('0313ChenChengRWalk5Min.csv', low_memory=False)\n",
    "dfwalk11 = pd.read_csv('0313RezaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk12 = pd.read_csv('0313RilaniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk13 = pd.read_csv('0313SariRWalk5Min.csv', low_memory=False)\n",
    "dfwalk14 = pd.read_csv('0313ShelbyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk15 = pd.read_csv('0314HelenRWalk5Min.csv', low_memory=False)\n",
    "dfwalk16 = pd.read_csv('0315AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk17 = pd.read_csv('0315HappyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk18 = pd.read_csv('0317HeniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk19 = pd.read_csv('0317NadiaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk20 = pd.read_csv('0317VikaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk21 = pd.read_csv('0319AlfianRWalk5Min.csv', low_memory=False)\n",
    "dfwalk22 = pd.read_csv('1225JakariaRWalk5Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfwalks1 = dfwalk1[columns]\n",
    "selected_dfwalks2 = dfwalk2[columns]\n",
    "selected_dfwalks3 = dfwalk3[columns]\n",
    "selected_dfwalks4 = dfwalk4[columns]\n",
    "selected_dfwalks5 = dfwalk5[columns]\n",
    "selected_dfwalks6 = dfwalk6[columns]\n",
    "selected_dfwalks7 = dfwalk7[columns]\n",
    "selected_dfwalks8 = dfwalk8[columns]\n",
    "selected_dfwalks9 = dfwalk9[columns]\n",
    "selected_dfwalks10 = dfwalk10[columns]\n",
    "selected_dfwalks11 = dfwalk11[columns]\n",
    "selected_dfwalks12 = dfwalk12[columns]\n",
    "selected_dfwalks13 = dfwalk13[columns]\n",
    "selected_dfwalks14 = dfwalk14[columns]\n",
    "selected_dfwalks15 = dfwalk15[columns]\n",
    "selected_dfwalks16 = dfwalk16[columns]\n",
    "selected_dfwalks17 = dfwalk17[columns]\n",
    "selected_dfwalks18 = dfwalk18[columns]\n",
    "selected_dfwalks19 = dfwalk19[columns]\n",
    "selected_dfwalks20 = dfwalk20[columns]\n",
    "selected_dfwalks21 = dfwalk21[columns]\n",
    "selected_dfwalks22 = dfwalk22[columns]\n",
    "FPDatasWalking1 = selected_dfwalks1[:15000]\n",
    "FPDatasWalking2 = selected_dfwalks2[:15000]\n",
    "FPDatasWalking3 = selected_dfwalks3[:15000]\n",
    "FPDatasWalking4 = selected_dfwalks4[:15000]\n",
    "FPDatasWalking5 = selected_dfwalks5[:15000]\n",
    "FPDatasWalking6 = selected_dfwalks6[:15000]\n",
    "FPDatasWalking7 = selected_dfwalks7[:15000]\n",
    "FPDatasWalking8 = selected_dfwalks8[:15000]\n",
    "FPDatasWalking9 = selected_dfwalks9[:15000]\n",
    "FPDatasWalking10 = selected_dfwalks10[:15000]\n",
    "FPDatasWalking11 = selected_dfwalks11[:15000]\n",
    "FPDatasWalking12 = selected_dfwalks12[:15000]\n",
    "FPDatasWalking13 = selected_dfwalks13[:15000]\n",
    "FPDatasWalking14 = selected_dfwalks14[:15000]\n",
    "FPDatasWalking15 = selected_dfwalks15[:15000]\n",
    "FPDatasWalking16 = selected_dfwalks16[:15000]\n",
    "FPDatasWalking17 = selected_dfwalks17[:15000]\n",
    "FPDatasWalking18 = selected_dfwalks18[:15000]\n",
    "FPDatasWalking19 = selected_dfwalks19[:15000]\n",
    "FPDatasWalking20 = selected_dfwalks20[:15000]\n",
    "FPDatasWalking21 = selected_dfwalks21[:15000]\n",
    "FPDatasWalking22 = selected_dfwalks22[:15000]\n",
    "\n",
    "SIDataWalking1 = np.array(SIDatasWalking1[:15000]).astype('float32')\n",
    "SIDataWalking2 = np.array(SIDatasWalking2[:15000]).astype('float32')\n",
    "SIDataWalking3 = np.array(SIDatasWalking3[:15000]).astype('float32')\n",
    "SIDataWalking4 = np.array(SIDatasWalking4[:15000]).astype('float32')\n",
    "SIDataWalking5 = np.array(SIDatasWalking5[:15000]).astype('float32')\n",
    "SIDataWalking6 = np.array(SIDatasWalking6[:15000]).astype('float32')\n",
    "SIDataWalking7 = np.array(SIDatasWalking7[:15000]).astype('float32')\n",
    "SIDataWalking8 = np.array(SIDatasWalking8[:15000]).astype('float32')\n",
    "SIDataWalking9 = np.array(SIDatasWalking9[:15000]).astype('float32')\n",
    "SIDataWalking10 = np.array(SIDatasWalking10[:15000]).astype('float32')\n",
    "SIDataWalking11 = np.array(SIDatasWalking11[:15000]).astype('float32')\n",
    "SIDataWalking12 = np.array(SIDatasWalking12[:15000]).astype('float32')\n",
    "SIDataWalking13 = np.array(SIDatasWalking13[:15000]).astype('float32')\n",
    "SIDataWalking14 = np.array(SIDatasWalking14[:15000]).astype('float32')\n",
    "SIDataWalking15 = np.array(SIDatasWalking15[:15000]).astype('float32')\n",
    "SIDataWalking16 = np.array(SIDatasWalking16[:15000]).astype('float32')\n",
    "SIDataWalking17 = np.array(SIDatasWalking17[:15000]).astype('float32')\n",
    "SIDataWalking18 = np.array(SIDatasWalking18[:15000]).astype('float32')\n",
    "SIDataWalking19 = np.array(SIDatasWalking19[:15000]).astype('float32')\n",
    "SIDataWalking20 = np.array(SIDatasWalking20[:15000]).astype('float32')\n",
    "SIDataWalking21 = np.array(SIDatasWalking21[:15000]).astype('float32')\n",
    "SIDataWalking22 = np.array(SIDatasWalking22[:15000]).astype('float32')\n",
    "FPDataWalking1 = np.array(FPDatasWalking1).astype('float32')\n",
    "FPDataWalking2 = np.array(FPDatasWalking2).astype('float32')\n",
    "FPDataWalking3= np.array(FPDatasWalking3).astype('float32')\n",
    "FPDataWalking4= np.array(FPDatasWalking4).astype('float32')\n",
    "FPDataWalking5= np.array(FPDatasWalking5).astype('float32')\n",
    "FPDataWalking6= np.array(FPDatasWalking6).astype('float32')\n",
    "FPDataWalking7= np.array(FPDatasWalking7).astype('float32')\n",
    "FPDataWalking8= np.array(FPDatasWalking8).astype('float32')\n",
    "FPDataWalking9= np.array(FPDatasWalking9).astype('float32')\n",
    "FPDataWalking10 = np.array(FPDatasWalking10).astype('float32')\n",
    "FPDataWalking11 = np.array(FPDatasWalking11).astype('float32')\n",
    "FPDataWalking12= np.array(FPDatasWalking12).astype('float32')\n",
    "FPDataWalking13= np.array(FPDatasWalking13).astype('float32')\n",
    "FPDataWalking14= np.array(FPDatasWalking14).astype('float32')\n",
    "FPDataWalking15= np.array(FPDatasWalking15).astype('float32')\n",
    "FPDataWalking16= np.array(FPDatasWalking16).astype('float32')\n",
    "FPDataWalking17= np.array(FPDatasWalking17).astype('float32')\n",
    "FPDataWalking18= np.array(FPDatasWalking18).astype('float32')\n",
    "FPDataWalking19= np.array(FPDatasWalking19).astype('float32')\n",
    "FPDataWalking20= np.array(FPDatasWalking20).astype('float32')\n",
    "FPDataWalking21= np.array(FPDatasWalking21).astype('float32')\n",
    "FPDataWalking22= np.array(FPDatasWalking22).astype('float32')\n",
    "\n",
    "SIDatasetWalking = np.concatenate((SIDataWalking1, SIDataWalking2, SIDataWalking3,\n",
    "                            SIDataWalking4, SIDataWalking5, SIDataWalking6,\n",
    "                            SIDataWalking7, SIDataWalking8, SIDataWalking9,\n",
    "                            SIDataWalking10, SIDataWalking11, SIDataWalking12,\n",
    "                            SIDataWalking13, SIDataWalking14, SIDataWalking15,\n",
    "                            SIDataWalking16, SIDataWalking17, SIDataWalking18,\n",
    "                            SIDataWalking19, SIDataWalking20, SIDataWalking21,\n",
    "                            SIDataWalking22), axis=0)\n",
    "                            \n",
    "FPDatasetWalking = np.concatenate((FPDataWalking1, FPDataWalking2, FPDataWalking3,\n",
    "                            FPDataWalking4, FPDataWalking5, FPDataWalking6,\n",
    "                            FPDataWalking7, FPDataWalking8, FPDataWalking9,\n",
    "                            FPDataWalking10, FPDataWalking11, FPDataWalking12,\n",
    "                            FPDataWalking13, FPDataWalking14, FPDataWalking15,\n",
    "                            FPDataWalking16, FPDataWalking17, FPDataWalking18,\n",
    "                            FPDataWalking19, FPDataWalking20, FPDataWalking21,\n",
    "                            FPDataWalking22), axis=0)\n",
    "\n",
    "# SIDatasetWalking = SIDataWalking1\n",
    "# FPDatasetWalking = FPDataWalking1\n",
    "\n",
    "# SIDatasetWalking = np.array(SIDatasetWalking).astype('float64')\n",
    "# FPDatasetWalking = np.array(FPDatasetWalking).astype('float64')\n",
    "\n",
    "# Standing Dataset\n",
    "InsoleStanding1 = pd.read_csv('0310AyuStand5Min2.txt', header=None, low_memory=False)\n",
    "InsoleStanding2 = pd.read_csv('0310HudaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding3 = pd.read_csv('0311LalaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding4 = pd.read_csv('0311YunitaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding5 = pd.read_csv('0312AbelStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding6 = pd.read_csv('0312AbiStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding7 = pd.read_csv('0312AryaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding8 = pd.read_csv('0312HawaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding9 = pd.read_csv('0312NisaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding10 = pd.read_csv('0313ChenChengStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding11 = pd.read_csv('0313RezaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding12 = pd.read_csv('0313RilaniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding13 = pd.read_csv('0313SariStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding14 = pd.read_csv('0313ShelbyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding15 = pd.read_csv('0314HelenStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding16 = pd.read_csv('0315AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding17 = pd.read_csv('0315HappyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding18 = pd.read_csv('0317HeniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding19 = pd.read_csv('0317NadiaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding20 = pd.read_csv('0317VikaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding21 = pd.read_csv('0319AlfianStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding22 = pd.read_csv('0310JakaStand2Min.txt', header=None, low_memory=False)\n",
    "SIDatasStanding1 =  np.array(InsoleStanding1)\n",
    "SIDatasStanding2 =  np.array(InsoleStanding2)\n",
    "SIDatasStanding3 =  np.array(InsoleStanding3)\n",
    "SIDatasStanding4 =  np.array(InsoleStanding4)\n",
    "SIDatasStanding5 =  np.array(InsoleStanding5)\n",
    "SIDatasStanding6 =  np.array(InsoleStanding6)\n",
    "SIDatasStanding7 =  np.array(InsoleStanding7)\n",
    "SIDatasStanding8 =  np.array(InsoleStanding8)\n",
    "SIDatasStanding9 =  np.array(InsoleStanding9)\n",
    "SIDatasStanding10 =  np.array(InsoleStanding10)\n",
    "SIDatasStanding11 =  np.array(InsoleStanding11)\n",
    "SIDatasStanding12 =  np.array(InsoleStanding12)\n",
    "SIDatasStanding13 =  np.array(InsoleStanding13)\n",
    "SIDatasStanding14 =  np.array(InsoleStanding14)\n",
    "SIDatasStanding15 =  np.array(InsoleStanding15)\n",
    "SIDatasStanding16 =  np.array(InsoleStanding16)\n",
    "SIDatasStanding17 =  np.array(InsoleStanding17)\n",
    "SIDatasStanding18 =  np.array(InsoleStanding18)\n",
    "SIDatasStanding19 =  np.array(InsoleStanding19)\n",
    "SIDatasStanding20 =  np.array(InsoleStanding20)\n",
    "SIDatasStanding21 =  np.array(InsoleStanding21)\n",
    "SIDatasStanding22 =  np.array(InsoleStanding22)\n",
    "\n",
    "dfStanding1 = pd.read_csv('0310AyuStand5Min2.csv', low_memory=False)\n",
    "dfStanding2 = pd.read_csv('0310HudaStand5Min1.csv', low_memory=False)\n",
    "dfStanding3 = pd.read_csv('0311LalaStand5Min1.csv', low_memory=False)\n",
    "dfStanding4 = pd.read_csv('0311YunitaStand5Min1.csv', low_memory=False)\n",
    "dfStanding5 = pd.read_csv('0312AbelStand5Min1.csv', low_memory=False)\n",
    "dfStanding6 = pd.read_csv('0312AbiStand5Min1.csv', low_memory=False)\n",
    "dfStanding7 = pd.read_csv('0312AryaStand5Min1.csv', low_memory=False)\n",
    "dfStanding8 = pd.read_csv('0312HawaStand5Min1.csv', low_memory=False)\n",
    "dfStanding9 = pd.read_csv('0312NisaStand5Min1.csv', low_memory=False)\n",
    "dfStanding10 = pd.read_csv('0313ChenChengStand5Min1.csv', low_memory=False)\n",
    "dfStanding11 = pd.read_csv('0313RezaStand5Min1.csv', low_memory=False)\n",
    "dfStanding12 = pd.read_csv('0313RilaniStand5Min1.csv', low_memory=False)\n",
    "dfStanding13 = pd.read_csv('0313SariStand5Min1.csv', low_memory=False)\n",
    "dfStanding14 = pd.read_csv('0313ShelbyStand5Min1.csv', low_memory=False)\n",
    "dfStanding15 = pd.read_csv('0314HelenStand5Min1.csv', low_memory=False)\n",
    "dfStanding16 = pd.read_csv('0315AyuStand5Min1.csv', low_memory=False)\n",
    "dfStanding17 = pd.read_csv('0315HappyStand5Min1.csv', low_memory=False)\n",
    "dfStanding18 = pd.read_csv('0317HeniStand5Min1.csv', low_memory=False)\n",
    "dfStanding19 = pd.read_csv('0317NadiaStand5Min1.csv', low_memory=False)\n",
    "dfStanding20 = pd.read_csv('0317VikaStand5Min1.csv', low_memory=False)\n",
    "dfStanding21 = pd.read_csv('0319AlfianStand5Min1.csv', low_memory=False)\n",
    "dfStanding22 = pd.read_csv('0310JakaStand2Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfStandings1 = dfStanding1[columns]\n",
    "selected_dfStandings2 = dfStanding2[columns]\n",
    "selected_dfStandings3 = dfStanding3[columns]\n",
    "selected_dfStandings4 = dfStanding4[columns]\n",
    "selected_dfStandings5 = dfStanding5[columns]\n",
    "selected_dfStandings6 = dfStanding6[columns]\n",
    "selected_dfStandings7 = dfStanding7[columns]\n",
    "selected_dfStandings8 = dfStanding8[columns]\n",
    "selected_dfStandings9 = dfStanding9[columns]\n",
    "selected_dfStandings10 = dfStanding10[columns]\n",
    "selected_dfStandings11 = dfStanding11[columns]\n",
    "selected_dfStandings12 = dfStanding12[columns]\n",
    "selected_dfStandings13 = dfStanding13[columns]\n",
    "selected_dfStandings14 = dfStanding14[columns]\n",
    "selected_dfStandings15 = dfStanding15[columns]\n",
    "selected_dfStandings16 = dfStanding16[columns]\n",
    "selected_dfStandings17 = dfStanding17[columns]\n",
    "selected_dfStandings18 = dfStanding18[columns]\n",
    "selected_dfStandings19 = dfStanding19[columns]\n",
    "selected_dfStandings20 = dfStanding20[columns]\n",
    "selected_dfStandings21 = dfStanding21[columns]\n",
    "selected_dfStandings22 = dfStanding22[columns]\n",
    "FPDataStandings1 = selected_dfStandings1[:15000]\n",
    "FPDataStandings2 = selected_dfStandings2[:15000]\n",
    "FPDataStandings3 = selected_dfStandings3[:15000]\n",
    "FPDataStandings4 = selected_dfStandings4[:15000]\n",
    "FPDataStandings5 = selected_dfStandings5[:15000]\n",
    "FPDataStandings6 = selected_dfStandings6[:15000]\n",
    "FPDataStandings7 = selected_dfStandings7[:15000]\n",
    "FPDataStandings8 = selected_dfStandings8[:15000]\n",
    "FPDataStandings9 = selected_dfStandings9[:15000]\n",
    "FPDataStandings10 = selected_dfStandings10[:15000]\n",
    "FPDataStandings11 = selected_dfStandings11[:15000]\n",
    "FPDataStandings12 = selected_dfStandings12[:15000]\n",
    "FPDataStandings13 = selected_dfStandings13[:15000]\n",
    "FPDataStandings14 = selected_dfStandings14[:15000]\n",
    "FPDataStandings15 = selected_dfStandings15[:15000]\n",
    "FPDataStandings16 = selected_dfStandings16[:15000]\n",
    "FPDataStandings17 = selected_dfStandings17[:15000]\n",
    "FPDataStandings18 = selected_dfStandings18[:15000]\n",
    "FPDataStandings19 = selected_dfStandings19[:15000]\n",
    "FPDataStandings20 = selected_dfStandings20[:15000]\n",
    "FPDataStandings21 = selected_dfStandings21[:15000]\n",
    "FPDataStandings22 = selected_dfStandings22[:15000]\n",
    "\n",
    "SIDataStanding1 = np.array(SIDatasStanding1[:15000]).astype('float32')\n",
    "SIDataStanding2 = np.array(SIDatasStanding2[:15000]).astype('float32')\n",
    "SIDataStanding3 = np.array(SIDatasStanding3[:15000]).astype('float32')\n",
    "SIDataStanding4 = np.array(SIDatasStanding4[:15000]).astype('float32')\n",
    "SIDataStanding5 = np.array(SIDatasStanding5[:15000]).astype('float32')\n",
    "SIDataStanding6 = np.array(SIDatasStanding6[:15000]).astype('float32')\n",
    "SIDataStanding7 = np.array(SIDatasStanding7[:15000]).astype('float32')\n",
    "SIDataStanding8 = np.array(SIDatasStanding8[:15000]).astype('float32')\n",
    "SIDataStanding9 = np.array(SIDatasStanding9[:15000]).astype('float32')\n",
    "SIDataStanding10 = np.array(SIDatasStanding10[:15000]).astype('float32')\n",
    "SIDataStanding11 = np.array(SIDatasStanding11[:15000]).astype('float32')\n",
    "SIDataStanding12 = np.array(SIDatasStanding12[:15000]).astype('float32')\n",
    "SIDataStanding13 = np.array(SIDatasStanding13[:15000]).astype('float32')\n",
    "SIDataStanding14 = np.array(SIDatasStanding14[:15000]).astype('float32')\n",
    "SIDataStanding15 = np.array(SIDatasStanding15[:15000]).astype('float32')\n",
    "SIDataStanding16 = np.array(SIDatasStanding16[:15000]).astype('float32')\n",
    "SIDataStanding17 = np.array(SIDatasStanding17[:15000]).astype('float32')\n",
    "SIDataStanding18 = np.array(SIDatasStanding18[:15000]).astype('float32')\n",
    "SIDataStanding19 = np.array(SIDatasStanding19[:15000]).astype('float32')\n",
    "SIDataStanding20 = np.array(SIDatasStanding20[:15000]).astype('float32')\n",
    "SIDataStanding21 = np.array(SIDatasStanding21[:15000]).astype('float32')\n",
    "SIDataStanding22 = np.array(SIDatasStanding22[:15000]).astype('float32')\n",
    "FPDataStanding1 = np.array(FPDataStandings1).astype('float32')\n",
    "FPDataStanding2 = np.array(FPDataStandings2).astype('float32')\n",
    "FPDataStanding3= np.array(FPDataStandings3).astype('float32')\n",
    "FPDataStanding4= np.array(FPDataStandings4).astype('float32')\n",
    "FPDataStanding5= np.array(FPDataStandings5).astype('float32')\n",
    "FPDataStanding6= np.array(FPDataStandings6).astype('float32')\n",
    "FPDataStanding7= np.array(FPDataStandings7).astype('float32')\n",
    "FPDataStanding8= np.array(FPDataStandings8).astype('float32')\n",
    "FPDataStanding9= np.array(FPDataStandings9).astype('float32')\n",
    "FPDataStanding10 = np.array(FPDataStandings10).astype('float32')\n",
    "FPDataStanding11 = np.array(FPDataStandings11).astype('float32')\n",
    "FPDataStanding12= np.array(FPDataStandings12).astype('float32')\n",
    "FPDataStanding13= np.array(FPDataStandings13).astype('float32')\n",
    "FPDataStanding14= np.array(FPDataStandings14).astype('float32')\n",
    "FPDataStanding15= np.array(FPDataStandings15).astype('float32')\n",
    "FPDataStanding16= np.array(FPDataStandings16).astype('float32')\n",
    "FPDataStanding17= np.array(FPDataStandings17).astype('float32')\n",
    "FPDataStanding18= np.array(FPDataStandings18).astype('float32')\n",
    "FPDataStanding19= np.array(FPDataStandings19).astype('float32')\n",
    "FPDataStanding20= np.array(FPDataStandings20).astype('float32')\n",
    "FPDataStanding21= np.array(FPDataStandings21).astype('float32')\n",
    "FPDataStanding22= np.array(FPDataStandings22).astype('float32')\n",
    "\n",
    "# SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3,\n",
    "#                             SIDataStanding4, SIDataStanding5, SIDataStanding6,\n",
    "#                             SIDataStanding7, SIDataStanding8, SIDataStanding9,\n",
    "#                             SIDataStanding10, SIDataStanding11, SIDataStanding12,\n",
    "#                             SIDataStanding13, SIDataStanding14, SIDataStanding15,\n",
    "#                             SIDataStanding16, SIDataStanding17, SIDataStanding18,\n",
    "#                             SIDataStanding19, SIDataStanding20, SIDataStanding21,\n",
    "#                             SIDataStanding22), axis=0)\n",
    "\n",
    "# SIDatasetStanding = np.concatenate((SIDataStanding13, SIDataStanding20, SIDataStanding17, \n",
    "#                        SIDataStanding15, SIDataStanding12, SIDataStanding22, SIDataStanding1, SIDataStanding4, SIDataStanding8, \n",
    "#                        SIDataStanding16, SIDataStanding9, SIDataStanding6, SIDataStanding7, SIDataStanding3,\n",
    "#                        SIDataStanding19, SIDataStanding10), axis=0)\n",
    "\n",
    "# SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3), axis=0)\n",
    "# FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3), axis=0)\n",
    "                        \n",
    "# FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3,\n",
    "#                             FPDataStanding4, FPDataStanding5, FPDataStanding6,\n",
    "#                             FPDataStanding7, FPDataStanding8, FPDataStanding9,\n",
    "#                             FPDataStanding10, FPDataStanding11, FPDataStanding12,\n",
    "#                             FPDataStanding13, FPDataStanding14, FPDataStanding15,\n",
    "#                             FPDataStanding16, FPDataStanding17, FPDataStanding18,\n",
    "#                             FPDataStanding19, FPDataStanding20, FPDataStanding21,\n",
    "#                             FPDataStanding22), axis=0)\n",
    "\n",
    "# FPDatasetStanding = np.concatenate((FPDataStanding13, FPDataStanding20, FPDataStanding17, \n",
    "#                        FPDataStanding15, FPDataStanding12, FPDataStanding22, FPDataStanding1, FPDataStanding4, FPDataStanding8, \n",
    "#                        FPDataStanding16, FPDataStanding9, FPDataStanding6, FPDataStanding7, FPDataStanding3,\n",
    "#                        FPDataStanding19, FPDataStanding10), axis=0)\n",
    "\n",
    "SIDatasetStanding = SIDataStanding1\n",
    "FPDatasetStanding = FPDataStanding1\n",
    "\n",
    "SIDatasetStanding = np.array(SIDatasetStanding).astype('float32')\n",
    "FPDatasetStanding = np.array(FPDatasetStanding).astype('float32')\n",
    "\n",
    "# Concat Standing and Walking\n",
    "# SIDataset = np.concatenate((SIDatasetWalking,SIDatasetStanding), axis=0)\n",
    "# FPDataset = np.concatenate((FPDatasetWalking,FPDatasetStanding), axis=0)\n",
    "# SIDataset = SIDatasetStanding\n",
    "# FPDataset = FPDatasetStanding\n",
    "\n",
    "SIDataset = SIDatasetStanding\n",
    "FPDataset = FPDatasetStanding\n",
    "\n",
    "## End Load Data\n",
    "\n",
    "wavelet = 'db4'\n",
    "\n",
    "SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(SIDataset[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "#     coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "#     coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "#     coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "#     coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "#     coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "SIData_filtered = np.zeros(SIDataset.shape)\n",
    "for i in range(89):\n",
    "    SIData_filtered[:, i] = pywt.waverec(SIDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "# max_iter = 50\n",
    "# iter = 0\n",
    "# for i in range(len(SIData_filtered)):\n",
    "#     SIData_filtered[i][0] = np.round(SIData_filtered[i][0] + (iter % max_iter) + 1,0)\n",
    "#     iter += 1\n",
    "\n",
    "# for i in range(len(SIDataset)):\n",
    "#     if i < len(SIDatasetWalking):\n",
    "#         SIData_filtered[i][0] = np.round(SIData_filtered[i][0] + (iter % max_iter) + 1,0)\n",
    "#         iter += 1\n",
    "#     else:\n",
    "#         SIData_filtered[i][0] = 0\n",
    "#         # SIData_filtered[i][0] = i-314999\n",
    "\n",
    "for i in range(len(SIData_filtered)):\n",
    "    SIData_filtered[i][np.abs(SIData_filtered[i]) < 1] = 0\n",
    "    \n",
    "     \n",
    "# Data Normalization\n",
    "# scaler_SI = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_SI.fit(SIData_filtered)\n",
    "scaler_fx = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_fx.fit(FPDataset[:, 0].reshape(-1, 1))\n",
    "# scaler_fy = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_fy.fit(FPDataset[:, 1].reshape(-1, 1))\n",
    "# scaler_fz = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_fz.fit(FPDataset[:, 2].reshape(-1, 1))\n",
    "# scaler_mx = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_mx.fit(FPDataset[:, 3].reshape(-1, 1))\n",
    "# scaler_my = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_my.fit(FPDataset[:, 4].reshape(-1, 1))\n",
    "# scaler_mz = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_mz.fit(FPDataset[:, 5].reshape(-1, 1))\n",
    "\n",
    "# Normalize each feature separately\n",
    "# normalized_SIData = scaler_SI.transform(SIData_filtered)\n",
    "normalized_fx = scaler_fx.transform(FPDataset[:, 0].reshape(-1, 1))\n",
    "# normalized_fy = scaler_fy.transform(FPDataset[:, 1].reshape(-1, 1))\n",
    "# normalized_fz = scaler_fz.transform(FPDataset[:, 2].reshape(-1, 1))\n",
    "# normalized_mx = scaler_mx.transform(FPDataset[:, 3].reshape(-1, 1))\n",
    "# normalized_my = scaler_my.transform(FPDataset[:, 4].reshape(-1, 1))\n",
    "# normalized_mz = scaler_mz.transform(FPDataset[:, 5].reshape(-1, 1))\n",
    "\n",
    "# Combine the normalized features back into a single numpy array\n",
    "# normalized_FPData= np.concatenate((normalized_fx, normalized_fy, normalized_fz, \n",
    "#                                               normalized_mx, normalized_my, normalized_mz), axis=1)\n",
    "#End Data Normalization\n",
    "\n",
    "#Spliting Data\n",
    "sample_size = SIData_filtered.shape[0] # number of samples in train set\n",
    "time_steps  = SIData_filtered.shape[1] # number of features in train set\n",
    "input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "train_data_reshaped = SIData_filtered.reshape(sample_size,time_steps,input_dimension)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_reshaped, normalized_fx, test_size=0.20, random_state=2)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n",
    "#End Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    16.2062       8.66447   -348.588    -1572.85    -63446.8\n",
      "  -4214.18   ]\n"
     ]
    }
   ],
   "source": [
    "print(FPDataset[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  33.  58.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  66.  73.   0.   0.   0.   0.   0.\n",
      "   0.  49.  72.  51.   0.  48.   0.   0.   0.   0.   0.   0.  66.  67.\n",
      "  15.   8.  17.  13.   0.   1.  29.  68.  49.   0.   0.   0.   0.   0.\n",
      "   0.   0.  16.  38.   0.  34.  63.  36.  68. 105.  76.  91.  50.   0.\n",
      "  29.   9.   0.   0.  67. 112. 126. 115.   0.  29.   5.   0.   0.  99.\n",
      "   5.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(SIDataset[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    16.2062 ,      8.66447,   -348.588  ,  -1572.85   ,\n",
       "        -63446.8    ,  -4214.18   ],\n",
       "       [    16.0428 ,      8.07436,   -348.85   ,  -1545.33   ,\n",
       "        -63460.3    ,  -4279.01   ],\n",
       "       [    16.9946 ,      6.81864,   -348.754  ,  -1383.58   ,\n",
       "        -63481.7    ,  -4043.77   ],\n",
       "       [    16.4017 ,      7.27899,   -348.026  ,  -1409.9    ,\n",
       "        -63335.4    ,  -3797.94   ],\n",
       "       [    15.7312 ,      7.37392,   -348.513  ,  -1369.85   ,\n",
       "        -63405.5    ,  -3881.99   ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPDataset[50:55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6IOf_sFx5Dm"
   },
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tFqNbe_vch4u"
   },
   "outputs": [],
   "source": [
    "\"Configurations for ResNet in Regression Mode\"\n",
    "length = X_train.shape[1]   # Number of Features (or length of the signal)\n",
    "model_width = 64           # Number of Filter or Kernel in the Input Layer\n",
    "num_channel = 1             # Number of Input Channels\n",
    "problem_type = 'Regression' # Regression or Classification\n",
    "output_number = 1           # Number of Outputs in the Regression Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1L543Qc_x7AB"
   },
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nq-4BfWjcSHf"
   },
   "outputs": [],
   "source": [
    "class AdamW(Adam):\n",
    "    def __init__(self, learning_rate=0.0001, weight_decay=0.01, **kwargs):\n",
    "        super(AdamW, self).__init__(learning_rate, **kwargs)\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def get_gradients(self, loss, params):\n",
    "        gradients = super(AdamW, self).get_gradients(loss, params)\n",
    "        if self.weight_decay > 0.0:\n",
    "            for i in range(len(gradients)):\n",
    "                if gradients[i] is not None:\n",
    "                    gradients[i] += self.weight_decay * params[i]\n",
    "        return gradients\n",
    "\n",
    "Regression_Model = ResNet(length, num_channel, model_width, problem_type=problem_type, output_nums=output_number).ResNet50() # Build Model\n",
    "# ResNet Models supported: ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, \n",
    "Regression_Model.compile(loss='mse', optimizer=AdamW(learning_rate=0.0001, weight_decay=0.01), metrics= ['mse']) # Compile Model\n",
    "# Here, Model validation metric is set as Mean Squared Error or MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nu7h2qmWx-Jg"
   },
   "source": [
    "Model_Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLz469jDhJWx",
    "outputId": "85690d69-f6cf-4e1f-964e-112af4accc6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 89, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 45, 64)       512         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 45, 64)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 22, 64)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 22, 64)       4160        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 22, 64)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 22, 64)       12352       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 22, 64)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 22, 256)      16640       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 22, 256)      16640       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 22, 256)      0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 22, 256)      0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 22, 256)      0           ['activation_4[0][0]',           \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 22, 256)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 22, 64)       16448       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 22, 64)       0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 22, 64)       12352       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 22, 64)       0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 22, 256)      16640       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 22, 256)      65792       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 22, 256)      0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 22, 256)      0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 22, 256)      0           ['activation_9[0][0]',           \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 22, 256)      0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 22, 64)       16448       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 22, 64)       0           ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 22, 64)       12352       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 22, 64)       0           ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 22, 256)      16640       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 22, 256)      65792       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 22, 256)      0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 22, 256)      0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 22, 256)      0           ['activation_14[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 22, 256)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 11, 128)      98432       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 11, 128)      0           ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 11, 128)      49280       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 11, 128)      0           ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 11, 128)      16512       ['activation_17[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 11, 128)      0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 11, 128)      49280       ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 11, 128)      0           ['conv1d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 11, 512)      66048       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 11, 512)      66048       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 11, 512)      0           ['conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 11, 512)      0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 11, 512)      0           ['activation_21[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 11, 512)      0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 11, 128)      65664       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 11, 128)      0           ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 11, 128)      49280       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 11, 128)      0           ['conv1d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 11, 512)      66048       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 11, 512)      262656      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 11, 512)      0           ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 11, 512)      0           ['conv1d_19[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 11, 512)      0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 11, 512)      0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 11, 128)      65664       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 11, 128)      0           ['conv1d_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 11, 128)      49280       ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 11, 128)      0           ['conv1d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 11, 512)      66048       ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 11, 512)      262656      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 11, 512)      0           ['conv1d_26[0][0]']              \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 11, 512)      0           ['conv1d_23[0][0]']              \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 11, 512)      0           ['activation_31[0][0]',          \n",
      "                                                                  'activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 11, 512)      0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 6, 256)       393472      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 6, 256)       0           ['conv1d_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 6, 256)       196864      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 6, 256)       0           ['conv1d_28[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 6, 256)       65792       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 6, 256)       0           ['conv1d_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 6, 256)       196864      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 6, 256)       0           ['conv1d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 6, 1024)      263168      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 6, 1024)      263168      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 6, 1024)      0           ['conv1d_32[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 6, 1024)      0           ['conv1d_29[0][0]']              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 6, 1024)      0           ['activation_38[0][0]',          \n",
      "                                                                  'activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 6, 1024)      0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 6, 256)       262400      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 6, 256)       0           ['conv1d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 6, 256)       196864      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 6, 256)       0           ['conv1d_35[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 6, 1024)      263168      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 6, 1024)      1049600     ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 6, 1024)      0           ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 6, 1024)      0           ['conv1d_33[0][0]']              \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 6, 1024)      0           ['activation_43[0][0]',          \n",
      "                                                                  'activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 6, 1024)      0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 6, 256)       262400      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 6, 256)       0           ['conv1d_38[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 6, 256)       196864      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 6, 256)       0           ['conv1d_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 6, 1024)      263168      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 6, 1024)      1049600     ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 6, 1024)      0           ['conv1d_40[0][0]']              \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 6, 1024)      0           ['conv1d_37[0][0]']              \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 6, 1024)      0           ['activation_48[0][0]',          \n",
      "                                                                  'activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 6, 1024)      0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 6, 256)       262400      ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 6, 256)       0           ['conv1d_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 6, 256)       196864      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 6, 256)       0           ['conv1d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 6, 1024)      263168      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 6, 1024)      1049600     ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 6, 1024)      0           ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 6, 1024)      0           ['conv1d_41[0][0]']              \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 6, 1024)      0           ['activation_53[0][0]',          \n",
      "                                                                  'activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 6, 1024)      0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 6, 256)       262400      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 6, 256)       0           ['conv1d_46[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 6, 256)       196864      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 6, 256)       0           ['conv1d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 6, 1024)      263168      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 6, 1024)      1049600     ['activation_54[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_58 (Activation)     (None, 6, 1024)      0           ['conv1d_48[0][0]']              \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 6, 1024)      0           ['conv1d_45[0][0]']              \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 6, 1024)      0           ['activation_58[0][0]',          \n",
      "                                                                  'activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 6, 1024)      0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 3, 512)       1573376     ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 3, 512)       0           ['conv1d_49[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 3, 512)       786944      ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 3, 512)       0           ['conv1d_50[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 3, 512)       262656      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 3, 512)       0           ['conv1d_52[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 3, 512)       786944      ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 3, 512)       0           ['conv1d_53[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 3, 2048)      1050624     ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 3, 2048)      1050624     ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 3, 2048)      0           ['conv1d_54[0][0]']              \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 3, 2048)      0           ['conv1d_51[0][0]']              \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 3, 2048)      0           ['activation_65[0][0]',          \n",
      "                                                                  'activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 3, 2048)      0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)             (None, 3, 512)       1049088     ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 3, 512)       0           ['conv1d_56[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_57 (Conv1D)             (None, 3, 512)       786944      ['activation_68[0][0]']          \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 3, 512)       0           ['conv1d_57[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_58 (Conv1D)             (None, 3, 2048)      1050624     ['activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 3, 2048)      4196352     ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 3, 2048)      0           ['conv1d_58[0][0]']              \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 3, 2048)      0           ['conv1d_55[0][0]']              \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 3, 2048)      0           ['activation_70[0][0]',          \n",
      "                                                                  'activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 3, 2048)      0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 2048)        0           ['activation_71[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2049        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,569,345\n",
      "Trainable params: 22,569,345\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Regression_Model.summary() # Summary of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vHdlpJFx_14"
   },
   "source": [
    "Upload Past Weights if available (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SSW2BfUMqs7A"
   },
   "outputs": [],
   "source": [
    "# Regression_Model.load_weights('Saved_Model.h5') # Load Previously Trained Weights for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSicHIFzyCky"
   },
   "source": [
    "Train Model for 'n' number of Epochs with Batch size of 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuaVIjBviw7n",
    "outputId": "751c008c-6b1c-4fd8-d84c-05467ed173e9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 33091430.0000 - mse: 33091430.0000\n",
      "Epoch 1: val_loss improved from inf to 8.24379, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 14s 55ms/step - loss: 32870820.0000 - mse: 32870820.0000 - val_loss: 8.2438 - val_mse: 8.2438\n",
      "Epoch 2/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 5.4335 - mse: 5.4335\n",
      "Epoch 2: val_loss improved from 8.24379 to 3.80261, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 5.4243 - mse: 5.4243 - val_loss: 3.8026 - val_mse: 3.8026\n",
      "Epoch 3/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 3.0395 - mse: 3.0395\n",
      "Epoch 3: val_loss improved from 3.80261 to 2.48515, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 3.0324 - mse: 3.0324 - val_loss: 2.4851 - val_mse: 2.4851\n",
      "Epoch 4/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.0801 - mse: 2.0801\n",
      "Epoch 4: val_loss improved from 2.48515 to 1.94673, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 2.0746 - mse: 2.0746 - val_loss: 1.9467 - val_mse: 1.9467\n",
      "Epoch 5/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.6459 - mse: 1.6459\n",
      "Epoch 5: val_loss improved from 1.94673 to 1.55055, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 1.6432 - mse: 1.6432 - val_loss: 1.5506 - val_mse: 1.5506\n",
      "Epoch 6/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.3586 - mse: 1.3586\n",
      "Epoch 6: val_loss improved from 1.55055 to 1.49571, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 1.3549 - mse: 1.3549 - val_loss: 1.4957 - val_mse: 1.4957\n",
      "Epoch 7/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.3244 - mse: 1.3244\n",
      "Epoch 7: val_loss improved from 1.49571 to 0.99916, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 1.3208 - mse: 1.3208 - val_loss: 0.9992 - val_mse: 0.9992\n",
      "Epoch 8/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.1242 - mse: 1.1242\n",
      "Epoch 8: val_loss did not improve from 0.99916\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.1222 - mse: 1.1222 - val_loss: 1.0055 - val_mse: 1.0055\n",
      "Epoch 9/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.9319 - mse: 0.9319\n",
      "Epoch 9: val_loss improved from 0.99916 to 0.88905, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.9385 - mse: 0.9385 - val_loss: 0.8891 - val_mse: 0.8891\n",
      "Epoch 10/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.9673 - mse: 0.9673\n",
      "Epoch 10: val_loss improved from 0.88905 to 0.81578, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.9662 - mse: 0.9662 - val_loss: 0.8158 - val_mse: 0.8158\n",
      "Epoch 11/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.1075 - mse: 1.1075\n",
      "Epoch 11: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.1124 - mse: 1.1124 - val_loss: 1.7472 - val_mse: 1.7472\n",
      "Epoch 12/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.0361 - mse: 1.0361\n",
      "Epoch 12: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.0338 - mse: 1.0338 - val_loss: 1.2286 - val_mse: 1.2286\n",
      "Epoch 13/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.3370 - mse: 1.3370\n",
      "Epoch 13: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.3331 - mse: 1.3331 - val_loss: 1.1429 - val_mse: 1.1429\n",
      "Epoch 14/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 4.7834 - mse: 4.7834\n",
      "Epoch 14: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 4.7597 - mse: 4.7597 - val_loss: 1.9744 - val_mse: 1.9744\n",
      "Epoch 15/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.1006 - mse: 2.1006\n",
      "Epoch 15: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 2.1110 - mse: 2.1110 - val_loss: 5.3908 - val_mse: 5.3908\n",
      "Epoch 16/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 7.9672 - mse: 7.9672\n",
      "Epoch 16: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 7.9409 - mse: 7.9409 - val_loss: 1.6508 - val_mse: 1.6508\n",
      "Epoch 17/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 14.0612 - mse: 14.0612\n",
      "Epoch 17: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 14.1835 - mse: 14.1835 - val_loss: 30.5520 - val_mse: 30.5520\n",
      "Epoch 18/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 5.2216 - mse: 5.2216\n",
      "Epoch 18: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 5.1965 - mse: 5.1965 - val_loss: 0.8667 - val_mse: 0.8667\n",
      "Epoch 19/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 19.2218 - mse: 19.2218\n",
      "Epoch 19: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 19.3108 - mse: 19.3108 - val_loss: 14.3949 - val_mse: 14.3949\n",
      "Epoch 20/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 13.1931 - mse: 13.1931\n",
      "Epoch 20: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 13.1329 - mse: 13.1329 - val_loss: 4.4591 - val_mse: 4.4591\n",
      "Epoch 21/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 6.9208 - mse: 6.9208\n",
      "Epoch 21: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 7.3803 - mse: 7.3803 - val_loss: 60.7076 - val_mse: 60.7076\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - ETA: 0s - loss: 28.4702 - mse: 28.4702\n",
      "Epoch 22: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 28.4702 - mse: 28.4702 - val_loss: 3.1751 - val_mse: 3.1751\n",
      "Epoch 23/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 8.4706 - mse: 8.4706\n",
      "Epoch 23: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 8.5024 - mse: 8.5024 - val_loss: 4.5768 - val_mse: 4.5768\n",
      "Epoch 24/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 21.5491 - mse: 21.5491\n",
      "Epoch 24: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 21.4201 - mse: 21.4201 - val_loss: 1.2364 - val_mse: 1.2364\n",
      "Epoch 25/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 5.4134 - mse: 5.4134\n",
      "Epoch 25: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 5.4026 - mse: 5.4026 - val_loss: 2.9593 - val_mse: 2.9593\n",
      "Epoch 26/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 27.5030 - mse: 27.5030\n",
      "Epoch 26: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 27.3640 - mse: 27.3640 - val_loss: 10.3975 - val_mse: 10.3975\n",
      "Epoch 27/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 14.7650 - mse: 14.7650\n",
      "Epoch 27: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 14.9460 - mse: 14.9460 - val_loss: 26.5053 - val_mse: 26.5053\n",
      "Epoch 28/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 21.1015 - mse: 21.1015\n",
      "Epoch 28: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 20.9671 - mse: 20.9671 - val_loss: 1.4125 - val_mse: 1.4125\n",
      "Epoch 29/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 35.2657 - mse: 35.2657\n",
      "Epoch 29: val_loss did not improve from 0.81578\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 35.0621 - mse: 35.0621 - val_loss: 5.2813 - val_mse: 5.2813\n",
      "Epoch 30/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 3.8219 - mse: 3.8219\n",
      "Epoch 30: val_loss improved from 0.81578 to 0.66511, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 3.8011 - mse: 3.8011 - val_loss: 0.6651 - val_mse: 0.6651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 6.0923 - mse: 6.0923\n",
      "Epoch 31: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 6.0623 - mse: 6.0623 - val_loss: 1.0712 - val_mse: 1.0712\n",
      "Epoch 32/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 29.8223 - mse: 29.8223\n",
      "Epoch 32: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 29.6466 - mse: 29.6466 - val_loss: 3.5172 - val_mse: 3.5172\n",
      "Epoch 33/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 8.0721 - mse: 8.0721\n",
      "Epoch 33: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 8.9931 - mse: 8.9931 - val_loss: 113.8125 - val_mse: 113.8125\n",
      "Epoch 34/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 23.4314 - mse: 23.4314\n",
      "Epoch 34: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 23.2864 - mse: 23.2864 - val_loss: 1.9269 - val_mse: 1.9269\n",
      "Epoch 35/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 14.8602 - mse: 14.8602\n",
      "Epoch 35: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 14.8621 - mse: 14.8621 - val_loss: 13.6415 - val_mse: 13.6415\n",
      "Epoch 36/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 17.3827 - mse: 17.3827\n",
      "Epoch 36: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 17.4996 - mse: 17.4996 - val_loss: 22.2460 - val_mse: 22.2460\n",
      "Epoch 37/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 10.0274 - mse: 10.0274\n",
      "Epoch 37: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 9.9689 - mse: 9.9689 - val_loss: 3.8208 - val_mse: 3.8208\n",
      "Epoch 38/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 25.7678 - mse: 25.7678\n",
      "Epoch 38: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 25.6293 - mse: 25.6293 - val_loss: 4.2290 - val_mse: 4.2290\n",
      "Epoch 39/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 11.7768 - mse: 11.7768\n",
      "Epoch 39: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 11.7367 - mse: 11.7367 - val_loss: 18.6547 - val_mse: 18.6547\n",
      "Epoch 40/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 26.4538 - mse: 26.4538\n",
      "Epoch 40: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 26.2845 - mse: 26.2845 - val_loss: 1.3676 - val_mse: 1.3676\n",
      "Epoch 41/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.3247 - mse: 2.3247\n",
      "Epoch 41: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 2.3148 - mse: 2.3148 - val_loss: 1.0014 - val_mse: 1.0014\n",
      "Epoch 42/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1228.5027 - mse: 1228.5027\n",
      "Epoch 42: val_loss did not improve from 0.66511\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1220.9121 - mse: 1220.9121 - val_loss: 85.2041 - val_mse: 85.2041\n",
      "Epoch 43/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 5.8794 - mse: 5.8794\n",
      "Epoch 43: val_loss improved from 0.66511 to 0.54939, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 5.8450 - mse: 5.8450 - val_loss: 0.5494 - val_mse: 0.5494\n",
      "Epoch 44/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3630 - mse: 0.3630\n",
      "Epoch 44: val_loss improved from 0.54939 to 0.30582, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.3622 - mse: 0.3622 - val_loss: 0.3058 - val_mse: 0.3058\n",
      "Epoch 45/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2775 - mse: 0.2775\n",
      "Epoch 45: val_loss improved from 0.30582 to 0.25207, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.2771 - mse: 0.2771 - val_loss: 0.2521 - val_mse: 0.2521\n",
      "Epoch 46/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2492 - mse: 0.2492\n",
      "Epoch 46: val_loss did not improve from 0.25207\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.2486 - mse: 0.2486 - val_loss: 0.4046 - val_mse: 0.4046\n",
      "Epoch 47/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2158 - mse: 0.2158\n",
      "Epoch 47: val_loss improved from 0.25207 to 0.23919, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.2160 - mse: 0.2160 - val_loss: 0.2392 - val_mse: 0.2392\n",
      "Epoch 48/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1637 - mse: 0.1637\n",
      "Epoch 48: val_loss improved from 0.23919 to 0.17679, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.1639 - mse: 0.1639 - val_loss: 0.1768 - val_mse: 0.1768\n",
      "Epoch 49/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1475 - mse: 0.1475\n",
      "Epoch 49: val_loss improved from 0.17679 to 0.14320, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.1474 - mse: 0.1474 - val_loss: 0.1432 - val_mse: 0.1432\n",
      "Epoch 50/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1321 - mse: 0.1321\n",
      "Epoch 50: val_loss did not improve from 0.14320\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.1323 - mse: 0.1323 - val_loss: 0.1453 - val_mse: 0.1453\n",
      "Epoch 51/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1269 - mse: 0.1269\n",
      "Epoch 51: val_loss improved from 0.14320 to 0.11654, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.1270 - mse: 0.1270 - val_loss: 0.1165 - val_mse: 0.1165\n",
      "Epoch 52/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1285 - mse: 0.1285\n",
      "Epoch 52: val_loss did not improve from 0.11654\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.1282 - mse: 0.1282 - val_loss: 0.1238 - val_mse: 0.1238\n",
      "Epoch 53/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1085 - mse: 0.1085\n",
      "Epoch 53: val_loss did not improve from 0.11654\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.1084 - mse: 0.1084 - val_loss: 0.2619 - val_mse: 0.2619\n",
      "Epoch 54/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1428 - mse: 0.1428\n",
      "Epoch 54: val_loss improved from 0.11654 to 0.09982, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.1424 - mse: 0.1424 - val_loss: 0.0998 - val_mse: 0.0998\n",
      "Epoch 55/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1201 - mse: 0.1201\n",
      "Epoch 55: val_loss improved from 0.09982 to 0.09165, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.1198 - mse: 0.1198 - val_loss: 0.0917 - val_mse: 0.0917\n",
      "Epoch 56/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0885 - mse: 0.0885\n",
      "Epoch 56: val_loss improved from 0.09165 to 0.08558, saving model to Saved_Model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.0856 - val_mse: 0.0856\n",
      "Epoch 57/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1346 - mse: 0.1346\n",
      "Epoch 57: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.1341 - mse: 0.1341 - val_loss: 0.2530 - val_mse: 0.2530\n",
      "Epoch 58/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1748 - mse: 0.1748\n",
      "Epoch 58: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.1745 - mse: 0.1745 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 59/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1849 - mse: 0.1849\n",
      "Epoch 59: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.1862 - mse: 0.1862 - val_loss: 0.5271 - val_mse: 0.5271\n",
      "Epoch 60/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.7767 - mse: 0.7767\n",
      "Epoch 60: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.7754 - mse: 0.7754 - val_loss: 0.4114 - val_mse: 0.4114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.5590 - mse: 2.5590\n",
      "Epoch 61: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 2.5747 - mse: 2.5747 - val_loss: 1.6629 - val_mse: 1.6629\n",
      "Epoch 62/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 3.3669 - mse: 3.3669\n",
      "Epoch 62: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 3.3488 - mse: 3.3488 - val_loss: 0.6847 - val_mse: 0.6847\n",
      "Epoch 63/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.5146 - mse: 2.5146\n",
      "Epoch 63: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 2.5469 - mse: 2.5469 - val_loss: 9.3643 - val_mse: 9.3643\n",
      "Epoch 64/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 11.9065 - mse: 11.9065\n",
      "Epoch 64: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 11.8430 - mse: 11.8430 - val_loss: 0.8161 - val_mse: 0.8161\n",
      "Epoch 65/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.3409 - mse: 1.3409\n",
      "Epoch 65: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.3337 - mse: 1.3337 - val_loss: 0.3798 - val_mse: 0.3798\n",
      "Epoch 66/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.7105 - mse: 1.7105\n",
      "Epoch 66: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.7408 - mse: 1.7408 - val_loss: 1.3619 - val_mse: 1.3619\n",
      "Epoch 67/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.5232 - mse: 2.5232\n",
      "Epoch 67: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 2.5276 - mse: 2.5276 - val_loss: 1.1914 - val_mse: 1.1914\n",
      "Epoch 68/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 3.6940 - mse: 3.6940\n",
      "Epoch 68: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 3.7959 - mse: 3.7959 - val_loss: 9.2016 - val_mse: 9.2016\n",
      "Epoch 69/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 5.8099 - mse: 5.8099\n",
      "Epoch 69: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 5.7825 - mse: 5.7825 - val_loss: 0.5748 - val_mse: 0.5748\n",
      "Epoch 70/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.8985 - mse: 1.8985\n",
      "Epoch 70: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.8908 - mse: 1.8908 - val_loss: 0.3641 - val_mse: 0.3641\n",
      "Epoch 71/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.7783 - mse: 1.7783\n",
      "Epoch 71: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.8012 - mse: 1.8012 - val_loss: 4.4095 - val_mse: 4.4095\n",
      "Epoch 72/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 6.0067 - mse: 6.0067\n",
      "Epoch 72: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 5.9713 - mse: 5.9713 - val_loss: 0.5552 - val_mse: 0.5552\n",
      "Epoch 73/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.8553 - mse: 0.8553\n",
      "Epoch 73: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.8558 - mse: 0.8558 - val_loss: 0.3004 - val_mse: 0.3004\n",
      "Epoch 74/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 9.0846 - mse: 9.0846\n",
      "Epoch 74: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 9.0301 - mse: 9.0301 - val_loss: 1.3777 - val_mse: 1.3777\n",
      "Epoch 75/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.0448 - mse: 1.0448\n",
      "Epoch 75: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.0409 - mse: 1.0409 - val_loss: 1.9198 - val_mse: 1.9198\n",
      "Epoch 76/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.6571 - mse: 1.6571\n",
      "Epoch 76: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.6492 - mse: 1.6492 - val_loss: 0.3340 - val_mse: 0.3340\n",
      "Epoch 77/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 3.2413 - mse: 3.2413\n",
      "Epoch 77: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 3.2339 - mse: 3.2339 - val_loss: 6.4443 - val_mse: 6.4443\n",
      "Epoch 78/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 4.1919 - mse: 4.1919\n",
      "Epoch 78: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 4.1790 - mse: 4.1790 - val_loss: 0.6023 - val_mse: 0.6023\n",
      "Epoch 79/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.9010 - mse: 0.9010\n",
      "Epoch 79: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.9033 - mse: 0.9033 - val_loss: 0.5843 - val_mse: 0.5843\n",
      "Epoch 80/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.1823 - mse: 2.1823\n",
      "Epoch 80: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 2.2191 - mse: 2.2191 - val_loss: 12.8607 - val_mse: 12.8607\n",
      "Epoch 81/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.4056 - mse: 2.4056\n",
      "Epoch 81: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 2.4461 - mse: 2.4461 - val_loss: 15.7131 - val_mse: 15.7131\n",
      "Epoch 82/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.2818 - mse: 2.2818\n",
      "Epoch 82: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 2.2725 - mse: 2.2725 - val_loss: 0.4770 - val_mse: 0.4770\n",
      "Epoch 83/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.6012 - mse: 2.6012\n",
      "Epoch 83: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 2.5890 - mse: 2.5890 - val_loss: 1.3521 - val_mse: 1.3521\n",
      "Epoch 84/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.5904 - mse: 1.5904\n",
      "Epoch 84: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.5815 - mse: 1.5815 - val_loss: 0.2810 - val_mse: 0.2810\n",
      "Epoch 85/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 1.0615 - mse: 1.0615\n",
      "Epoch 85: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 1.0679 - mse: 1.0679 - val_loss: 1.0501 - val_mse: 1.0501\n",
      "Epoch 86/500\n",
      "149/150 [============================>.] - ETA: 0s - loss: 7750.7725 - mse: 7750.7725\n",
      "Epoch 86: val_loss did not improve from 0.08558\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 7699.2183 - mse: 7699.2183 - val_loss: 2.9999 - val_mse: 2.9999\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping and Model_Checkpoints are optional parameters\n",
    "# Early Stopping is to stop the training based on certain condition set by the user\n",
    "# Model Checkpoint is to save a model in a directory basped on certain conditions so that it can be used later for Transfer Learning or avoiding retraining\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=30, mode='min'), ModelCheckpoint('Saved_Model.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
    "history = Regression_Model.fit(X_train, y_train, epochs=500, batch_size=64, verbose=1, validation_split=0.2, shuffle=True, callbacks=callbacks)\n",
    "# Save 'History' of the model for model performance analysis performed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_3ydNmIKFJqv"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.keras.models.save_model(Regression_Model, 'Resnet18_StandnoWav.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model with custom_objects\n",
    "# import tensorflow as tf\n",
    "# class AdamW(Adam):\n",
    "#     def __init__(self, learning_rate=0.0001, weight_decay=0.01, **kwargs):\n",
    "#         super(AdamW, self).__init__(learning_rate, **kwargs)\n",
    "#         self.weight_decay = weight_decay\n",
    "\n",
    "#     def get_gradients(self, loss, params):\n",
    "#         gradients = super(AdamW, self).get_gradients(loss, params)\n",
    "#         if self.weight_decay > 0.0:\n",
    "#             for i in range(len(gradients)):\n",
    "#                 if gradients[i] is not None:\n",
    "#                     gradients[i] += self.weight_decay * params[i]\n",
    "#         return gradients\n",
    "# custom_objects = {'AdamW': AdamW}\n",
    "# RR = tf.keras.models.load_model('Resnet18_StandnoWav.h5', custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rejbOtGN-ixL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7rTwvEAos2fB",
    "outputId": "4191163c-57a5-4ed6-d3af-b5dbf3593950"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_FPData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Evaluate Model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m Regression_Model\u001b[38;5;241m.\u001b[39mevaluate(train_data_reshaped, \u001b[43mnormalized_FPData\u001b[49m)\n\u001b[0;32m      6\u001b[0m ypred \u001b[38;5;241m=\u001b[39m Regression_Model\u001b[38;5;241m.\u001b[39mpredict(train_data_reshaped)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalized_FPData' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Evaluate Model\n",
    "Regression_Model.evaluate(train_data_reshaped, normalized_FPData)\n",
    "ypred = Regression_Model.predict(train_data_reshaped)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.show()\n",
    "plt.savefig('Loss Result.png')\n",
    "\n",
    "# print('MSE: ',mean_squared_error(normalized_FPData, ypred))\n",
    "# print('RMSE: ',math.sqrt(mean_squared_error(normalized_FPData, ypred)))\n",
    "# print('Coefficient of determination (r2 Score): ', r2_score(normalized_FPData, ypred))\n",
    "\n",
    "\n",
    "#Inverse\n",
    "fx_real = scaler_fx.inverse_transform(normalized_fx)\n",
    "# fy_real = scaler_fy.inverse_transform(normalized_fy)\n",
    "# fz_real = scaler_fz.inverse_transform(normalized_fz)\n",
    "# mx_real = scaler_mx.inverse_transform(normalized_mx)\n",
    "# my_real = scaler_my.inverse_transform(normalized_my)\n",
    "# mz_real = scaler_mz.inverse_transform(normalized_mz)\n",
    "\n",
    "fx_pred = scaler_fx.inverse_transform(ypred[:,0].reshape(-1,1))\n",
    "# fy_pred = scaler_fy.inverse_transform(ypred[:,1].reshape(-1,1))\n",
    "# fz_pred = scaler_fz.inverse_transform(ypred[:,2].reshape(-1,1))\n",
    "# mx_pred = scaler_mx.inverse_transform(ypred[:,3].reshape(-1,1))\n",
    "# my_pred = scaler_my.inverse_transform(ypred[:,4].reshape(-1,1))\n",
    "# mz_pred = scaler_mz.inverse_transform(ypred[:,5].reshape(-1,1))\n",
    "\n",
    "# FPReal = np.concatenate((fx_real, fy_real, fz_real, mx_real, my_real, mz_real), axis=1)\n",
    "# FPPred = np.concatenate((fx_pred, fy_pred, fz_pred, mx_pred, my_pred, mz_pred), axis=1)\n",
    "\n",
    "y_inverse = fx_real\n",
    "y_pred_inverse = fx_pred\n",
    "\n",
    "for i in range(len(y_pred_inverse)):\n",
    "    if (np.abs(y_pred_inverse[i]) < 1).all():\n",
    "        y_pred_inverse[i] = 0\n",
    "\n",
    "for i in range(0, y_pred_inverse.shape[0], 50):\n",
    "    zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "    non_zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "    if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "        y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "print('MSE: ',mean_squared_error(y_inverse, y_pred_inverse))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(y_inverse, y_pred_inverse)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(y_inverse, y_pred_inverse))\n",
    "\n",
    "# restore to original Data\n",
    "new_inverse2 = y_inverse\n",
    "new_inverse3 = y_pred_inverse\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,1))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# # COP\n",
    "# from math import*\n",
    "# np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# out_Fz = new_inverse2[:,2]\n",
    "# out_Mx = new_inverse2[:,3]\n",
    "# out_My = new_inverse2[:,4]\n",
    "# Pred_Fz = new_inverse3[:,2]\n",
    "# Pred_Mx = new_inverse3[:,3]\n",
    "# Pred_My = new_inverse3[:,4]\n",
    "\n",
    "# Pred_COPx=[]\n",
    "# for i in range(0,len(Pred_Fz)):\n",
    "#   Pred_COPx_temp=-(Pred_My[i])/Pred_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if Pred_COPx_temp != Pred_COPx_temp:\n",
    "#     Pred_COPx_temp=0\n",
    "#   Pred_COPx.append(Pred_COPx_temp)\n",
    "#   # break\n",
    "\n",
    "# out_COPx=[]\n",
    "# for i in range(0,len(out_Fz)):\n",
    "#   out_COPx_temp=-(out_My[i])/out_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if out_COPx_temp != out_COPx_temp:\n",
    "#     out_COPx_temp=0\n",
    "#   out_COPx.append(out_COPx_temp)\n",
    "#   # break\n",
    "\n",
    "# Pred_COPy=[]\n",
    "# for i in range(0,len(Pred_Mx)):\n",
    "#   Pred_COPy_temp=Pred_Mx[i]/Pred_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if Pred_COPy_temp != Pred_COPy_temp:\n",
    "#     Pred_COPy_temp=0\n",
    "#   Pred_COPy.append(Pred_COPy_temp)\n",
    "#   # break\n",
    "\n",
    "# out_COPy=[]\n",
    "# for i in range(0,len(out_Mx)):\n",
    "#   out_COPy_temp=out_Mx[i]/out_Fz[i]\n",
    "#   # print(temp)\n",
    "#   if out_COPy_temp != out_COPy_temp:\n",
    "#     out_COPy_temp=0\n",
    "#   out_COPy.append(out_COPy_temp)\n",
    "#   # break\n",
    "\n",
    "\n",
    "# # out_COPx = -(out_My)/out_Fz\n",
    "# out_COPx = np.array(out_COPx)\n",
    "# out_COPx= out_COPx.reshape(-1,1)\n",
    "\n",
    "# # out_COPy = out_Mx/out_Fz\n",
    "# out_COPy = np.array(out_COPy)\n",
    "# out_COPy= out_COPy.reshape(-1,1)\n",
    "\n",
    "# # Pred_COPx = -(Pred_My)/Pred_Fz\n",
    "# Pred_COPx = np.array(Pred_COPx)\n",
    "# Pred_COPx= Pred_COPx.reshape(-1,1)\n",
    "\n",
    "# # Pred_COPy = Pred_Mx/Pred_Fz\n",
    "# Pred_COPy = np.array(Pred_COPy)\n",
    "# Pred_COPy= Pred_COPy.reshape(-1,1)\n",
    "\n",
    "# Pred_COP = np.concatenate((Pred_COPx, Pred_COPy), axis=1)\n",
    "# FC_COP = np.concatenate((out_COPx, out_COPy), axis=1)\n",
    "\n",
    "# col_COP = 'COPx', 'COPy'\n",
    "\n",
    "# x=[]\n",
    "# colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "# colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "# x = np.arange(0,2000)*40/2000 \n",
    "# for i in range(0,2):\n",
    "#     plt.figure(figsize=(15,6))\n",
    "#     plt.plot(x,FC_COP[0:2000,i], color='red')\n",
    "#     plt.plot(x,Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "#     plt.title('COP Calculation (Training Data)')\n",
    "#     plt.ylabel(col_COP[i])\n",
    "#     plt.xlabel('Time(s)')\n",
    "#     plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "#     plt.savefig('Regression Result.png'[i])\n",
    "#     plt.show()\n",
    "\n",
    "# # Trajectory\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# x = range(50)\n",
    "# y1 = FC_COP[50:100,0]\n",
    "# y2 = FC_COP[50:100,1]\n",
    "# y3 = Pred_COP[50:100,0]\n",
    "# y4 = Pred_COP[50:100,1]\n",
    "\n",
    "# # pyplot.figure(figsize=(15,6))\n",
    "# # pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# # pyplot.show()\n",
    "\n",
    "# data_filter = abs(y1) > 0\n",
    "# data_filter2 = abs(y3) > 0\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(y1[data_filter], y2[data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(y3[data_filter2], y4[data_filter2 ], color='green')\n",
    "# # pyplot.plot(y1, y2, color='red')\n",
    "# # pyplot.plot(y3, y4, color='green')\n",
    "# plt.title('COP Trajectory (Training Data)')\n",
    "# pyplot.ylabel('COPy (mm)')\n",
    "# pyplot.xlabel('COPx (mm)')\n",
    "# pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,new_inverse2[15000:18000,i],color='red')\n",
    "    plt.plot(x,new_inverse3[15000:18000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "CHhYv7LpNRTb",
    "outputId": "4d9bc457-9596-441f-8bda-6759e0af84cc"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[0:100,0]\n",
    "y2 = FC_COP[0:100,1]\n",
    "y3 = Pred_COP[0:100,0]\n",
    "y4 = Pred_COP[0:100,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "-3fg6ZDwNNLd",
    "outputId": "c707c66a-4d1a-4d89-9bbf-67ec96062e95"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[100:200,0]\n",
    "y2 = FC_COP[100:200,1]\n",
    "y3 = Pred_COP[100:200,0]\n",
    "y4 = Pred_COP[100:200,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "9qxieSZKNVlT",
    "outputId": "67998abd-a2f0-426f-9cd9-f205ef349c53"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[200:300,0]\n",
    "y2 = FC_COP[200:300,1]\n",
    "y3 = Pred_COP[200:300,0]\n",
    "y4 = Pred_COP[200:300,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Axx3FDcMsYAm",
    "outputId": "abf8945d-cb34-4786-f80f-425cca382d52"
   },
   "outputs": [],
   "source": [
    "new_inverse2[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlZwHomDsZ5R",
    "outputId": "1d112f34-ffa8-4015-f3f0-a591f5d69688"
   },
   "outputs": [],
   "source": [
    "new_inverse3[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8Cnd-RuHso4",
    "outputId": "1dbdfab9-3a55-4b59-d51a-71ac18c572a2"
   },
   "outputs": [],
   "source": [
    "new_inverse2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4I2lr9yfHuJA",
    "outputId": "fbf0bd74-599a-4afb-8eab-ecf5a8f797be"
   },
   "outputs": [],
   "source": [
    "new_inverse3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oa_UQq_v1atq",
    "outputId": "2f0db226-fe50-4d59-aba1-2b0aaa328e41"
   },
   "outputs": [],
   "source": [
    "y_inverse[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsSpiSOY1dQ-",
    "outputId": "5713ad7c-fb14-4068-86d9-50299350084b"
   },
   "outputs": [],
   "source": [
    "y_pred_inverse[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw0HsDDtyEuv"
   },
   "source": [
    "Test and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Validation\n",
    "Test_Insole = pd.read_csv('0310AyuStand5Min2.txt', header=None, low_memory=False)\n",
    "TestSIData =  np.asarray(Test_Insole)\n",
    "\n",
    "Test_df = pd.read_csv('0310AyuStand5Min2.csv', low_memory=False)\n",
    "Test_columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "Test_selected_df = Test_df[Test_columns]\n",
    "Test_FPDatas = Test_selected_df[:6000]\n",
    "\n",
    "\n",
    "test_SmartInsole = np.array(TestSIData[:6000]).astype('float32')\n",
    "Test_FPData = np.array(Test_FPDatas).astype('float32')\n",
    "## End Load Data\n",
    "\n",
    "# print(Test_newFPData[50:55])\n",
    "\n",
    "Test_SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(test_SmartInsole[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "#     coeffsN[-2] = np.zeros_like(coeffsN[-2])\n",
    "#     coeffsN[-3] = np.zeros_like(coeffsN[-3])\n",
    "#     coeffsN[-4] = np.zeros_like(coeffsN[-4])\n",
    "#     coeffsN[-5] = np.zeros_like(coeffsN[-5])\n",
    "#     coeffsN[-6] = np.zeros_like(coeffsN[-6])\n",
    "    # coeffs[-7] = np.zeros_like(coeffs[-7])\n",
    "    Test_SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_SIData_filtered = np.zeros(test_SmartInsole.shape)\n",
    "for i in range(89):\n",
    "    Test_SIData_filtered[:, i] = pywt.waverec(Test_SIDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "# for i in range(len(test_SmartInsole)):\n",
    "#     if i < len(test_SmartInsole):\n",
    "# #         Test_SIData_filtered[i][0] = i+1\n",
    "#         test_SmartInsole[i][0] = test_SmartInsole[i][0] + (iter % max_iter) + 1\n",
    "#         iter += 1\n",
    "#     else:\n",
    "#         test_SmartInsole[i][0] = i+1\n",
    "\n",
    "# for i in range(len(Test_SIData_filtered)):\n",
    "#     Test_SIData_filtered[i][0] = np.round(Test_SIData_filtered[i][0] + (iter % max_iter) + 1,0)\n",
    "#     iter += 1\n",
    "    \n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    Test_SIData_filtered[i][np.abs(Test_SIData_filtered[i]) < 1] = 0\n",
    "\n",
    "\n",
    "# Normalize each feature separately\n",
    "# test_normalized_SIData = scaler_SI.transform(Test_SIData_filtered)\n",
    "test_normalized_fx = scaler_fx.transform(Test_FPData[:, 0].reshape(-1, 1))\n",
    "test_normalized_fy = scaler_fy.transform(Test_FPData[:, 1].reshape(-1, 1))\n",
    "test_normalized_fz = scaler_fz.transform(Test_FPData[:, 2].reshape(-1, 1))\n",
    "test_normalized_mx = scaler_mx.transform(Test_FPData[:, 3].reshape(-1, 1))\n",
    "test_normalized_my = scaler_my.transform(Test_FPData[:, 4].reshape(-1, 1))\n",
    "test_normalized_mz = scaler_mz.transform(Test_FPData[:, 5].reshape(-1, 1))\n",
    "\n",
    "# Combine the normalized features back into a single numpy array\n",
    "test_normalized_FPData= np.concatenate((test_normalized_fx, test_normalized_fy, test_normalized_fz, \n",
    "                                        test_normalized_mx, test_normalized_my, test_normalized_mz), axis=1)\n",
    "\n",
    "# Test_xscale = scaler_x.transform(test_normalized_SIData)\n",
    "# Test_yscale = scaler_y.transform(test_normalized_FPData)\n",
    "\n",
    "test_sample_size = Test_SIData_filtered.shape[0] # number of samples in train set\n",
    "test_time_steps  = Test_SIData_filtered.shape[1] # number of features in train set\n",
    "test_input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "test_train_data_reshaped = Test_SIData_filtered.reshape(test_sample_size,test_time_steps,test_input_dimension)\n",
    "\n",
    "Regression_Model.evaluate(test_train_data_reshaped, test_normalized_FPData)\n",
    "Test_FP_pred = Regression_Model.predict(test_train_data_reshaped)\n",
    "\n",
    "#invert normalize\n",
    "test_fx_real = scaler_fx.inverse_transform(test_normalized_fx)\n",
    "test_fy_real = scaler_fy.inverse_transform(test_normalized_fy)\n",
    "test_fz_real = scaler_fz.inverse_transform(test_normalized_fz)\n",
    "test_mx_real = scaler_mx.inverse_transform(test_normalized_mx)\n",
    "test_my_real = scaler_my.inverse_transform(test_normalized_my)\n",
    "test_mz_real = scaler_mz.inverse_transform(test_normalized_mz)\n",
    "\n",
    "test_fx_pred = scaler_fx.inverse_transform(Test_FP_pred[:,0].reshape(-1,1))\n",
    "test_fy_pred = scaler_fy.inverse_transform(Test_FP_pred[:,1].reshape(-1,1))\n",
    "test_fz_pred = scaler_fz.inverse_transform(Test_FP_pred[:,2].reshape(-1,1))\n",
    "test_mx_pred = scaler_mx.inverse_transform(Test_FP_pred[:,3].reshape(-1,1))\n",
    "test_my_pred = scaler_my.inverse_transform(Test_FP_pred[:,4].reshape(-1,1))\n",
    "test_mz_pred = scaler_mz.inverse_transform(Test_FP_pred[:,5].reshape(-1,1))\n",
    "\n",
    "test_FPReal = np.concatenate((test_fx_real, test_fy_real, test_fz_real, \n",
    "                              test_mx_real, test_my_real, test_mz_real), axis=1)\n",
    "test_FPPred = np.concatenate((test_fx_pred, test_fy_pred, test_fz_pred, \n",
    "                              test_mx_pred, test_my_pred, test_mz_pred), axis=1)\n",
    "\n",
    "Test_y_pred_inverse = test_FPPred\n",
    "Test_y_inverse = test_FPReal\n",
    "\n",
    "for i in range(len(Test_y_pred_inverse)):\n",
    "    if (np.abs(Test_y_pred_inverse[i]) < 1).all():\n",
    "        Test_y_pred_inverse[i] = 0\n",
    "\n",
    "for i in range(0, Test_y_pred_inverse.shape[0], 50):\n",
    "    zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "    non_zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "    if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "        Test_y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "print(Test_y_pred_inverse[50:55])\n",
    "\n",
    "\n",
    "Test_new_inverse2 = Test_y_inverse\n",
    "Test_new_inverse3 = Test_y_pred_inverse\n",
    "    \n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('CNN Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "Test_out_Fz = Test_new_inverse2[:,2]\n",
    "Test_out_Mx = Test_new_inverse2[:,3]\n",
    "Test_out_My = Test_new_inverse2[:,4]\n",
    "Test_Pred_Fz = Test_new_inverse3[:,2]\n",
    "Test_Pred_Mx = Test_new_inverse3[:,3]\n",
    "Test_Pred_My = Test_new_inverse3[:,4]\n",
    "\n",
    "Test_Pred_COPx=[]\n",
    "for i in range(0,len(Test_Pred_Fz)):\n",
    "  Test_Pred_COPx_temp=-(Test_Pred_My[i])/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPx_temp != Test_Pred_COPx_temp:\n",
    "    Test_Pred_COPx_temp=0\n",
    "  Test_Pred_COPx.append(Test_Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPx=[]\n",
    "for i in range(0,len(Test_out_Fz)):\n",
    "  Test_out_COPx_temp=-(Test_out_My[i])/Test_out_Fz[i]\n",
    "  if Test_out_COPx_temp != Test_out_COPx_temp:\n",
    "    Test_out_COPx_temp=0\n",
    "  Test_out_COPx.append(Test_out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_Pred_COPy=[]\n",
    "for i in range(0,len(Test_Pred_Mx)):\n",
    "  Test_Pred_COPy_temp=Test_Pred_Mx[i]/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPy_temp != Test_Pred_COPy_temp:\n",
    "    Test_Pred_COPy_temp=0\n",
    "  Test_Pred_COPy.append(Test_Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPy=[]\n",
    "for i in range(0,len(Test_out_Mx)):\n",
    "  Test_out_COPy_temp=Test_out_Mx[i]/Test_out_Fz[i]\n",
    "  if Test_out_COPy_temp != Test_out_COPy_temp:\n",
    "    Test_out_COPy_temp=0\n",
    "  Test_out_COPy.append(Test_out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "Test_out_COPx = np.array(Test_out_COPx)\n",
    "Test_out_COPx= Test_out_COPx.reshape(-1,1)\n",
    "\n",
    "Test_out_COPy = np.array(Test_out_COPy)\n",
    "Test_out_COPy= Test_out_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPx = np.array(Test_Pred_COPx)\n",
    "Test_Pred_COPx= Test_Pred_COPx.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPy = np.array(Test_Pred_COPy)\n",
    "Test_Pred_COPy= Test_Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COP = np.concatenate((Test_Pred_COPx, Test_Pred_COPy), axis=1)\n",
    "Test_FC_COP = np.concatenate((Test_out_COPx, Test_out_COPy), axis=1)\n",
    "\n",
    "Test_col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000 \n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,Test_FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Test_Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Testing Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "Test_y1 = Test_FC_COP[50:100,0]\n",
    "Test_y2 = Test_FC_COP[50:100,1]\n",
    "Test_y3 = Test_Pred_COP[50:100,0]\n",
    "Test_y4 = Test_Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "# Test_data_filter = abs(y1) > 0\n",
    "# Test_data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(Test_y1[Test_data_filter], Test_y2[Test_data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(Test_y3[Test_data_filter2], Test_y4[Test_data_filter2 ], color='green')\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Testing Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SmartInsole[2900:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_new_inverse2[50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "q7qd6uS3OBZs",
    "outputId": "b6b3d93f-657e-48fb-c376-cad72f55c8f6"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[0:100,0]\n",
    "Test_y2 = Test_FC_COP[0:100,1]\n",
    "Test_y3 = Test_Pred_COP[0:100,0]\n",
    "Test_y4 = Test_Pred_COP[0:100,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "R-fQqEiDOEDM",
    "outputId": "f5a46771-3b48-4093-fb96-7b645b1aaf39"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[100:200,0]\n",
    "Test_y2 = Test_FC_COP[100:200,1]\n",
    "Test_y3 = Test_Pred_COP[100:200,0]\n",
    "Test_y4 = Test_Pred_COP[100:200,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "Isay2TbVOG6F",
    "outputId": "4dc7543c-2fb0-4033-a8ea-f5783e879724"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[200:300,0]\n",
    "Test_y2 = Test_FC_COP[200:300,1]\n",
    "Test_y3 = Test_Pred_COP[200:300,0]\n",
    "Test_y4 = Test_Pred_COP[200:300,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "NlIfrOihUGt7",
    "outputId": "140ea2ee-6558-4efd-ba8e-0175eefb8983"
   },
   "outputs": [],
   "source": [
    "## Model Validation\n",
    "Test_Insole = pd.read_csv('0312AryaStand5Min2.txt', header=None, low_memory=False)\n",
    "TestSIData =  np.asarray(Test_Insole)\n",
    "\n",
    "Test_df = pd.read_csv('0312AryaStand5Min2.csv', low_memory=False)\n",
    "Test_columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "Test_selected_df = Test_df[Test_columns]\n",
    "Test_FPDatas = Test_selected_df[:6000]\n",
    "\n",
    "\n",
    "test_SmartInsole = np.array(TestSIData[:6000]).astype('float64')\n",
    "Test_FPData = np.array(Test_FPDatas).astype('float64')\n",
    "\n",
    "Test_FXData = Test_FPData[:,0]/10\n",
    "Test_FXData =  np.array(Test_FXData)\n",
    "Test_FXData = Test_FXData.reshape(-1,1)\n",
    "Test_FYData = Test_FPData[:,1]/5\n",
    "Test_FYData =  np.array(Test_FYData)\n",
    "Test_FYData = Test_FYData.reshape(-1,1)\n",
    "Test_FZData = (Test_FPData[:,2])/10\n",
    "Test_FZData =  np.array(Test_FZData)\n",
    "Test_FZData = Test_FZData.reshape(-1,1)\n",
    "Test_MXData = (Test_FPData[:,3])/1000\n",
    "Test_MXData =  np.array(Test_MXData)\n",
    "Test_MXData = Test_MXData.reshape(-1,1)\n",
    "Test_MYData = (Test_FPData[:,4])/10000\n",
    "Test_MYData =  np.array(Test_MYData)\n",
    "Test_MYData =Test_MYData.reshape(-1,1)\n",
    "Test_MZData = (Test_FPData[:,5])/100\n",
    "Test_MZData =  np.array(Test_MZData)\n",
    "Test_MZData = Test_MZData.reshape(-1,1)\n",
    "\n",
    "Test_newFPData = np.concatenate((Test_FXData, Test_FYData, Test_FZData, Test_MXData, Test_MYData, Test_MZData), axis=1)\n",
    "## End Load Data\n",
    "Test_newFPData = abs(Test_newFPData)\n",
    "\n",
    "Test_SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(test_SmartInsole[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    # coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "    # coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "    # coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "    # coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "    # coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    # coeffs[-7] = np.zeros_like(coeffs[-7])\n",
    "    Test_SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_SIData_filtered = np.zeros(test_SmartInsole.shape)\n",
    "for i in range(89):\n",
    "    Test_SIData_filtered[:, i] = pywt.waverec(Test_SIDWTcoeffs[i], 'db4', mode='symmetric', axis=0)\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    if i < len(Test_SIData_filtered):\n",
    "        Test_SIData_filtered[i][0] = 0\n",
    "        # Test_SIData_filtered[i][0] = Test_SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "        iter += 1\n",
    "    else:\n",
    "        Test_SIData_filtered[i][0] = 0\n",
    "\n",
    "# for i in range(len(Test_SIData_filtered)):\n",
    "#     Test_SIData_filtered[i][0] = i-1\n",
    "#     iter += 1\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    Test_SIData_filtered[i][np.abs(Test_SIData_filtered[i]) < 1] = 0\n",
    "\n",
    "Test_xscale = (Test_SIData_filtered - minInsole) / ( maxInsole - minInsole )\n",
    "\n",
    "Test_yscale = []\n",
    "for i in range(0,6):\n",
    "  Test_scale = (Test_newFPData[:,i] - FPmin[i]) / ( FPmax[i] - FPmin[i] )\n",
    "  Test_yscale.append(Test_scale)\n",
    "Test_yscale = np.array(Test_yscale)\n",
    "Test_yscale = Test_yscale.transpose()\n",
    "\n",
    "test_sample_size = Test_xscale.shape[0] # number of samples in train set\n",
    "test_time_steps  = Test_xscale.shape[1] # number of features in train set\n",
    "test_input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "test_train_data_reshaped = Test_xscale.reshape(test_sample_size,test_time_steps,test_input_dimension)\n",
    "\n",
    "Regression_Model.evaluate(test_train_data_reshaped, Test_yscale)\n",
    "Test_xX_model = Regression_Model.predict(test_train_data_reshaped)\n",
    "\n",
    "#invert normalize\n",
    "Test_y_inverse = []\n",
    "Test_y_pred_inverse = []\n",
    "\n",
    "for i in range(0,6):\n",
    "  Test_Y_inver =  Test_yscale[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_Pred_inver = Test_xX_model[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_y_inverse.append(Test_Y_inver)\n",
    "  Test_y_pred_inverse.append(Test_Pred_inver)\n",
    "Test_y_inverse = np.array(Test_y_inverse)\n",
    "Test_y_inverse = Test_y_inverse.transpose()\n",
    "Test_y_pred_inverse = np.array(Test_y_pred_inverse)\n",
    "Test_y_pred_inverse = Test_y_pred_inverse.transpose()\n",
    "\n",
    "for i in range(len(Test_y_pred_inverse)):\n",
    "    if (np.abs(Test_y_pred_inverse[i]) < 1).all():\n",
    "        Test_y_pred_inverse[i] = 0\n",
    "\n",
    "for i in range(0, Test_y_pred_inverse.shape[0], 50):\n",
    "    zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "    non_zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "    if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "        Test_y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "# make to original Data\n",
    "Test_FXData2 = Test_y_inverse[:,0]*10\n",
    "Test_FXData2=  np.array(Test_FXData2)\n",
    "Test_FXData2 = Test_FXData2.reshape(-1,1)\n",
    "\n",
    "Test_FYData2 = Test_y_inverse[:,1]*10\n",
    "Test_FYData2 =  np.array(Test_FYData2)\n",
    "Test_FYData2 = Test_FYData2.reshape(-1,1)\n",
    "\n",
    "Test_FZData2 = (Test_y_inverse[:,2]*10)\n",
    "Test_FZData2 =  np.array(Test_FZData2)\n",
    "Test_FZData2 = Test_FZData2.reshape(-1,1)\n",
    "\n",
    "Test_MXData2 = (Test_y_inverse[:,3]*1000)\n",
    "Test_MXData2 =  np.array(Test_MXData2)\n",
    "Test_MXData2 = Test_MXData2.reshape(-1,1)\n",
    "\n",
    "Test_MYData2 = (Test_y_inverse[:,4]*10000)\n",
    "Test_MYData2 =  np.array(Test_MYData2)\n",
    "Test_MYData2 = Test_MYData2.reshape(-1,1\n",
    "                          )\n",
    "Test_MZData2 = (Test_y_inverse[:,5]*100)\n",
    "Test_MZData2 =  np.array(Test_MZData2)\n",
    "Test_MZData2 = Test_MZData2.reshape(-1,1)\n",
    "\n",
    "Test_new_inverse2 = np.concatenate((Test_FXData2, Test_FYData2, Test_FZData2, Test_MXData2, Test_MYData2, Test_MZData2), axis=1)\n",
    "\n",
    "Test_FXData3 = Test_y_pred_inverse[:,0]*10\n",
    "Test_FXData3=  np.array(Test_FXData3)\n",
    "Test_FXData3 = Test_FXData3.reshape(-1,1)\n",
    "\n",
    "Test_FYData3 = Test_y_pred_inverse[:,1]*10\n",
    "Test_FYData3 =  np.array(Test_FYData3)\n",
    "Test_FYData3 = Test_FYData3.reshape(-1,1)\n",
    "\n",
    "Test_FZData3 = (Test_y_pred_inverse[:,2]*10)\n",
    "Test_FZData3 =  np.array(Test_FZData3)\n",
    "Test_FZData3 = Test_FZData3.reshape(-1,1)\n",
    "\n",
    "Test_MXData3 = (Test_y_pred_inverse[:,3]*1000)\n",
    "Test_MXData3 =  np.array(Test_MXData3)\n",
    "Test_MXData3 = Test_MXData3.reshape(-1,1)\n",
    "\n",
    "Test_MYData3 = (Test_y_pred_inverse[:,4]*10000)\n",
    "Test_MYData3 =  np.array(Test_MYData3)\n",
    "Test_MYData3 = Test_MYData3.reshape(-1,1)\n",
    "\n",
    "Test_MZData3 = (Test_y_pred_inverse[:,5]*100)\n",
    "Test_MZData3 =  np.array(Test_MZData3)\n",
    "Test_MZData3 = Test_MZData3.reshape(-1,1)\n",
    "\n",
    "Test_new_inverse3 = np.concatenate((Test_FXData3, Test_FYData3, Test_FZData3, Test_MXData3, Test_MYData3, Test_MZData3), axis=1)\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('CNN Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "Test_out_Fz = Test_new_inverse2[:,2]\n",
    "Test_out_Mx = Test_new_inverse2[:,3]\n",
    "Test_out_My = Test_new_inverse2[:,4]\n",
    "Test_Pred_Fz = Test_new_inverse3[:,2]\n",
    "Test_Pred_Mx = Test_new_inverse3[:,3]\n",
    "Test_Pred_My = Test_new_inverse3[:,4]\n",
    "\n",
    "Test_Pred_COPx=[]\n",
    "for i in range(0,len(Test_Pred_Fz)):\n",
    "  Test_Pred_COPx_temp=-(Test_Pred_My[i])/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPx_temp != Test_Pred_COPx_temp:\n",
    "    Test_Pred_COPx_temp=0\n",
    "  Test_Pred_COPx.append(Test_Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPx=[]\n",
    "for i in range(0,len(Test_out_Fz)):\n",
    "  Test_out_COPx_temp=-(Test_out_My[i])/Test_out_Fz[i]\n",
    "  if Test_out_COPx_temp != Test_out_COPx_temp:\n",
    "    Test_out_COPx_temp=0\n",
    "  Test_out_COPx.append(Test_out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_Pred_COPy=[]\n",
    "for i in range(0,len(Test_Pred_Mx)):\n",
    "  Test_Pred_COPy_temp=Test_Pred_Mx[i]/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPy_temp != Test_Pred_COPy_temp:\n",
    "    Test_Pred_COPy_temp=0\n",
    "  Test_Pred_COPy.append(Test_Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPy=[]\n",
    "for i in range(0,len(Test_out_Mx)):\n",
    "  Test_out_COPy_temp=Test_out_Mx[i]/Test_out_Fz[i]\n",
    "  if Test_out_COPy_temp != Test_out_COPy_temp:\n",
    "    Test_out_COPy_temp=0\n",
    "  Test_out_COPy.append(Test_out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "Test_out_COPx = np.array(Test_out_COPx)\n",
    "Test_out_COPx= Test_out_COPx.reshape(-1,1)\n",
    "\n",
    "Test_out_COPy = np.array(Test_out_COPy)\n",
    "Test_out_COPy= Test_out_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPx = np.array(Test_Pred_COPx)\n",
    "Test_Pred_COPx= Test_Pred_COPx.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPy = np.array(Test_Pred_COPy)\n",
    "Test_Pred_COPy= Test_Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COP = np.concatenate((Test_Pred_COPx, Test_Pred_COPy), axis=1)\n",
    "Test_FC_COP = np.concatenate((Test_out_COPx, Test_out_COPy), axis=1)\n",
    "\n",
    "Test_col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000 \n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,Test_FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Test_Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Testing Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "Test_y1 = Test_FC_COP[50:100,0]\n",
    "Test_y2 = Test_FC_COP[50:100,1]\n",
    "Test_y3 = Test_Pred_COP[50:100,0]\n",
    "Test_y4 = Test_Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "# Test_data_filter = abs(y1) > 0\n",
    "# Test_data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(Test_y1[Test_data_filter], Test_y2[Test_data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(Test_y3[Test_data_filter2], Test_y4[Test_data_filter2 ], color='green')\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Testing Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
