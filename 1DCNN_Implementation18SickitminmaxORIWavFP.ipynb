{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFyb0y7PUJOo"
   },
   "source": [
    "# ResNet Model Building Pipeline for 1D Signals with DEMO\n",
    "#### ResNet18, ResNet34, ResNet50, ResNet101, ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import tornado.iostream\n",
    "\n",
    "# Create a TCP connection to a server running on localhost at port 8000\n",
    "sock = socket.create_connection(('localhost', 8888))\n",
    "\n",
    "# Create an IOStream object with a large buffer size\n",
    "stream = tornado.iostream.IOStream(sock, max_buffer_size=1073741824)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eMhBhz1CrMb3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from numpy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, BatchNormalization, Activation, add\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape, Flatten, Dense\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "# from tensorflow.keras.optimizers import AdamW\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import Normalizer,MinMaxScaler,StandardScaler, RobustScaler, QuantileTransformer, PowerTransformer\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "import pywt\n",
    "np.set_printoptions(suppress=True)\n",
    "# Import ResNet1D Module\n",
    "from ResNet_1DCNN import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeR4-T_yKu00",
    "outputId": "d4c38f3d-2523-47cd-8038-27d5b1807c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105600, 89, 1) (26400, 89, 1)\n",
      "(105600, 6) (26400, 6)\n"
     ]
    }
   ],
   "source": [
    "columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "wavelet = 'db4'\n",
    "max_iter = 50\n",
    "iter = 0\n",
    "\n",
    "# Walking Dataset\n",
    "InsoleWalking1 = pd.read_csv('0310AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking2 = pd.read_csv('0310HudaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking3 = pd.read_csv('0311LalaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking4 = pd.read_csv('0311YunitaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking5 = pd.read_csv('0312AbelRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking6 = pd.read_csv('0312AbiRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking7 = pd.read_csv('0312AryaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking8 = pd.read_csv('0312HawaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking9 = pd.read_csv('0312NisaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking10 = pd.read_csv('0313ChenChengRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking11 = pd.read_csv('0313RezaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking12 = pd.read_csv('0313RilaniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking13 = pd.read_csv('0313SariRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking14 = pd.read_csv('0313ShelbyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking15 = pd.read_csv('0314HelenRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking16 = pd.read_csv('0315AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking17 = pd.read_csv('0315HappyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking18 = pd.read_csv('0317HeniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking19 = pd.read_csv('0317NadiaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking20 = pd.read_csv('0317VikaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking21 = pd.read_csv('0319AlfianRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking22 = pd.read_csv('1225JakariaRWalk5Min.txt', header=None, low_memory=False)\n",
    "SIDatasWalking1 =  np.array(InsoleWalking1)\n",
    "SIDatasWalking2 =  np.array(InsoleWalking2)\n",
    "SIDatasWalking3 =  np.array(InsoleWalking3)\n",
    "SIDatasWalking4 =  np.array(InsoleWalking4)\n",
    "SIDatasWalking5 =  np.array(InsoleWalking5)\n",
    "SIDatasWalking6 =  np.array(InsoleWalking6)\n",
    "SIDatasWalking7 =  np.array(InsoleWalking7)\n",
    "SIDatasWalking8 =  np.array(InsoleWalking8)\n",
    "SIDatasWalking9 =  np.array(InsoleWalking9)\n",
    "SIDatasWalking10 =  np.array(InsoleWalking10)\n",
    "SIDatasWalking11 =  np.array(InsoleWalking11)\n",
    "SIDatasWalking12 =  np.array(InsoleWalking12)\n",
    "SIDatasWalking13 =  np.array(InsoleWalking13)\n",
    "SIDatasWalking14 =  np.array(InsoleWalking14)\n",
    "SIDatasWalking15 =  np.array(InsoleWalking15)\n",
    "SIDatasWalking16 =  np.array(InsoleWalking16)\n",
    "SIDatasWalking17 =  np.array(InsoleWalking17)\n",
    "SIDatasWalking18 =  np.array(InsoleWalking18)\n",
    "SIDatasWalking19 =  np.array(InsoleWalking19)\n",
    "SIDatasWalking20 =  np.array(InsoleWalking20)\n",
    "SIDatasWalking21 =  np.array(InsoleWalking21)\n",
    "SIDatasWalking22 =  np.array(InsoleWalking22)\n",
    "\n",
    "dfwalk1 = pd.read_csv('0310AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk2 = pd.read_csv('0310HudaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk3 = pd.read_csv('0311LalaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk4 = pd.read_csv('0311YunitaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk5 = pd.read_csv('0312AbelRWalk5Min.csv', low_memory=False)\n",
    "dfwalk6 = pd.read_csv('0312AbiRWalk5Min.csv', low_memory=False)\n",
    "dfwalk7 = pd.read_csv('0312AryaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk8 = pd.read_csv('0312HawaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk9 = pd.read_csv('0312NisaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk10 = pd.read_csv('0313ChenChengRWalk5Min.csv', low_memory=False)\n",
    "dfwalk11 = pd.read_csv('0313RezaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk12 = pd.read_csv('0313RilaniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk13 = pd.read_csv('0313SariRWalk5Min.csv', low_memory=False)\n",
    "dfwalk14 = pd.read_csv('0313ShelbyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk15 = pd.read_csv('0314HelenRWalk5Min.csv', low_memory=False)\n",
    "dfwalk16 = pd.read_csv('0315AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk17 = pd.read_csv('0315HappyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk18 = pd.read_csv('0317HeniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk19 = pd.read_csv('0317NadiaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk20 = pd.read_csv('0317VikaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk21 = pd.read_csv('0319AlfianRWalk5Min.csv', low_memory=False)\n",
    "dfwalk22 = pd.read_csv('1225JakariaRWalk5Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfwalks1 = dfwalk1[columns]\n",
    "selected_dfwalks2 = dfwalk2[columns]\n",
    "selected_dfwalks3 = dfwalk3[columns]\n",
    "selected_dfwalks4 = dfwalk4[columns]\n",
    "selected_dfwalks5 = dfwalk5[columns]\n",
    "selected_dfwalks6 = dfwalk6[columns]\n",
    "selected_dfwalks7 = dfwalk7[columns]\n",
    "selected_dfwalks8 = dfwalk8[columns]\n",
    "selected_dfwalks9 = dfwalk9[columns]\n",
    "selected_dfwalks10 = dfwalk10[columns]\n",
    "selected_dfwalks11 = dfwalk11[columns]\n",
    "selected_dfwalks12 = dfwalk12[columns]\n",
    "selected_dfwalks13 = dfwalk13[columns]\n",
    "selected_dfwalks14 = dfwalk14[columns]\n",
    "selected_dfwalks15 = dfwalk15[columns]\n",
    "selected_dfwalks16 = dfwalk16[columns]\n",
    "selected_dfwalks17 = dfwalk17[columns]\n",
    "selected_dfwalks18 = dfwalk18[columns]\n",
    "selected_dfwalks19 = dfwalk19[columns]\n",
    "selected_dfwalks20 = dfwalk20[columns]\n",
    "selected_dfwalks21 = dfwalk21[columns]\n",
    "selected_dfwalks22 = dfwalk22[columns]\n",
    "FPDatasWalking1 = selected_dfwalks1[:15000]\n",
    "FPDatasWalking2 = selected_dfwalks2[:15000]\n",
    "FPDatasWalking3 = selected_dfwalks3[:15000]\n",
    "FPDatasWalking4 = selected_dfwalks4[:15000]\n",
    "FPDatasWalking5 = selected_dfwalks5[:15000]\n",
    "FPDatasWalking6 = selected_dfwalks6[:15000]\n",
    "FPDatasWalking7 = selected_dfwalks7[:15000]\n",
    "FPDatasWalking8 = selected_dfwalks8[:15000]\n",
    "FPDatasWalking9 = selected_dfwalks9[:15000]\n",
    "FPDatasWalking10 = selected_dfwalks10[:15000]\n",
    "FPDatasWalking11 = selected_dfwalks11[:15000]\n",
    "FPDatasWalking12 = selected_dfwalks12[:15000]\n",
    "FPDatasWalking13 = selected_dfwalks13[:15000]\n",
    "FPDatasWalking14 = selected_dfwalks14[:15000]\n",
    "FPDatasWalking15 = selected_dfwalks15[:15000]\n",
    "FPDatasWalking16 = selected_dfwalks16[:15000]\n",
    "FPDatasWalking17 = selected_dfwalks17[:15000]\n",
    "FPDatasWalking18 = selected_dfwalks18[:15000]\n",
    "FPDatasWalking19 = selected_dfwalks19[:15000]\n",
    "FPDatasWalking20 = selected_dfwalks20[:15000]\n",
    "FPDatasWalking21 = selected_dfwalks21[:15000]\n",
    "FPDatasWalking22 = selected_dfwalks22[:15000]\n",
    "\n",
    "SIDataWalking1 = np.array(SIDatasWalking1[:15000]).astype('float32')\n",
    "SIDataWalking2 = np.array(SIDatasWalking2[:15000]).astype('float32')\n",
    "SIDataWalking3 = np.array(SIDatasWalking3[:15000]).astype('float32')\n",
    "SIDataWalking4 = np.array(SIDatasWalking4[:15000]).astype('float32')\n",
    "SIDataWalking5 = np.array(SIDatasWalking5[:15000]).astype('float32')\n",
    "SIDataWalking6 = np.array(SIDatasWalking6[:15000]).astype('float32')\n",
    "SIDataWalking7 = np.array(SIDatasWalking7[:15000]).astype('float32')\n",
    "SIDataWalking8 = np.array(SIDatasWalking8[:15000]).astype('float32')\n",
    "SIDataWalking9 = np.array(SIDatasWalking9[:15000]).astype('float32')\n",
    "SIDataWalking10 = np.array(SIDatasWalking10[:15000]).astype('float32')\n",
    "SIDataWalking11 = np.array(SIDatasWalking11[:15000]).astype('float32')\n",
    "SIDataWalking12 = np.array(SIDatasWalking12[:15000]).astype('float32')\n",
    "SIDataWalking13 = np.array(SIDatasWalking13[:15000]).astype('float32')\n",
    "SIDataWalking14 = np.array(SIDatasWalking14[:15000]).astype('float32')\n",
    "SIDataWalking15 = np.array(SIDatasWalking15[:15000]).astype('float32')\n",
    "SIDataWalking16 = np.array(SIDatasWalking16[:15000]).astype('float32')\n",
    "SIDataWalking17 = np.array(SIDatasWalking17[:15000]).astype('float32')\n",
    "SIDataWalking18 = np.array(SIDatasWalking18[:15000]).astype('float32')\n",
    "SIDataWalking19 = np.array(SIDatasWalking19[:15000]).astype('float32')\n",
    "SIDataWalking20 = np.array(SIDatasWalking20[:15000]).astype('float32')\n",
    "SIDataWalking21 = np.array(SIDatasWalking21[:15000]).astype('float32')\n",
    "SIDataWalking22 = np.array(SIDatasWalking22[:15000]).astype('float32')\n",
    "FPDataWalking1 = np.array(FPDatasWalking1).astype('float32')\n",
    "FPDataWalking2 = np.array(FPDatasWalking2).astype('float32')\n",
    "FPDataWalking3= np.array(FPDatasWalking3).astype('float32')\n",
    "FPDataWalking4= np.array(FPDatasWalking4).astype('float32')\n",
    "FPDataWalking5= np.array(FPDatasWalking5).astype('float32')\n",
    "FPDataWalking6= np.array(FPDatasWalking6).astype('float32')\n",
    "FPDataWalking7= np.array(FPDatasWalking7).astype('float32')\n",
    "FPDataWalking8= np.array(FPDatasWalking8).astype('float32')\n",
    "FPDataWalking9= np.array(FPDatasWalking9).astype('float32')\n",
    "FPDataWalking10 = np.array(FPDatasWalking10).astype('float32')\n",
    "FPDataWalking11 = np.array(FPDatasWalking11).astype('float32')\n",
    "FPDataWalking12= np.array(FPDatasWalking12).astype('float32')\n",
    "FPDataWalking13= np.array(FPDatasWalking13).astype('float32')\n",
    "FPDataWalking14= np.array(FPDatasWalking14).astype('float32')\n",
    "FPDataWalking15= np.array(FPDatasWalking15).astype('float32')\n",
    "FPDataWalking16= np.array(FPDatasWalking16).astype('float32')\n",
    "FPDataWalking17= np.array(FPDatasWalking17).astype('float32')\n",
    "FPDataWalking18= np.array(FPDatasWalking18).astype('float32')\n",
    "FPDataWalking19= np.array(FPDatasWalking19).astype('float32')\n",
    "FPDataWalking20= np.array(FPDatasWalking20).astype('float32')\n",
    "FPDataWalking21= np.array(FPDatasWalking21).astype('float32')\n",
    "FPDataWalking22= np.array(FPDatasWalking22).astype('float32')\n",
    "\n",
    "SIDatasetWalking = np.concatenate((SIDataWalking1, SIDataWalking2, SIDataWalking3,\n",
    "                            SIDataWalking4, SIDataWalking5, SIDataWalking6,\n",
    "                            SIDataWalking7, SIDataWalking8, SIDataWalking9,\n",
    "                            SIDataWalking10, SIDataWalking11, SIDataWalking12,\n",
    "                            SIDataWalking13, SIDataWalking14, SIDataWalking15,\n",
    "                            SIDataWalking16, SIDataWalking17, SIDataWalking18,\n",
    "                            SIDataWalking19, SIDataWalking20, SIDataWalking21,\n",
    "                            SIDataWalking22), axis=0)\n",
    "                            \n",
    "FPDatasetWalking = np.concatenate((FPDataWalking1, FPDataWalking2, FPDataWalking3,\n",
    "                            FPDataWalking4, FPDataWalking5, FPDataWalking6,\n",
    "                            FPDataWalking7, FPDataWalking8, FPDataWalking9,\n",
    "                            FPDataWalking10, FPDataWalking11, FPDataWalking12,\n",
    "                            FPDataWalking13, FPDataWalking14, FPDataWalking15,\n",
    "                            FPDataWalking16, FPDataWalking17, FPDataWalking18,\n",
    "                            FPDataWalking19, FPDataWalking20, FPDataWalking21,\n",
    "                            FPDataWalking22), axis=0)\n",
    "\n",
    "# SIDatasetWalking = SIDataWalking1\n",
    "# FPDatasetWalking = FPDataWalking1\n",
    "\n",
    "# SIDatasetWalking = np.array(SIDatasetWalking).astype('float64')\n",
    "# FPDatasetWalking = np.array(FPDatasetWalking).astype('float64')\n",
    "\n",
    "# Standing Dataset\n",
    "InsoleStanding1 = pd.read_csv('0310AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding2 = pd.read_csv('0310HudaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding3 = pd.read_csv('0311LalaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding4 = pd.read_csv('0311YunitaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding5 = pd.read_csv('0312AbelStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding6 = pd.read_csv('0312AbiStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding7 = pd.read_csv('0312AryaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding8 = pd.read_csv('0312HawaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding9 = pd.read_csv('0312NisaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding10 = pd.read_csv('0313ChenChengStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding11 = pd.read_csv('0313RezaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding12 = pd.read_csv('0313RilaniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding13 = pd.read_csv('0313SariStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding14 = pd.read_csv('0313ShelbyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding15 = pd.read_csv('0314HelenStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding16 = pd.read_csv('0315AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding17 = pd.read_csv('0315HappyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding18 = pd.read_csv('0317HeniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding19 = pd.read_csv('0317NadiaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding20 = pd.read_csv('0317VikaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding21 = pd.read_csv('0319AlfianStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding22 = pd.read_csv('0310JakaStand2Min.txt', header=None, low_memory=False)\n",
    "SIDatasStanding1 =  np.array(InsoleStanding1)\n",
    "SIDatasStanding2 =  np.array(InsoleStanding2)\n",
    "SIDatasStanding3 =  np.array(InsoleStanding3)\n",
    "SIDatasStanding4 =  np.array(InsoleStanding4)\n",
    "SIDatasStanding5 =  np.array(InsoleStanding5)\n",
    "SIDatasStanding6 =  np.array(InsoleStanding6)\n",
    "SIDatasStanding7 =  np.array(InsoleStanding7)\n",
    "SIDatasStanding8 =  np.array(InsoleStanding8)\n",
    "SIDatasStanding9 =  np.array(InsoleStanding9)\n",
    "SIDatasStanding10 =  np.array(InsoleStanding10)\n",
    "SIDatasStanding11 =  np.array(InsoleStanding11)\n",
    "SIDatasStanding12 =  np.array(InsoleStanding12)\n",
    "SIDatasStanding13 =  np.array(InsoleStanding13)\n",
    "SIDatasStanding14 =  np.array(InsoleStanding14)\n",
    "SIDatasStanding15 =  np.array(InsoleStanding15)\n",
    "SIDatasStanding16 =  np.array(InsoleStanding16)\n",
    "SIDatasStanding17 =  np.array(InsoleStanding17)\n",
    "SIDatasStanding18 =  np.array(InsoleStanding18)\n",
    "SIDatasStanding19 =  np.array(InsoleStanding19)\n",
    "SIDatasStanding20 =  np.array(InsoleStanding20)\n",
    "SIDatasStanding21 =  np.array(InsoleStanding21)\n",
    "SIDatasStanding22 =  np.array(InsoleStanding22)\n",
    "\n",
    "dfStanding1 = pd.read_csv('0310AyuStand5Min1.csv', low_memory=False)\n",
    "dfStanding2 = pd.read_csv('0310HudaStand5Min1.csv', low_memory=False)\n",
    "dfStanding3 = pd.read_csv('0311LalaStand5Min1.csv', low_memory=False)\n",
    "dfStanding4 = pd.read_csv('0311YunitaStand5Min1.csv', low_memory=False)\n",
    "dfStanding5 = pd.read_csv('0312AbelStand5Min1.csv', low_memory=False)\n",
    "dfStanding6 = pd.read_csv('0312AbiStand5Min1.csv', low_memory=False)\n",
    "dfStanding7 = pd.read_csv('0312AryaStand5Min1.csv', low_memory=False)\n",
    "dfStanding8 = pd.read_csv('0312HawaStand5Min1.csv', low_memory=False)\n",
    "dfStanding9 = pd.read_csv('0312NisaStand5Min1.csv', low_memory=False)\n",
    "dfStanding10 = pd.read_csv('0313ChenChengStand5Min1.csv', low_memory=False)\n",
    "dfStanding11 = pd.read_csv('0313RezaStand5Min1.csv', low_memory=False)\n",
    "dfStanding12 = pd.read_csv('0313RilaniStand5Min1.csv', low_memory=False)\n",
    "dfStanding13 = pd.read_csv('0313SariStand5Min1.csv', low_memory=False)\n",
    "dfStanding14 = pd.read_csv('0313ShelbyStand5Min1.csv', low_memory=False)\n",
    "dfStanding15 = pd.read_csv('0314HelenStand5Min1.csv', low_memory=False)\n",
    "dfStanding16 = pd.read_csv('0315AyuStand5Min1.csv', low_memory=False)\n",
    "dfStanding17 = pd.read_csv('0315HappyStand5Min1.csv', low_memory=False)\n",
    "dfStanding18 = pd.read_csv('0317HeniStand5Min1.csv', low_memory=False)\n",
    "dfStanding19 = pd.read_csv('0317NadiaStand5Min1.csv', low_memory=False)\n",
    "dfStanding20 = pd.read_csv('0317VikaStand5Min1.csv', low_memory=False)\n",
    "dfStanding21 = pd.read_csv('0319AlfianStand5Min1.csv', low_memory=False)\n",
    "dfStanding22 = pd.read_csv('0310JakaStand2Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfStandings1 = dfStanding1[columns]\n",
    "selected_dfStandings2 = dfStanding2[columns]\n",
    "selected_dfStandings3 = dfStanding3[columns]\n",
    "selected_dfStandings4 = dfStanding4[columns]\n",
    "selected_dfStandings5 = dfStanding5[columns]\n",
    "selected_dfStandings6 = dfStanding6[columns]\n",
    "selected_dfStandings7 = dfStanding7[columns]\n",
    "selected_dfStandings8 = dfStanding8[columns]\n",
    "selected_dfStandings9 = dfStanding9[columns]\n",
    "selected_dfStandings10 = dfStanding10[columns]\n",
    "selected_dfStandings11 = dfStanding11[columns]\n",
    "selected_dfStandings12 = dfStanding12[columns]\n",
    "selected_dfStandings13 = dfStanding13[columns]\n",
    "selected_dfStandings14 = dfStanding14[columns]\n",
    "selected_dfStandings15 = dfStanding15[columns]\n",
    "selected_dfStandings16 = dfStanding16[columns]\n",
    "selected_dfStandings17 = dfStanding17[columns]\n",
    "selected_dfStandings18 = dfStanding18[columns]\n",
    "selected_dfStandings19 = dfStanding19[columns]\n",
    "selected_dfStandings20 = dfStanding20[columns]\n",
    "selected_dfStandings21 = dfStanding21[columns]\n",
    "selected_dfStandings22 = dfStanding22[columns]\n",
    "FPDataStandings1 = selected_dfStandings1[:6000]\n",
    "FPDataStandings2 = selected_dfStandings2[:6000]\n",
    "FPDataStandings3 = selected_dfStandings3[:6000]\n",
    "FPDataStandings4 = selected_dfStandings4[:6000]\n",
    "FPDataStandings5 = selected_dfStandings5[:6000]\n",
    "FPDataStandings6 = selected_dfStandings6[:6000]\n",
    "FPDataStandings7 = selected_dfStandings7[:6000]\n",
    "FPDataStandings8 = selected_dfStandings8[:6000]\n",
    "FPDataStandings9 = selected_dfStandings9[:6000]\n",
    "FPDataStandings10 = selected_dfStandings10[:6000]\n",
    "FPDataStandings11 = selected_dfStandings11[:6000]\n",
    "FPDataStandings12 = selected_dfStandings12[:6000]\n",
    "FPDataStandings13 = selected_dfStandings13[:6000]\n",
    "FPDataStandings14 = selected_dfStandings14[:6000]\n",
    "FPDataStandings15 = selected_dfStandings15[:6000]\n",
    "FPDataStandings16 = selected_dfStandings16[:6000]\n",
    "FPDataStandings17 = selected_dfStandings17[:6000]\n",
    "FPDataStandings18 = selected_dfStandings18[:6000]\n",
    "FPDataStandings19 = selected_dfStandings19[:6000]\n",
    "FPDataStandings20 = selected_dfStandings20[:6000]\n",
    "FPDataStandings21 = selected_dfStandings21[:6000]\n",
    "FPDataStandings22 = selected_dfStandings22[:6000]\n",
    "\n",
    "SIDataStanding1 = np.array(SIDatasStanding1[:6000]).astype('float32')\n",
    "SIDataStanding2 = np.array(SIDatasStanding2[:6000]).astype('float32')\n",
    "SIDataStanding3 = np.array(SIDatasStanding3[:6000]).astype('float32')\n",
    "SIDataStanding4 = np.array(SIDatasStanding4[:6000]).astype('float32')\n",
    "SIDataStanding5 = np.array(SIDatasStanding5[:6000]).astype('float32')\n",
    "SIDataStanding6 = np.array(SIDatasStanding6[:6000]).astype('float32')\n",
    "SIDataStanding7 = np.array(SIDatasStanding7[:6000]).astype('float32')\n",
    "SIDataStanding8 = np.array(SIDatasStanding8[:6000]).astype('float32')\n",
    "SIDataStanding9 = np.array(SIDatasStanding9[:6000]).astype('float32')\n",
    "SIDataStanding10 = np.array(SIDatasStanding10[:6000]).astype('float32')\n",
    "SIDataStanding11 = np.array(SIDatasStanding11[:6000]).astype('float32')\n",
    "SIDataStanding12 = np.array(SIDatasStanding12[:6000]).astype('float32')\n",
    "SIDataStanding13 = np.array(SIDatasStanding13[:6000]).astype('float32')\n",
    "SIDataStanding14 = np.array(SIDatasStanding14[:6000]).astype('float32')\n",
    "SIDataStanding15 = np.array(SIDatasStanding15[:6000]).astype('float32')\n",
    "SIDataStanding16 = np.array(SIDatasStanding16[:6000]).astype('float32')\n",
    "SIDataStanding17 = np.array(SIDatasStanding17[:6000]).astype('float32')\n",
    "SIDataStanding18 = np.array(SIDatasStanding18[:6000]).astype('float32')\n",
    "SIDataStanding19 = np.array(SIDatasStanding19[:6000]).astype('float32')\n",
    "SIDataStanding20 = np.array(SIDatasStanding20[:6000]).astype('float32')\n",
    "SIDataStanding21 = np.array(SIDatasStanding21[:6000]).astype('float32')\n",
    "SIDataStanding22 = np.array(SIDatasStanding22[:6000]).astype('float32')\n",
    "FPDataStanding1 = np.array(FPDataStandings1).astype('float32')\n",
    "FPDataStanding2 = np.array(FPDataStandings2).astype('float32')\n",
    "FPDataStanding3= np.array(FPDataStandings3).astype('float32')\n",
    "FPDataStanding4= np.array(FPDataStandings4).astype('float32')\n",
    "FPDataStanding5= np.array(FPDataStandings5).astype('float32')\n",
    "FPDataStanding6= np.array(FPDataStandings6).astype('float32')\n",
    "FPDataStanding7= np.array(FPDataStandings7).astype('float32')\n",
    "FPDataStanding8= np.array(FPDataStandings8).astype('float32')\n",
    "FPDataStanding9= np.array(FPDataStandings9).astype('float32')\n",
    "FPDataStanding10 = np.array(FPDataStandings10).astype('float32')\n",
    "FPDataStanding11 = np.array(FPDataStandings11).astype('float32')\n",
    "FPDataStanding12= np.array(FPDataStandings12).astype('float32')\n",
    "FPDataStanding13= np.array(FPDataStandings13).astype('float32')\n",
    "FPDataStanding14= np.array(FPDataStandings14).astype('float32')\n",
    "FPDataStanding15= np.array(FPDataStandings15).astype('float32')\n",
    "FPDataStanding16= np.array(FPDataStandings16).astype('float32')\n",
    "FPDataStanding17= np.array(FPDataStandings17).astype('float32')\n",
    "FPDataStanding18= np.array(FPDataStandings18).astype('float32')\n",
    "FPDataStanding19= np.array(FPDataStandings19).astype('float32')\n",
    "FPDataStanding20= np.array(FPDataStandings20).astype('float32')\n",
    "FPDataStanding21= np.array(FPDataStandings21).astype('float32')\n",
    "FPDataStanding22= np.array(FPDataStandings22).astype('float32')\n",
    "\n",
    "SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3,\n",
    "                            SIDataStanding4, SIDataStanding5, SIDataStanding6,\n",
    "                            SIDataStanding7, SIDataStanding8, SIDataStanding9,\n",
    "                            SIDataStanding10, SIDataStanding11, SIDataStanding12,\n",
    "                            SIDataStanding13, SIDataStanding14, SIDataStanding15,\n",
    "                            SIDataStanding16, SIDataStanding17, SIDataStanding18,\n",
    "                            SIDataStanding19, SIDataStanding20, SIDataStanding21,\n",
    "                            SIDataStanding22), axis=0)\n",
    "\n",
    "# SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3), axis=0)\n",
    "# FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3), axis=0)\n",
    "                            \n",
    "FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3,\n",
    "                            FPDataStanding4, FPDataStanding5, FPDataStanding6,\n",
    "                            FPDataStanding7, FPDataStanding8, FPDataStanding9,\n",
    "                            FPDataStanding10, FPDataStanding11, FPDataStanding12,\n",
    "                            FPDataStanding13, FPDataStanding14, FPDataStanding15,\n",
    "                            FPDataStanding16, FPDataStanding17, FPDataStanding18,\n",
    "                            FPDataStanding19, FPDataStanding20, FPDataStanding21,\n",
    "                            FPDataStanding22), axis=0)\n",
    "\n",
    "# SIDatasetStanding = SIDataStanding1\n",
    "# FPDatasetStanding = FPDataStanding1\n",
    "\n",
    "SIDatasetStanding = np.array(SIDatasetStanding).astype('float32')\n",
    "FPDatasetStanding = np.array(FPDatasetStanding).astype('float32')\n",
    "\n",
    "# Concat Standing and Walking\n",
    "# SIDataset = np.concatenate((SIDatasetWalking,SIDatasetStanding), axis=0)\n",
    "# FPDataset = np.concatenate((FPDatasetWalking,FPDatasetStanding), axis=0)\n",
    "SIDataset = SIDatasetStanding\n",
    "FPDataset = FPDatasetStanding\n",
    "\n",
    "# SIDataset = SIDatasetStanding\n",
    "# FPDataset = FPDatasetStanding\n",
    "\n",
    "FXData = FPDataset[:,0]/2\n",
    "FXData =  np.array(FXData)\n",
    "FXData = FXData.reshape(-1,1)\n",
    "FYData = FPDataset[:,1]/5\n",
    "FYData =  np.array(FYData)\n",
    "FYData = FYData.reshape(-1,1)\n",
    "FZData = (FPDataset[:,2])/100\n",
    "FZData =  np.array(FZData)\n",
    "FZData = FZData.reshape(-1,1)\n",
    "MXData = (FPDataset[:,3])/10000\n",
    "MXData =  np.array(MXData)\n",
    "MXData = MXData.reshape(-1,1)\n",
    "MYData = (FPDataset[:,4])/10000\n",
    "MYData =  np.array(MYData)\n",
    "MYData = MYData.reshape(-1,1)\n",
    "MZData = (FPDataset[:,5])/1000\n",
    "MZData =  np.array(MZData)\n",
    "MZData = MZData.reshape(-1,1)\n",
    "\n",
    "newFPDataset = np.concatenate((FXData, FYData, FZData, MXData, MYData, MZData), axis=1)\n",
    "## End Load Data\n",
    "\n",
    "wavelet = 'db4'\n",
    "\n",
    "SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(SIDataset[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "    coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "    coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "    coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "    coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "SIData_filtered = np.zeros(SIDataset.shape)\n",
    "for i in range(89):\n",
    "    SIData_filtered[:, i] = pywt.waverec(SIDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "# max_iter = 50\n",
    "# iter = 0\n",
    "# for i in range(len(SIData_filtered)):\n",
    "#     SIData_filtered[i][0] = SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "#     iter += 1\n",
    "\n",
    "for i in range(len(SIDataset)):\n",
    "    if i < len(SIDatasetWalking):\n",
    "#         SIData_filtered[i][0] = 0\n",
    "        SIData_filtered[i][0] = np.round(SIData_filtered[i][0] + (iter % max_iter) + 1,0)\n",
    "        iter += 1\n",
    "    else:\n",
    "        SIData_filtered[i][0] = 0\n",
    "        # SIData_filtered[i][0] = i-314999\n",
    "\n",
    "for i in range(len(SIData_filtered)):\n",
    "    SIData_filtered[i][np.abs(SIData_filtered[i]) < 1] = 0\n",
    "    \n",
    "FPDWTcoeffs = []\n",
    "for i in range(6):\n",
    "    coeffs = pywt.wavedec(newFPDataset[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "    coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "    coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "    coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "    coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    FPDWTcoeffs.append(coeffs)\n",
    "\n",
    "FPData_filtered = np.zeros(newFPDataset.shape)\n",
    "for i in range(6):\n",
    "    FPData_filtered[:, i] = pywt.waverec(FPDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "# Data Normalization\n",
    "scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_x.fit(SIData_filtered)\n",
    "xscale = scaler_x.transform(SIData_filtered)\n",
    "\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y.fit(FPData_filtered)\n",
    "yscale = scaler_y.transform(FPData_filtered)\n",
    "#End Data Normalization\n",
    "\n",
    "#Spliting Data\n",
    "sample_size = xscale.shape[0] # number of samples in train set\n",
    "time_steps  = xscale.shape[1] # number of features in train set\n",
    "input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "train_data_reshaped = xscale.reshape(sample_size,time_steps,input_dimension)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_reshaped, yscale, test_size=0.20, random_state=2)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n",
    "#End Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VzoiWHFxvYWl",
    "outputId": "c059e419-eca8-4187-d1d7-7b47d8934dbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,  48.53626251,  61.97613907,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,  54.32222366,  44.44361496,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,  29.50403976,  49.99699783,  37.55599594,\n",
       "         0.        ,  15.80661869,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "        61.02895737,  50.29193878,   3.02869129,   5.75435448,\n",
       "        22.06497383,  10.66202259,   0.        ,  15.24681091,\n",
       "        17.59612274,  51.18689728,  69.73716736,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   9.83272743,  19.34981728,\n",
       "         0.        ,   8.67493534,  27.46739578,   9.22700214,\n",
       "        82.78890991, 118.4275589 ,  64.13658142,  90.15716553,\n",
       "        35.4559021 ,   0.        ,   7.75289297,   0.        ,\n",
       "         0.        ,   0.        ,  44.78297424, 109.79719543,\n",
       "       121.38256073,  90.10142517,   0.        ,  55.01996994,\n",
       "         0.        ,   0.        ,   0.        ,  49.85046387,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIData_filtered[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z42vOnjv_1cE",
    "outputId": "5aaeb048-fc53-4df5-a5ba-5a0ebdd0f2af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.752735 ,  1.16801  , -3.9976401, -0.319121 , -7.4322705,\n",
       "       -3.8692   ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newFPDataset[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6IOf_sFx5Dm"
   },
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tFqNbe_vch4u"
   },
   "outputs": [],
   "source": [
    "\"Configurations for ResNet in Regression Mode\"\n",
    "length = X_train.shape[1]   # Number of Features (or length of the signal)\n",
    "model_width = 64           # Number of Filter or Kernel in the Input Layer\n",
    "num_channel = 1             # Number of Input Channels\n",
    "problem_type = 'Regression' # Regression or Classification\n",
    "output_number = 6           # Number of Outputs in the Regression Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1L543Qc_x7AB"
   },
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nq-4BfWjcSHf"
   },
   "outputs": [],
   "source": [
    "class AdamW(Adam):\n",
    "    def __init__(self, learning_rate=0.0001, weight_decay=0.01, **kwargs):\n",
    "        super(AdamW, self).__init__(learning_rate, **kwargs)\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def get_gradients(self, loss, params):\n",
    "        gradients = super(AdamW, self).get_gradients(loss, params)\n",
    "        if self.weight_decay > 0.0:\n",
    "            for i in range(len(gradients)):\n",
    "                if gradients[i] is not None:\n",
    "                    gradients[i] += self.weight_decay * params[i]\n",
    "        return gradients\n",
    "\n",
    "Regression_Model = ResNet(length, num_channel, model_width, problem_type=problem_type, output_nums=output_number).ResNet18() # Build Model\n",
    "# ResNet Models supported: ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, \n",
    "Regression_Model.compile(loss='mse', optimizer=AdamW(learning_rate=0.0001, weight_decay=0.01), metrics= ['mse']) # Compile Model\n",
    "# Here, Model validation metric is set as Mean Squared Error or MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nu7h2qmWx-Jg"
   },
   "source": [
    "Model_Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLz469jDhJWx",
    "outputId": "85690d69-f6cf-4e1f-964e-112af4accc6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 89, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 45, 64)       512         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 45, 64)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 22, 64)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 22, 64)       12352       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 22, 64)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 22, 64)       12352       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 22, 64)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 22, 64)       0           ['activation_2[0][0]',           \n",
      "                                                                  'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 22, 64)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 22, 64)       12352       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 22, 64)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 22, 64)       12352       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 22, 64)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 22, 64)       0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 22, 64)       0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 11, 128)      24704       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 11, 128)      0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 11, 128)      49280       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 11, 128)      0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 11, 128)      49280       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 11, 128)      0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 11, 128)      49280       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 11, 128)      0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 11, 128)      0           ['activation_10[0][0]',          \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 11, 128)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 6, 256)       98560       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 6, 256)       0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 6, 256)       196864      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 6, 256)       0           ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 6, 256)       196864      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 6, 256)       0           ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 6, 256)       196864      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 6, 256)       0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 6, 256)       0           ['activation_15[0][0]',          \n",
      "                                                                  'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 6, 256)       0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 3, 512)       393728      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 3, 512)       0           ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_14 (Conv1D)             (None, 3, 512)       786944      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 3, 512)       0           ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 3, 512)       786944      ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 3, 512)       0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 3, 512)       786944      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 3, 512)       0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 3, 512)       0           ['activation_20[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 3, 512)       0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['activation_21[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            3078        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,669,254\n",
      "Trainable params: 3,669,254\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Regression_Model.summary() # Summary of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vHdlpJFx_14"
   },
   "source": [
    "Upload Past Weights if available (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SSW2BfUMqs7A"
   },
   "outputs": [],
   "source": [
    "# Regression_Model.load_weights('Saved_Model.h5') # Load Previously Trained Weights for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSicHIFzyCky"
   },
   "source": [
    "Train Model for 'n' number of Epochs with Batch size of 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuaVIjBviw7n",
    "outputId": "751c008c-6b1c-4fd8-d84c-05467ed173e9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5276/5280 [============================>.] - ETA: 0s - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 1: val_loss improved from inf to 0.00137, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 54s 10ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 2/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 2: val_loss improved from 0.00137 to 0.00112, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 3/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 9.9715e-04 - mse: 9.9715e-04\n",
      "Epoch 3: val_loss improved from 0.00112 to 0.00082, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 9.9715e-04 - mse: 9.9715e-04 - val_loss: 8.1565e-04 - val_mse: 8.1565e-04\n",
      "Epoch 4/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 7.7116e-04 - mse: 7.7116e-04\n",
      "Epoch 4: val_loss improved from 0.00082 to 0.00066, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 7.7116e-04 - mse: 7.7116e-04 - val_loss: 6.6308e-04 - val_mse: 6.6308e-04\n",
      "Epoch 5/500\n",
      "5279/5280 [============================>.] - ETA: 0s - loss: 6.3465e-04 - mse: 6.3465e-04\n",
      "Epoch 5: val_loss improved from 0.00066 to 0.00052, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 6.3460e-04 - mse: 6.3460e-04 - val_loss: 5.1938e-04 - val_mse: 5.1938e-04\n",
      "Epoch 6/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 5.3255e-04 - mse: 5.3255e-04\n",
      "Epoch 6: val_loss improved from 0.00052 to 0.00050, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 5.3247e-04 - mse: 5.3247e-04 - val_loss: 5.0232e-04 - val_mse: 5.0232e-04\n",
      "Epoch 7/500\n",
      "5278/5280 [============================>.] - ETA: 0s - loss: 4.5982e-04 - mse: 4.5982e-04\n",
      "Epoch 7: val_loss improved from 0.00050 to 0.00045, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 53s 10ms/step - loss: 4.5986e-04 - mse: 4.5986e-04 - val_loss: 4.4908e-04 - val_mse: 4.4908e-04\n",
      "Epoch 8/500\n",
      "5279/5280 [============================>.] - ETA: 0s - loss: 4.0419e-04 - mse: 4.0419e-04\n",
      "Epoch 8: val_loss improved from 0.00045 to 0.00039, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.0416e-04 - mse: 4.0416e-04 - val_loss: 3.9067e-04 - val_mse: 3.9067e-04\n",
      "Epoch 9/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 3.6269e-04 - mse: 3.6269e-04\n",
      "Epoch 9: val_loss did not improve from 0.00039\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.6269e-04 - mse: 3.6269e-04 - val_loss: 4.6230e-04 - val_mse: 4.6230e-04\n",
      "Epoch 10/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.3119e-04 - mse: 3.3119e-04\n",
      "Epoch 10: val_loss improved from 0.00039 to 0.00030, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 53s 10ms/step - loss: 3.3115e-04 - mse: 3.3115e-04 - val_loss: 3.0369e-04 - val_mse: 3.0369e-04\n",
      "Epoch 11/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.0270e-04 - mse: 3.0270e-04\n",
      "Epoch 11: val_loss improved from 0.00030 to 0.00024, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 53s 10ms/step - loss: 3.0262e-04 - mse: 3.0262e-04 - val_loss: 2.4288e-04 - val_mse: 2.4288e-04\n",
      "Epoch 12/500\n",
      "5278/5280 [============================>.] - ETA: 0s - loss: 2.7555e-04 - mse: 2.7555e-04\n",
      "Epoch 12: val_loss did not improve from 0.00024\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 2.7552e-04 - mse: 2.7552e-04 - val_loss: 3.2853e-04 - val_mse: 3.2853e-04\n",
      "Epoch 13/500\n",
      "5278/5280 [============================>.] - ETA: 0s - loss: 2.6905e-04 - mse: 2.6905e-04\n",
      "Epoch 13: val_loss improved from 0.00024 to 0.00023, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 2.6901e-04 - mse: 2.6901e-04 - val_loss: 2.2606e-04 - val_mse: 2.2606e-04\n",
      "Epoch 14/500\n",
      "5279/5280 [============================>.] - ETA: 0s - loss: 2.3401e-04 - mse: 2.3401e-04\n",
      "Epoch 14: val_loss did not improve from 0.00023\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 2.3401e-04 - mse: 2.3401e-04 - val_loss: 2.3848e-04 - val_mse: 2.3848e-04\n",
      "Epoch 15/500\n",
      "5279/5280 [============================>.] - ETA: 0s - loss: 2.1100e-04 - mse: 2.1100e-04\n",
      "Epoch 15: val_loss improved from 0.00023 to 0.00019, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 2.1099e-04 - mse: 2.1099e-04 - val_loss: 1.8610e-04 - val_mse: 1.8610e-04\n",
      "Epoch 16/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 2.1304e-04 - mse: 2.1304e-04\n",
      "Epoch 16: val_loss did not improve from 0.00019\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 2.1304e-04 - mse: 2.1304e-04 - val_loss: 2.0961e-04 - val_mse: 2.0961e-04\n",
      "Epoch 17/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.8520e-04 - mse: 1.8520e-04\n",
      "Epoch 17: val_loss improved from 0.00019 to 0.00017, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 1.8515e-04 - mse: 1.8515e-04 - val_loss: 1.6829e-04 - val_mse: 1.6829e-04\n",
      "Epoch 18/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.8505e-04 - mse: 1.8505e-04\n",
      "Epoch 18: val_loss did not improve from 0.00017\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 1.8507e-04 - mse: 1.8507e-04 - val_loss: 2.5676e-04 - val_mse: 2.5676e-04\n",
      "Epoch 19/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.8321e-04 - mse: 1.8321e-04\n",
      "Epoch 19: val_loss improved from 0.00017 to 0.00013, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 1.8317e-04 - mse: 1.8317e-04 - val_loss: 1.2625e-04 - val_mse: 1.2625e-04\n",
      "Epoch 20/500\n",
      "5279/5280 [============================>.] - ETA: 0s - loss: 1.7205e-04 - mse: 1.7205e-04\n",
      "Epoch 20: val_loss did not improve from 0.00013\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 1.7203e-04 - mse: 1.7203e-04 - val_loss: 1.5714e-04 - val_mse: 1.5714e-04\n",
      "Epoch 21/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 1.5560e-04 - mse: 1.5560e-04\n",
      "Epoch 21: val_loss did not improve from 0.00013\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 1.5560e-04 - mse: 1.5560e-04 - val_loss: 1.3289e-04 - val_mse: 1.3289e-04\n",
      "Epoch 22/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 1.5238e-04 - mse: 1.5238e-04\n",
      "Epoch 22: val_loss did not improve from 0.00013\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 1.5238e-04 - mse: 1.5238e-04 - val_loss: 1.6184e-04 - val_mse: 1.6184e-04\n",
      "Epoch 23/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.4452e-04 - mse: 1.4452e-04\n",
      "Epoch 23: val_loss improved from 0.00013 to 0.00011, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 1.4447e-04 - mse: 1.4447e-04 - val_loss: 1.0774e-04 - val_mse: 1.0774e-04\n",
      "Epoch 24/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 1.4191e-04 - mse: 1.4191e-04\n",
      "Epoch 24: val_loss did not improve from 0.00011\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 1.4191e-04 - mse: 1.4191e-04 - val_loss: 1.1264e-04 - val_mse: 1.1264e-04\n",
      "Epoch 25/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.4073e-04 - mse: 1.4073e-04\n",
      "Epoch 25: val_loss improved from 0.00011 to 0.00010, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 1.4067e-04 - mse: 1.4067e-04 - val_loss: 1.0350e-04 - val_mse: 1.0350e-04\n",
      "Epoch 26/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.3070e-04 - mse: 1.3070e-04\n",
      "Epoch 26: val_loss did not improve from 0.00010\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 1.3073e-04 - mse: 1.3073e-04 - val_loss: 1.1255e-04 - val_mse: 1.1255e-04\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.2104e-04 - mse: 1.2104e-04\n",
      "Epoch 27: val_loss improved from 0.00010 to 0.00010, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 1.2099e-04 - mse: 1.2099e-04 - val_loss: 9.6434e-05 - val_mse: 9.6434e-05\n",
      "Epoch 28/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.2508e-04 - mse: 1.2508e-04\n",
      "Epoch 28: val_loss improved from 0.00010 to 0.00009, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 1.2504e-04 - mse: 1.2504e-04 - val_loss: 9.0745e-05 - val_mse: 9.0745e-05\n",
      "Epoch 29/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.1198e-04 - mse: 1.1198e-04\n",
      "Epoch 29: val_loss did not improve from 0.00009\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 1.1199e-04 - mse: 1.1199e-04 - val_loss: 1.8989e-04 - val_mse: 1.8989e-04\n",
      "Epoch 30/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.1307e-04 - mse: 1.1307e-04\n",
      "Epoch 30: val_loss did not improve from 0.00009\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 1.1304e-04 - mse: 1.1304e-04 - val_loss: 9.7899e-05 - val_mse: 9.7899e-05\n",
      "Epoch 31/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 1.0823e-04 - mse: 1.0823e-04\n",
      "Epoch 31: val_loss did not improve from 0.00009\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 1.0823e-04 - mse: 1.0823e-04 - val_loss: 1.0961e-04 - val_mse: 1.0961e-04\n",
      "Epoch 32/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.1048e-04 - mse: 1.1048e-04\n",
      "Epoch 32: val_loss did not improve from 0.00009\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 1.1062e-04 - mse: 1.1062e-04 - val_loss: 1.5349e-04 - val_mse: 1.5349e-04\n",
      "Epoch 33/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.0241e-04 - mse: 1.0241e-04\n",
      "Epoch 33: val_loss improved from 0.00009 to 0.00009, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 1.0239e-04 - mse: 1.0239e-04 - val_loss: 8.9867e-05 - val_mse: 8.9867e-05\n",
      "Epoch 34/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 1.0660e-04 - mse: 1.0660e-04\n",
      "Epoch 34: val_loss did not improve from 0.00009\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 1.0666e-04 - mse: 1.0666e-04 - val_loss: 1.1152e-04 - val_mse: 1.1152e-04\n",
      "Epoch 35/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 9.4856e-05 - mse: 9.4856e-05\n",
      "Epoch 35: val_loss improved from 0.00009 to 0.00008, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 9.4833e-05 - mse: 9.4833e-05 - val_loss: 7.6282e-05 - val_mse: 7.6282e-05\n",
      "Epoch 36/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 9.9316e-05 - mse: 9.9316e-05\n",
      "Epoch 36: val_loss did not improve from 0.00008\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 9.9316e-05 - mse: 9.9316e-05 - val_loss: 9.3079e-05 - val_mse: 9.3079e-05\n",
      "Epoch 37/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 9.0559e-05 - mse: 9.0559e-05\n",
      "Epoch 37: val_loss did not improve from 0.00008\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 9.0587e-05 - mse: 9.0587e-05 - val_loss: 1.0887e-04 - val_mse: 1.0887e-04\n",
      "Epoch 38/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 9.2845e-05 - mse: 9.2845e-05\n",
      "Epoch 38: val_loss did not improve from 0.00008\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 9.2884e-05 - mse: 9.2884e-05 - val_loss: 1.7184e-04 - val_mse: 1.7184e-04\n",
      "Epoch 39/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 9.1043e-05 - mse: 9.1043e-05\n",
      "Epoch 39: val_loss did not improve from 0.00008\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 9.1035e-05 - mse: 9.1035e-05 - val_loss: 1.4327e-04 - val_mse: 1.4327e-04\n",
      "Epoch 40/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 8.6888e-05 - mse: 8.6888e-05\n",
      "Epoch 40: val_loss did not improve from 0.00008\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 8.6881e-05 - mse: 8.6881e-05 - val_loss: 8.6230e-05 - val_mse: 8.6230e-05\n",
      "Epoch 41/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 8.1410e-05 - mse: 8.1410e-05\n",
      "Epoch 41: val_loss improved from 0.00008 to 0.00006, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 8.1413e-05 - mse: 8.1413e-05 - val_loss: 6.3521e-05 - val_mse: 6.3521e-05\n",
      "Epoch 42/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 8.2273e-05 - mse: 8.2273e-05\n",
      "Epoch 42: val_loss did not improve from 0.00006\n",
      "5280/5280 [==============================] - 50s 10ms/step - loss: 8.2300e-05 - mse: 8.2300e-05 - val_loss: 9.8936e-05 - val_mse: 9.8936e-05\n",
      "Epoch 43/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 7.9276e-05 - mse: 7.9276e-05\n",
      "Epoch 43: val_loss did not improve from 0.00006\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 7.9240e-05 - mse: 7.9240e-05 - val_loss: 6.8282e-05 - val_mse: 6.8282e-05\n",
      "Epoch 44/500\n",
      "5276/5280 [============================>.] - ETA: 0s - loss: 8.1794e-05 - mse: 8.1794e-05\n",
      "Epoch 44: val_loss improved from 0.00006 to 0.00006, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 50s 10ms/step - loss: 8.1813e-05 - mse: 8.1813e-05 - val_loss: 5.5238e-05 - val_mse: 5.5238e-05\n",
      "Epoch 45/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 7.1292e-05 - mse: 7.1292e-05\n",
      "Epoch 45: val_loss did not improve from 0.00006\n",
      "5280/5280 [==============================] - 50s 10ms/step - loss: 7.1272e-05 - mse: 7.1272e-05 - val_loss: 6.5305e-05 - val_mse: 6.5305e-05\n",
      "Epoch 46/500\n",
      "5276/5280 [============================>.] - ETA: 0s - loss: 7.0746e-05 - mse: 7.0746e-05\n",
      "Epoch 46: val_loss did not improve from 0.00006\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 7.0735e-05 - mse: 7.0735e-05 - val_loss: 7.4444e-05 - val_mse: 7.4444e-05\n",
      "Epoch 47/500\n",
      "5277/5280 [============================>.] - ETA: 0s - loss: 7.7514e-05 - mse: 7.7514e-05\n",
      "Epoch 47: val_loss improved from 0.00006 to 0.00004, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 50s 10ms/step - loss: 7.7509e-05 - mse: 7.7509e-05 - val_loss: 4.2097e-05 - val_mse: 4.2097e-05\n",
      "Epoch 48/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 7.1249e-05 - mse: 7.1249e-05\n",
      "Epoch 48: val_loss did not improve from 0.00004\n",
      "5280/5280 [==============================] - 50s 10ms/step - loss: 7.1244e-05 - mse: 7.1244e-05 - val_loss: 5.9155e-05 - val_mse: 5.9155e-05\n",
      "Epoch 49/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 7.4316e-05 - mse: 7.4316e-05\n",
      "Epoch 49: val_loss did not improve from 0.00004\n",
      "5280/5280 [==============================] - 50s 10ms/step - loss: 7.4393e-05 - mse: 7.4393e-05 - val_loss: 9.8813e-05 - val_mse: 9.8813e-05\n",
      "Epoch 50/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 6.6215e-05 - mse: 6.6215e-05\n",
      "Epoch 50: val_loss did not improve from 0.00004\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 6.6215e-05 - mse: 6.6215e-05 - val_loss: 6.5948e-05 - val_mse: 6.5948e-05\n",
      "Epoch 51/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 7.1368e-05 - mse: 7.1368e-05\n",
      "Epoch 51: val_loss improved from 0.00004 to 0.00003, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 7.1368e-05 - mse: 7.1368e-05 - val_loss: 3.2888e-05 - val_mse: 3.2888e-05\n",
      "Epoch 52/500\n",
      "5277/5280 [============================>.] - ETA: 0s - loss: 6.9204e-05 - mse: 6.9204e-05\n",
      "Epoch 52: val_loss did not improve from 0.00003\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 6.9190e-05 - mse: 6.9190e-05 - val_loss: 4.7429e-05 - val_mse: 4.7429e-05\n",
      "Epoch 53/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 5.6730e-05 - mse: 5.6730e-05\n",
      "Epoch 53: val_loss did not improve from 0.00003\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 5.6730e-05 - mse: 5.6730e-05 - val_loss: 7.1207e-05 - val_mse: 7.1207e-05\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5275/5280 [============================>.] - ETA: 0s - loss: 6.9750e-05 - mse: 6.9750e-05\n",
      "Epoch 54: val_loss improved from 0.00003 to 0.00003, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 6.9708e-05 - mse: 6.9708e-05 - val_loss: 2.8783e-05 - val_mse: 2.8783e-05\n",
      "Epoch 55/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 6.3332e-05 - mse: 6.3332e-05\n",
      "Epoch 55: val_loss improved from 0.00003 to 0.00003, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 6.3290e-05 - mse: 6.3290e-05 - val_loss: 2.8057e-05 - val_mse: 2.8057e-05\n",
      "Epoch 56/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 5.6821e-05 - mse: 5.6821e-05\n",
      "Epoch 56: val_loss did not improve from 0.00003\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 5.6854e-05 - mse: 5.6854e-05 - val_loss: 7.1302e-05 - val_mse: 7.1302e-05\n",
      "Epoch 57/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 6.2180e-05 - mse: 6.2180e-05\n",
      "Epoch 57: val_loss did not improve from 0.00003\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 6.2166e-05 - mse: 6.2166e-05 - val_loss: 6.3852e-05 - val_mse: 6.3852e-05\n",
      "Epoch 58/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 6.5862e-05 - mse: 6.5862e-05\n",
      "Epoch 58: val_loss did not improve from 0.00003\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 6.5844e-05 - mse: 6.5844e-05 - val_loss: 9.9807e-05 - val_mse: 9.9807e-05\n",
      "Epoch 59/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 6.4074e-05 - mse: 6.4074e-05\n",
      "Epoch 59: val_loss did not improve from 0.00003\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 6.4074e-05 - mse: 6.4074e-05 - val_loss: 5.9453e-05 - val_mse: 5.9453e-05\n",
      "Epoch 60/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 5.5089e-05 - mse: 5.5089e-05\n",
      "Epoch 60: val_loss did not improve from 0.00003\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 5.5055e-05 - mse: 5.5055e-05 - val_loss: 3.4800e-05 - val_mse: 3.4800e-05\n",
      "Epoch 61/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 6.2106e-05 - mse: 6.2106e-05\n",
      "Epoch 61: val_loss did not improve from 0.00003\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 6.2066e-05 - mse: 6.2066e-05 - val_loss: 3.3243e-05 - val_mse: 3.3243e-05\n",
      "Epoch 62/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 5.3443e-05 - mse: 5.3443e-05\n",
      "Epoch 62: val_loss improved from 0.00003 to 0.00002, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 5.3443e-05 - mse: 5.3443e-05 - val_loss: 2.2854e-05 - val_mse: 2.2854e-05\n",
      "Epoch 63/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 4.8654e-05 - mse: 4.8654e-05\n",
      "Epoch 63: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.8654e-05 - mse: 4.8654e-05 - val_loss: 9.1543e-05 - val_mse: 9.1543e-05\n",
      "Epoch 64/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 5.0810e-05 - mse: 5.0810e-05\n",
      "Epoch 64: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 5.0810e-05 - mse: 5.0810e-05 - val_loss: 5.8816e-05 - val_mse: 5.8816e-05\n",
      "Epoch 65/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 5.4426e-05 - mse: 5.4426e-05\n",
      "Epoch 65: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 5.4426e-05 - mse: 5.4426e-05 - val_loss: 6.5253e-05 - val_mse: 6.5253e-05\n",
      "Epoch 66/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 5.4766e-05 - mse: 5.4766e-05\n",
      "Epoch 66: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 5.4734e-05 - mse: 5.4734e-05 - val_loss: 2.3345e-05 - val_mse: 2.3345e-05\n",
      "Epoch 67/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 5.1923e-05 - mse: 5.1923e-05\n",
      "Epoch 67: val_loss improved from 0.00002 to 0.00002, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 5.1885e-05 - mse: 5.1885e-05 - val_loss: 1.6857e-05 - val_mse: 1.6857e-05\n",
      "Epoch 68/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.8745e-05 - mse: 4.8745e-05\n",
      "Epoch 68: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.8734e-05 - mse: 4.8734e-05 - val_loss: 5.8762e-05 - val_mse: 5.8762e-05\n",
      "Epoch 69/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 5.2094e-05 - mse: 5.2094e-05\n",
      "Epoch 69: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 5.2057e-05 - mse: 5.2057e-05 - val_loss: 2.4850e-05 - val_mse: 2.4850e-05\n",
      "Epoch 70/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.4829e-05 - mse: 4.4829e-05\n",
      "Epoch 70: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.4823e-05 - mse: 4.4823e-05 - val_loss: 2.7113e-05 - val_mse: 2.7113e-05\n",
      "Epoch 71/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.8874e-05 - mse: 4.8874e-05\n",
      "Epoch 71: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.8845e-05 - mse: 4.8845e-05 - val_loss: 1.8958e-05 - val_mse: 1.8958e-05\n",
      "Epoch 72/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 4.7932e-05 - mse: 4.7932e-05\n",
      "Epoch 72: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.7932e-05 - mse: 4.7932e-05 - val_loss: 3.7667e-05 - val_mse: 3.7667e-05\n",
      "Epoch 73/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 5.3281e-05 - mse: 5.3281e-05\n",
      "Epoch 73: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 5.3336e-05 - mse: 5.3336e-05 - val_loss: 4.3617e-05 - val_mse: 4.3617e-05\n",
      "Epoch 74/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.6452e-05 - mse: 4.6452e-05\n",
      "Epoch 74: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 4.6482e-05 - mse: 4.6482e-05 - val_loss: 5.5466e-05 - val_mse: 5.5466e-05\n",
      "Epoch 75/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 5.5316e-05 - mse: 5.5316e-05\n",
      "Epoch 75: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 5.5388e-05 - mse: 5.5388e-05 - val_loss: 6.6898e-05 - val_mse: 6.6898e-05\n",
      "Epoch 76/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.7306e-05 - mse: 4.7306e-05\n",
      "Epoch 76: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.7346e-05 - mse: 4.7346e-05 - val_loss: 1.3202e-04 - val_mse: 1.3202e-04\n",
      "Epoch 77/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 5.0964e-05 - mse: 5.0964e-05\n",
      "Epoch 77: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 5.0964e-05 - mse: 5.0964e-05 - val_loss: 3.8633e-05 - val_mse: 3.8633e-05\n",
      "Epoch 78/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.7236e-05 - mse: 4.7236e-05\n",
      "Epoch 78: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.7258e-05 - mse: 4.7258e-05 - val_loss: 6.7716e-05 - val_mse: 6.7716e-05\n",
      "Epoch 79/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 5.0072e-05 - mse: 5.0072e-05\n",
      "Epoch 79: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 5.0070e-05 - mse: 5.0070e-05 - val_loss: 5.1745e-05 - val_mse: 5.1745e-05\n",
      "Epoch 80/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.5938e-05 - mse: 4.5938e-05\n",
      "Epoch 80: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.5958e-05 - mse: 4.5958e-05 - val_loss: 5.6110e-05 - val_mse: 5.6110e-05\n",
      "Epoch 81/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.6451e-05 - mse: 4.6451e-05\n",
      "Epoch 81: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.6426e-05 - mse: 4.6426e-05 - val_loss: 4.2971e-05 - val_mse: 4.2971e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.0241e-05 - mse: 4.0241e-05\n",
      "Epoch 82: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.0226e-05 - mse: 4.0226e-05 - val_loss: 3.6097e-05 - val_mse: 3.6097e-05\n",
      "Epoch 83/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.6893e-05 - mse: 4.6893e-05\n",
      "Epoch 83: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.6885e-05 - mse: 4.6885e-05 - val_loss: 3.3171e-05 - val_mse: 3.3171e-05\n",
      "Epoch 84/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.1935e-05 - mse: 4.1935e-05\n",
      "Epoch 84: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.1935e-05 - mse: 4.1935e-05 - val_loss: 3.8730e-05 - val_mse: 3.8730e-05\n",
      "Epoch 85/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.3688e-05 - mse: 4.3688e-05\n",
      "Epoch 85: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.3668e-05 - mse: 4.3668e-05 - val_loss: 4.0194e-05 - val_mse: 4.0194e-05\n",
      "Epoch 86/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.8558e-05 - mse: 3.8558e-05\n",
      "Epoch 86: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.8538e-05 - mse: 3.8538e-05 - val_loss: 2.9727e-05 - val_mse: 2.9727e-05\n",
      "Epoch 87/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.2079e-05 - mse: 4.2079e-05\n",
      "Epoch 87: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.2065e-05 - mse: 4.2065e-05 - val_loss: 4.4058e-05 - val_mse: 4.4058e-05\n",
      "Epoch 88/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.2551e-05 - mse: 3.2551e-05\n",
      "Epoch 88: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.2538e-05 - mse: 3.2538e-05 - val_loss: 2.6577e-05 - val_mse: 2.6577e-05\n",
      "Epoch 89/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.9038e-05 - mse: 4.9038e-05\n",
      "Epoch 89: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.9090e-05 - mse: 4.9090e-05 - val_loss: 7.9165e-05 - val_mse: 7.9165e-05\n",
      "Epoch 90/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.6395e-05 - mse: 3.6395e-05\n",
      "Epoch 90: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.6423e-05 - mse: 3.6423e-05 - val_loss: 3.3836e-05 - val_mse: 3.3836e-05\n",
      "Epoch 91/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.2732e-05 - mse: 4.2732e-05\n",
      "Epoch 91: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 4.2733e-05 - mse: 4.2733e-05 - val_loss: 3.9205e-05 - val_mse: 3.9205e-05\n",
      "Epoch 92/500\n",
      "5280/5280 [==============================] - ETA: 0s - loss: 4.2245e-05 - mse: 4.2245e-05\n",
      "Epoch 92: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 4.2245e-05 - mse: 4.2245e-05 - val_loss: 4.4105e-05 - val_mse: 4.4105e-05\n",
      "Epoch 93/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 4.6161e-05 - mse: 4.6161e-05\n",
      "Epoch 93: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 4.6127e-05 - mse: 4.6127e-05 - val_loss: 2.0821e-05 - val_mse: 2.0821e-05\n",
      "Epoch 94/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.3342e-05 - mse: 3.3342e-05\n",
      "Epoch 94: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 3.3343e-05 - mse: 3.3343e-05 - val_loss: 5.0565e-05 - val_mse: 5.0565e-05\n",
      "Epoch 95/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.7040e-05 - mse: 3.7040e-05\n",
      "Epoch 95: val_loss did not improve from 0.00002\n",
      "5280/5280 [==============================] - 52s 10ms/step - loss: 3.7079e-05 - mse: 3.7079e-05 - val_loss: 7.7828e-05 - val_mse: 7.7828e-05\n",
      "Epoch 96/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.2770e-05 - mse: 3.2770e-05\n",
      "Epoch 96: val_loss improved from 0.00002 to 0.00001, saving model to Saved_Model.h5\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.2748e-05 - mse: 3.2748e-05 - val_loss: 1.4379e-05 - val_mse: 1.4379e-05\n",
      "Epoch 97/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.0959e-05 - mse: 3.0959e-05\n",
      "Epoch 97: val_loss did not improve from 0.00001\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.1055e-05 - mse: 3.1055e-05 - val_loss: 9.0548e-05 - val_mse: 9.0548e-05\n",
      "Epoch 98/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.9560e-05 - mse: 3.9560e-05\n",
      "Epoch 98: val_loss did not improve from 0.00001\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.9533e-05 - mse: 3.9533e-05 - val_loss: 1.5135e-05 - val_mse: 1.5135e-05\n",
      "Epoch 99/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.7060e-05 - mse: 3.7060e-05\n",
      "Epoch 99: val_loss did not improve from 0.00001\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.7047e-05 - mse: 3.7047e-05 - val_loss: 3.1370e-05 - val_mse: 3.1370e-05\n",
      "Epoch 100/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.7627e-05 - mse: 3.7627e-05\n",
      "Epoch 100: val_loss did not improve from 0.00001\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.7622e-05 - mse: 3.7622e-05 - val_loss: 5.7827e-05 - val_mse: 5.7827e-05\n",
      "Epoch 101/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 3.4458e-05 - mse: 3.4458e-05\n",
      "Epoch 101: val_loss did not improve from 0.00001\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 3.4450e-05 - mse: 3.4450e-05 - val_loss: 2.7011e-05 - val_mse: 2.7011e-05\n",
      "Epoch 102/500\n",
      "5275/5280 [============================>.] - ETA: 0s - loss: 2.8754e-05 - mse: 2.8754e-05\n",
      "Epoch 102: val_loss did not improve from 0.00001\n",
      "5280/5280 [==============================] - 51s 10ms/step - loss: 2.8734e-05 - mse: 2.8734e-05 - val_loss: 1.6192e-05 - val_mse: 1.6192e-05\n",
      "Epoch 103/500\n",
      "3120/5280 [================>.............] - ETA: 19s - loss: 3.6262e-05 - mse: 3.6262e-05"
     ]
    }
   ],
   "source": [
    "# Early Stopping and Model_Checkpoints are optional parameters\n",
    "# Early Stopping is to stop the training based on certain condition set by the user\n",
    "# Model Checkpoint is to save a model in a directory based on certain conditions so that it can be used later for Transfer Learning or avoiding retraining\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=30, mode='min'), ModelCheckpoint('Saved_Model.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
    "history = Regression_Model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1, validation_split=0.2, shuffle=True, callbacks=callbacks)\n",
    "# Save 'History' of the model for model performance analysis performed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.models.save_model(Regression_Model, 'oeoe.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model with custom_objects\n",
    "# import tensorflow as tf\n",
    "# class AdamW(Adam):\n",
    "#     def __init__(self, learning_rate=0.0001, weight_decay=0.01, **kwargs):\n",
    "#         super(AdamW, self).__init__(learning_rate, **kwargs)\n",
    "#         self.weight_decay = weight_decay\n",
    "\n",
    "#     def get_gradients(self, loss, params):\n",
    "#         gradients = super(AdamW, self).get_gradients(loss, params)\n",
    "#         if self.weight_decay > 0.0:\n",
    "#             for i in range(len(gradients)):\n",
    "#                 if gradients[i] is not None:\n",
    "#                     gradients[i] += self.weight_decay * params[i]\n",
    "#         return gradients\n",
    "# custom_objects = {'AdamW': AdamW}\n",
    "# RR = tf.keras.models.load_model('Resnet18_StandWithWavseq.h5', custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rejbOtGN-ixL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7rTwvEAos2fB",
    "outputId": "4191163c-57a5-4ed6-d3af-b5dbf3593950"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Evaluate Model\n",
    "Regression_Model.evaluate(train_data_reshaped, yscale)\n",
    "ypred = Regression_Model.predict(train_data_reshaped)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.show()\n",
    "plt.savefig('Loss Result.png')\n",
    "\n",
    "print('MSE: ',mean_squared_error(yscale, ypred))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(yscale, ypred)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(yscale, ypred))\n",
    "\n",
    "\n",
    "#Inverse\n",
    "ypred = scaler_y.inverse_transform(ypred) \n",
    "yscale = scaler_y.inverse_transform(yscale) \n",
    "y_inverse = yscale\n",
    "y_pred_inverse = ypred\n",
    "\n",
    "for i in range(len(y_pred_inverse)):\n",
    "    if (np.abs(y_pred_inverse[i]) < 1).all():\n",
    "        y_pred_inverse[i] = 0\n",
    "\n",
    "for i in range(0, y_pred_inverse.shape[0], 50):\n",
    "    zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "    non_zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "    if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "        y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "print('MSE: ',mean_squared_error(y_inverse, y_pred_inverse))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(y_inverse, y_pred_inverse)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(y_inverse, y_pred_inverse))\n",
    "\n",
    "# restore to original Data\n",
    "FXData2 = y_inverse[:,0]*2\n",
    "FXData2=  np.array(FXData2)\n",
    "FXData2 = FXData2.reshape(-1,1)\n",
    "\n",
    "FYData2 = y_inverse[:,1]*5\n",
    "FYData2 =  np.array(FYData2)\n",
    "FYData2 = FYData2.reshape(-1,1)\n",
    "\n",
    "FZData2 = (y_inverse[:,2]*100)\n",
    "FZData2 =  np.array(FZData2)\n",
    "FZData2 = FZData2.reshape(-1,1)\n",
    "\n",
    "MXData2 = (y_inverse[:,3]*10000)\n",
    "MXData2 =  np.array(MXData2)\n",
    "MXData2 = MXData2.reshape(-1,1)\n",
    "\n",
    "MYData2 = (y_inverse[:,4]*10000)\n",
    "MYData2 =  np.array(MYData2)\n",
    "MYData2 = MYData2.reshape(-1,1\n",
    "                          )\n",
    "MZData2 = (y_inverse[:,5]*1000)\n",
    "MZData2 =  np.array(MZData2)\n",
    "MZData2 = MZData2.reshape(-1,1)\n",
    "\n",
    "new_inverse2 = np.concatenate((FXData2, FYData2, FZData2, MXData2, MYData2, MZData2), axis=1)\n",
    "\n",
    "FXData3 = y_pred_inverse[:,0]*2\n",
    "FXData3=  np.array(FXData3)\n",
    "FXData3 = FXData3.reshape(-1,1)\n",
    "\n",
    "FYData3 = y_pred_inverse[:,1]*5\n",
    "FYData3 =  np.array(FYData3)\n",
    "FYData3 = FYData3.reshape(-1,1)\n",
    "\n",
    "FZData3 = (y_pred_inverse[:,2]*100)\n",
    "FZData3 =  np.array(FZData3)\n",
    "FZData3 = FZData3.reshape(-1,1)\n",
    "\n",
    "MXData3 = (y_pred_inverse[:,3]*10000)\n",
    "MXData3 =  np.array(MXData3)\n",
    "MXData3 = MXData3.reshape(-1,1)\n",
    "\n",
    "MYData3 = (y_pred_inverse[:,4]*10000)\n",
    "MYData3 =  np.array(MYData3)\n",
    "MYData3 = MYData3.reshape(-1,1)\n",
    "\n",
    "MZData3 = (y_pred_inverse[:,5]*1000)\n",
    "MZData3 =  np.array(MZData3)\n",
    "MZData3 = MZData3.reshape(-1,1)\n",
    "\n",
    "new_inverse3 = np.concatenate((FXData3, FYData3, FZData3, MXData3, MYData3, MZData3), axis=1)\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('ResNet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "out_Fz = new_inverse2[:,2]\n",
    "out_Mx = new_inverse2[:,3]\n",
    "out_My = new_inverse2[:,4]\n",
    "Pred_Fz = new_inverse3[:,2]\n",
    "Pred_Mx = new_inverse3[:,3]\n",
    "Pred_My = new_inverse3[:,4]\n",
    "\n",
    "Pred_COPx=[]\n",
    "for i in range(0,len(Pred_Fz)):\n",
    "  Pred_COPx_temp=-(Pred_My[i])/Pred_Fz[i]\n",
    "  # print(temp)\n",
    "  if Pred_COPx_temp != Pred_COPx_temp:\n",
    "    Pred_COPx_temp=0\n",
    "  Pred_COPx.append(Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "out_COPx=[]\n",
    "for i in range(0,len(out_Fz)):\n",
    "  out_COPx_temp=-(out_My[i])/out_Fz[i]\n",
    "  # print(temp)\n",
    "  if out_COPx_temp != out_COPx_temp:\n",
    "    out_COPx_temp=0\n",
    "  out_COPx.append(out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Pred_COPy=[]\n",
    "for i in range(0,len(Pred_Mx)):\n",
    "  Pred_COPy_temp=Pred_Mx[i]/Pred_Fz[i]\n",
    "  # print(temp)\n",
    "  if Pred_COPy_temp != Pred_COPy_temp:\n",
    "    Pred_COPy_temp=0\n",
    "  Pred_COPy.append(Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "out_COPy=[]\n",
    "for i in range(0,len(out_Mx)):\n",
    "  out_COPy_temp=out_Mx[i]/out_Fz[i]\n",
    "  # print(temp)\n",
    "  if out_COPy_temp != out_COPy_temp:\n",
    "    out_COPy_temp=0\n",
    "  out_COPy.append(out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "# out_COPx = -(out_My)/out_Fz\n",
    "out_COPx = np.array(out_COPx)\n",
    "out_COPx= out_COPx.reshape(-1,1)\n",
    "\n",
    "# out_COPy = out_Mx/out_Fz\n",
    "out_COPy = np.array(out_COPy)\n",
    "out_COPy= out_COPy.reshape(-1,1)\n",
    "\n",
    "# Pred_COPx = -(Pred_My)/Pred_Fz\n",
    "Pred_COPx = np.array(Pred_COPx)\n",
    "Pred_COPx= Pred_COPx.reshape(-1,1)\n",
    "\n",
    "# Pred_COPy = Pred_Mx/Pred_Fz\n",
    "Pred_COPy = np.array(Pred_COPy)\n",
    "Pred_COPy= Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Pred_COP = np.concatenate((Pred_COPx, Pred_COPy), axis=1)\n",
    "FC_COP = np.concatenate((out_COPx, out_COPy), axis=1)\n",
    "\n",
    "col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000 \n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Training Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "y1 = FC_COP[50:100,0]\n",
    "y2 = FC_COP[50:100,1]\n",
    "y3 = Pred_COP[50:100,0]\n",
    "y4 = Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "data_filter = abs(y1) > 0\n",
    "data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1[data_filter], y2[data_filter ], color='red', alpha=0.3)\n",
    "pyplot.plot(y3[data_filter2], y4[data_filter2 ], color='green')\n",
    "# pyplot.plot(y1, y2, color='red')\n",
    "# pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "CHhYv7LpNRTb",
    "outputId": "4d9bc457-9596-441f-8bda-6759e0af84cc"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[0:100,0]\n",
    "y2 = FC_COP[0:100,1]\n",
    "y3 = Pred_COP[0:100,0]\n",
    "y4 = Pred_COP[0:100,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "-3fg6ZDwNNLd",
    "outputId": "c707c66a-4d1a-4d89-9bbf-67ec96062e95"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[100:200,0]\n",
    "y2 = FC_COP[100:200,1]\n",
    "y3 = Pred_COP[100:200,0]\n",
    "y4 = Pred_COP[100:200,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "9qxieSZKNVlT",
    "outputId": "67998abd-a2f0-426f-9cd9-f205ef349c53"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[200:300,0]\n",
    "y2 = FC_COP[200:300,1]\n",
    "y3 = Pred_COP[200:300,0]\n",
    "y4 = Pred_COP[200:300,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Axx3FDcMsYAm",
    "outputId": "abf8945d-cb34-4786-f80f-425cca382d52"
   },
   "outputs": [],
   "source": [
    "new_inverse2[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlZwHomDsZ5R",
    "outputId": "1d112f34-ffa8-4015-f3f0-a591f5d69688"
   },
   "outputs": [],
   "source": [
    "new_inverse3[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8Cnd-RuHso4",
    "outputId": "1dbdfab9-3a55-4b59-d51a-71ac18c572a2"
   },
   "outputs": [],
   "source": [
    "new_inverse2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4I2lr9yfHuJA",
    "outputId": "fbf0bd74-599a-4afb-8eab-ecf5a8f797be"
   },
   "outputs": [],
   "source": [
    "new_inverse3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oa_UQq_v1atq",
    "outputId": "2f0db226-fe50-4d59-aba1-2b0aaa328e41"
   },
   "outputs": [],
   "source": [
    "y_inverse[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsSpiSOY1dQ-",
    "outputId": "5713ad7c-fb14-4068-86d9-50299350084b"
   },
   "outputs": [],
   "source": [
    "y_pred_inverse[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = RR.history.history\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history['mse'], label='Training MSE')\n",
    "plt.plot(history['val_mse'], label='Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw0HsDDtyEuv"
   },
   "source": [
    "Test and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b_ov3Oh5nUx0",
    "outputId": "29b9f789-8c9e-483d-af1e-45a76ae9fffc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model Validation\n",
    "Test_Insole = pd.read_csv('0310HudaStand5Min2.txt', header=None, low_memory=False)\n",
    "TestSIData =  np.asarray(Test_Insole)\n",
    "\n",
    "Test_df = pd.read_csv('0310HudaStand5Min2.csv', low_memory=False)\n",
    "Test_columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "Test_selected_df = Test_df[Test_columns]\n",
    "Test_FPDatas = Test_selected_df[:6000]\n",
    "\n",
    "\n",
    "test_SmartInsole = np.array(TestSIData[:6000]).astype('float32')\n",
    "Test_FPData = np.array(Test_FPDatas).astype('float32')\n",
    "\n",
    "Test_FXData = Test_FPData[:,0]/2\n",
    "Test_FXData =  np.array(Test_FXData)\n",
    "Test_FXData = Test_FXData.reshape(-1,1)\n",
    "Test_FYData = Test_FPData[:,1]/5\n",
    "Test_FYData =  np.array(Test_FYData)\n",
    "Test_FYData = Test_FYData.reshape(-1,1)\n",
    "Test_FZData = (Test_FPData[:,2])/100\n",
    "Test_FZData =  np.array(Test_FZData)\n",
    "Test_FZData = Test_FZData.reshape(-1,1)\n",
    "Test_MXData = (Test_FPData[:,3])/10000\n",
    "Test_MXData =  np.array(Test_MXData)\n",
    "Test_MXData = Test_MXData.reshape(-1,1)\n",
    "Test_MYData = (Test_FPData[:,4])/10000\n",
    "Test_MYData =  np.array(Test_MYData)\n",
    "Test_MYData =Test_MYData.reshape(-1,1)\n",
    "Test_MZData = (Test_FPData[:,5])/1000\n",
    "Test_MZData =  np.array(Test_MZData)\n",
    "Test_MZData = Test_MZData.reshape(-1,1)\n",
    "\n",
    "Test_newFPData = np.concatenate((Test_FXData, Test_FYData, Test_FZData, Test_MXData, Test_MYData, Test_MZData), axis=1)\n",
    "# Test_newFPData = np.round(Test_newFPData,2)\n",
    "## End Load Data\n",
    "\n",
    "Test_SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(test_SmartInsole[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "    coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "    # coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "    # coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "    # coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    # coeffs[-7] = np.zeros_like(coeffs[-7])\n",
    "    Test_SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_SIData_filtered = np.zeros(test_SmartInsole.shape)\n",
    "for i in range(89):\n",
    "    Test_SIData_filtered[:, i] = pywt.waverec(Test_SIDWTcoeffs[i], 'db4', mode='symmetric', axis=0)\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    if i < len(Test_SIData_filtered):\n",
    "        Test_SIData_filtered[i][0] = 0\n",
    "#         Test_SIData_filtered[i][0] = Test_SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "        iter += 1\n",
    "    else:\n",
    "        Test_SIData_filtered[i][0] = 0\n",
    "\n",
    "# for i in range(len(Test_SIData_filtered)):\n",
    "#     Test_SIData_filtered[i][0] = i-1\n",
    "#     iter += 1\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    Test_SIData_filtered[i][np.abs(Test_SIData_filtered[i]) < 1] = 0\n",
    "    \n",
    "Test_FPDWTcoeffs = []\n",
    "for i in range(6):\n",
    "    coeffs = pywt.wavedec(Test_newFPData[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "    coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "    coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "    coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "    coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    # coeffs[-7] = np.zeros_like(coeffs[-7])\n",
    "    Test_FPDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_FPData_filtered = np.zeros(Test_newFPData.shape)\n",
    "for i in range(6):\n",
    "    Test_FPData_filtered[:, i] = pywt.waverec(Test_FPDWTcoeffs[i], 'db4', mode='symmetric', axis=0)\n",
    "\n",
    "# scaler_x.fit(Test_SIData_filtered)\n",
    "Test_xscale = scaler_x.transform(Test_SIData_filtered)\n",
    "Test_yscale = scaler_y.transform(Test_FPData_filtered)\n",
    "\n",
    "test_sample_size = Test_xscale.shape[0] # number of samples in train set\n",
    "test_time_steps  = Test_xscale.shape[1] # number of features in train set\n",
    "test_input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "test_train_data_reshaped = Test_xscale.reshape(test_sample_size,test_time_steps,test_input_dimension)\n",
    "\n",
    "RR.evaluate(test_train_data_reshaped, Test_yscale)\n",
    "Test_xX_model = RR.predict(test_train_data_reshaped)\n",
    "\n",
    "#invert normalize\n",
    "Test_xX_model = scaler_y.inverse_transform(Test_xX_model) \n",
    "Test_yscale = scaler_y.inverse_transform(Test_yscale) \n",
    "Test_y_pred_inverse = Test_xX_model\n",
    "Test_y_inverse = Test_yscale\n",
    "\n",
    "for i in range(len(Test_y_pred_inverse)):\n",
    "    if (np.abs(Test_y_pred_inverse[i]) < 1).all():\n",
    "        Test_y_pred_inverse[i] = 0\n",
    "\n",
    "for i in range(0, Test_y_pred_inverse.shape[0], 50):\n",
    "    zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "    non_zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "    if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "        Test_y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "# make to original Data\n",
    "Test_FXData2 = Test_y_inverse[:,0]*2\n",
    "Test_FXData2=  np.array(Test_FXData2)\n",
    "Test_FXData2 = Test_FXData2.reshape(-1,1)\n",
    "\n",
    "Test_FYData2 = Test_y_inverse[:,1]*5\n",
    "Test_FYData2 =  np.array(Test_FYData2)\n",
    "Test_FYData2 = Test_FYData2.reshape(-1,1)\n",
    "\n",
    "Test_FZData2 = (Test_y_inverse[:,2]*100)\n",
    "Test_FZData2 =  np.array(Test_FZData2)\n",
    "Test_FZData2 = Test_FZData2.reshape(-1,1)\n",
    "\n",
    "Test_MXData2 = (Test_y_inverse[:,3]*10000)\n",
    "Test_MXData2 =  np.array(Test_MXData2)\n",
    "Test_MXData2 = Test_MXData2.reshape(-1,1)\n",
    "\n",
    "Test_MYData2 = (Test_y_inverse[:,4]*10000)\n",
    "Test_MYData2 =  np.array(Test_MYData2)\n",
    "Test_MYData2 = Test_MYData2.reshape(-1,1\n",
    "                          )\n",
    "Test_MZData2 = (Test_y_inverse[:,5]*1000)\n",
    "Test_MZData2 =  np.array(Test_MZData2)\n",
    "Test_MZData2 = Test_MZData2.reshape(-1,1)\n",
    "\n",
    "\n",
    "Test_new_inverse2 = np.concatenate((Test_FXData2, Test_FYData2, Test_FZData2, Test_MXData2, Test_MYData2, Test_MZData2), axis=1)\n",
    "\n",
    "Test_FXData3 = Test_y_pred_inverse[:,0]*2\n",
    "Test_FXData3=  np.array(Test_FXData3)\n",
    "Test_FXData3 = Test_FXData3.reshape(-1,1)\n",
    "\n",
    "Test_FYData3 = Test_y_pred_inverse[:,1]*5\n",
    "Test_FYData3 =  np.array(Test_FYData3)\n",
    "Test_FYData3 = Test_FYData3.reshape(-1,1)\n",
    "\n",
    "Test_FZData3 = (Test_y_pred_inverse[:,2]*100)\n",
    "Test_FZData3 =  np.array(Test_FZData3)\n",
    "Test_FZData3 = Test_FZData3.reshape(-1,1)\n",
    "\n",
    "Test_MXData3 = (Test_y_pred_inverse[:,3]*10000)\n",
    "Test_MXData3 =  np.array(Test_MXData3)\n",
    "Test_MXData3 = Test_MXData3.reshape(-1,1)\n",
    "\n",
    "Test_MYData3 = (Test_y_pred_inverse[:,4]*10000)\n",
    "Test_MYData3 =  np.array(Test_MYData3)\n",
    "Test_MYData3 = Test_MYData3.reshape(-1,1)\n",
    "\n",
    "Test_MZData3 = (Test_y_pred_inverse[:,5]*1000)\n",
    "Test_MZData3 =  np.array(Test_MZData3)\n",
    "Test_MZData3 = Test_MZData3.reshape(-1,1)\n",
    "\n",
    "Test_new_inverse3 = np.concatenate((Test_FXData3, Test_FYData3, Test_FZData3, Test_MXData3, Test_MYData3, Test_MZData3), axis=1)\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('ResNet Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "Test_out_Fz = Test_new_inverse2[:,2]\n",
    "Test_out_Mx = Test_new_inverse2[:,3]\n",
    "Test_out_My = Test_new_inverse2[:,4]\n",
    "Test_Pred_Fz = Test_new_inverse3[:,2]\n",
    "Test_Pred_Mx = Test_new_inverse3[:,3]\n",
    "Test_Pred_My = Test_new_inverse3[:,4]\n",
    "\n",
    "Test_Pred_COPx=[]\n",
    "for i in range(0,len(Test_Pred_Fz)):\n",
    "  Test_Pred_COPx_temp=-(Test_Pred_My[i])/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPx_temp != Test_Pred_COPx_temp:\n",
    "    Test_Pred_COPx_temp=0\n",
    "  Test_Pred_COPx.append(Test_Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPx=[]\n",
    "for i in range(0,len(Test_out_Fz)):\n",
    "  Test_out_COPx_temp=-(Test_out_My[i])/Test_out_Fz[i]\n",
    "  if Test_out_COPx_temp != Test_out_COPx_temp:\n",
    "    Test_out_COPx_temp=0\n",
    "  Test_out_COPx.append(Test_out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_Pred_COPy=[]\n",
    "for i in range(0,len(Test_Pred_Mx)):\n",
    "  Test_Pred_COPy_temp=Test_Pred_Mx[i]/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPy_temp != Test_Pred_COPy_temp:\n",
    "    Test_Pred_COPy_temp=0\n",
    "  Test_Pred_COPy.append(Test_Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPy=[]\n",
    "for i in range(0,len(Test_out_Mx)):\n",
    "  Test_out_COPy_temp=Test_out_Mx[i]/Test_out_Fz[i]\n",
    "  if Test_out_COPy_temp != Test_out_COPy_temp:\n",
    "    Test_out_COPy_temp=0\n",
    "  Test_out_COPy.append(Test_out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "Test_out_COPx = np.array(Test_out_COPx)\n",
    "Test_out_COPx= Test_out_COPx.reshape(-1,1)\n",
    "\n",
    "Test_out_COPy = np.array(Test_out_COPy)\n",
    "Test_out_COPy= Test_out_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPx = np.array(Test_Pred_COPx)\n",
    "Test_Pred_COPx= Test_Pred_COPx.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPy = np.array(Test_Pred_COPy)\n",
    "Test_Pred_COPy= Test_Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COP = np.concatenate((Test_Pred_COPx, Test_Pred_COPy), axis=1)\n",
    "Test_FC_COP = np.concatenate((Test_out_COPx, Test_out_COPy), axis=1)\n",
    "\n",
    "Test_col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000 \n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,Test_FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Test_Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Testing Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "Test_y1 = Test_FC_COP[50:100,0]\n",
    "Test_y2 = Test_FC_COP[50:100,1]\n",
    "Test_y3 = Test_Pred_COP[50:100,0]\n",
    "Test_y4 = Test_Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "# Test_data_filter = abs(y1) > 0\n",
    "# Test_data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(Test_y1[Test_data_filter], Test_y2[Test_data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(Test_y3[Test_data_filter2], Test_y4[Test_data_filter2 ], color='green')\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Testing Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,89) \n",
    "for i in range(0,1):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,SIDatasetWalking[50],color='red')\n",
    "    plt.plot(x,SIData_filtered[50], markerfacecolor='none',color='green')\n",
    "    plt.title('Participants 2')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Insol Value')\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('0-89 Insole Values')\n",
    "    plt.legend(['RealData', 'Smoothed'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_SIData_filtered[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "q7qd6uS3OBZs",
    "outputId": "b6b3d93f-657e-48fb-c376-cad72f55c8f6"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[0:100,0]\n",
    "Test_y2 = Test_FC_COP[0:100,1]\n",
    "Test_y3 = Test_Pred_COP[0:100,0]\n",
    "Test_y4 = Test_Pred_COP[0:100,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "R-fQqEiDOEDM",
    "outputId": "f5a46771-3b48-4093-fb96-7b645b1aaf39"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[100:200,0]\n",
    "Test_y2 = Test_FC_COP[100:200,1]\n",
    "Test_y3 = Test_Pred_COP[100:200,0]\n",
    "Test_y4 = Test_Pred_COP[100:200,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "Isay2TbVOG6F",
    "outputId": "4dc7543c-2fb0-4033-a8ea-f5783e879724"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[200:300,0]\n",
    "Test_y2 = Test_FC_COP[200:300,1]\n",
    "Test_y3 = Test_Pred_COP[200:300,0]\n",
    "Test_y4 = Test_Pred_COP[200:300,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "NlIfrOihUGt7",
    "outputId": "140ea2ee-6558-4efd-ba8e-0175eefb8983"
   },
   "outputs": [],
   "source": [
    "## Model Validation\n",
    "Test_Insole = pd.read_csv('0312AryaStand5Min2.txt', header=None, low_memory=False)\n",
    "TestSIData =  np.asarray(Test_Insole)\n",
    "\n",
    "Test_df = pd.read_csv('0312AryaStand5Min2.csv', low_memory=False)\n",
    "Test_columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "Test_selected_df = Test_df[Test_columns]\n",
    "Test_FPDatas = Test_selected_df[:6000]\n",
    "\n",
    "\n",
    "test_SmartInsole = np.array(TestSIData[:6000]).astype('float64')\n",
    "Test_FPData = np.array(Test_FPDatas).astype('float64')\n",
    "\n",
    "Test_FXData = Test_FPData[:,0]/10\n",
    "Test_FXData =  np.array(Test_FXData)\n",
    "Test_FXData = Test_FXData.reshape(-1,1)\n",
    "Test_FYData = Test_FPData[:,1]/5\n",
    "Test_FYData =  np.array(Test_FYData)\n",
    "Test_FYData = Test_FYData.reshape(-1,1)\n",
    "Test_FZData = (Test_FPData[:,2])/10\n",
    "Test_FZData =  np.array(Test_FZData)\n",
    "Test_FZData = Test_FZData.reshape(-1,1)\n",
    "Test_MXData = (Test_FPData[:,3])/1000\n",
    "Test_MXData =  np.array(Test_MXData)\n",
    "Test_MXData = Test_MXData.reshape(-1,1)\n",
    "Test_MYData = (Test_FPData[:,4])/10000\n",
    "Test_MYData =  np.array(Test_MYData)\n",
    "Test_MYData =Test_MYData.reshape(-1,1)\n",
    "Test_MZData = (Test_FPData[:,5])/100\n",
    "Test_MZData =  np.array(Test_MZData)\n",
    "Test_MZData = Test_MZData.reshape(-1,1)\n",
    "\n",
    "Test_newFPData = np.concatenate((Test_FXData, Test_FYData, Test_FZData, Test_MXData, Test_MYData, Test_MZData), axis=1)\n",
    "## End Load Data\n",
    "Test_newFPData = abs(Test_newFPData)\n",
    "\n",
    "Test_SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(test_SmartInsole[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    # coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "    # coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "    # coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "    # coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "    # coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    # coeffs[-7] = np.zeros_like(coeffs[-7])\n",
    "    Test_SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_SIData_filtered = np.zeros(test_SmartInsole.shape)\n",
    "for i in range(89):\n",
    "    Test_SIData_filtered[:, i] = pywt.waverec(Test_SIDWTcoeffs[i], 'db4', mode='symmetric', axis=0)\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    if i < len(Test_SIData_filtered):\n",
    "        Test_SIData_filtered[i][0] = 0\n",
    "        # Test_SIData_filtered[i][0] = Test_SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "        iter += 1\n",
    "    else:\n",
    "        Test_SIData_filtered[i][0] = 0\n",
    "\n",
    "# for i in range(len(Test_SIData_filtered)):\n",
    "#     Test_SIData_filtered[i][0] = i-1\n",
    "#     iter += 1\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    Test_SIData_filtered[i][np.abs(Test_SIData_filtered[i]) < 1] = 0\n",
    "\n",
    "Test_xscale = (Test_SIData_filtered - minInsole) / ( maxInsole - minInsole )\n",
    "\n",
    "Test_yscale = []\n",
    "for i in range(0,6):\n",
    "  Test_scale = (Test_newFPData[:,i] - FPmin[i]) / ( FPmax[i] - FPmin[i] )\n",
    "  Test_yscale.append(Test_scale)\n",
    "Test_yscale = np.array(Test_yscale)\n",
    "Test_yscale = Test_yscale.transpose()\n",
    "\n",
    "test_sample_size = Test_xscale.shape[0] # number of samples in train set\n",
    "test_time_steps  = Test_xscale.shape[1] # number of features in train set\n",
    "test_input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "test_train_data_reshaped = Test_xscale.reshape(test_sample_size,test_time_steps,test_input_dimension)\n",
    "\n",
    "Regression_Model.evaluate(test_train_data_reshaped, Test_yscale)\n",
    "Test_xX_model = Regression_Model.predict(test_train_data_reshaped)\n",
    "\n",
    "#invert normalize\n",
    "Test_y_inverse = []\n",
    "Test_y_pred_inverse = []\n",
    "\n",
    "for i in range(0,6):\n",
    "  Test_Y_inver =  Test_yscale[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_Pred_inver = Test_xX_model[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_y_inverse.append(Test_Y_inver)\n",
    "  Test_y_pred_inverse.append(Test_Pred_inver)\n",
    "Test_y_inverse = np.array(Test_y_inverse)\n",
    "Test_y_inverse = Test_y_inverse.transpose()\n",
    "Test_y_pred_inverse = np.array(Test_y_pred_inverse)\n",
    "Test_y_pred_inverse = Test_y_pred_inverse.transpose()\n",
    "\n",
    "for i in range(len(Test_y_pred_inverse)):\n",
    "    if (np.abs(Test_y_pred_inverse[i]) < 1).all():\n",
    "        Test_y_pred_inverse[i] = 0\n",
    "\n",
    "for i in range(0, Test_y_pred_inverse.shape[0], 50):\n",
    "    zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "    non_zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "    if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "        Test_y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "# make to original Data\n",
    "Test_FXData2 = Test_y_inverse[:,0]*10\n",
    "Test_FXData2=  np.array(Test_FXData2)\n",
    "Test_FXData2 = Test_FXData2.reshape(-1,1)\n",
    "\n",
    "Test_FYData2 = Test_y_inverse[:,1]*10\n",
    "Test_FYData2 =  np.array(Test_FYData2)\n",
    "Test_FYData2 = Test_FYData2.reshape(-1,1)\n",
    "\n",
    "Test_FZData2 = (Test_y_inverse[:,2]*10)\n",
    "Test_FZData2 =  np.array(Test_FZData2)\n",
    "Test_FZData2 = Test_FZData2.reshape(-1,1)\n",
    "\n",
    "Test_MXData2 = (Test_y_inverse[:,3]*1000)\n",
    "Test_MXData2 =  np.array(Test_MXData2)\n",
    "Test_MXData2 = Test_MXData2.reshape(-1,1)\n",
    "\n",
    "Test_MYData2 = (Test_y_inverse[:,4]*10000)\n",
    "Test_MYData2 =  np.array(Test_MYData2)\n",
    "Test_MYData2 = Test_MYData2.reshape(-1,1\n",
    "                          )\n",
    "Test_MZData2 = (Test_y_inverse[:,5]*100)\n",
    "Test_MZData2 =  np.array(Test_MZData2)\n",
    "Test_MZData2 = Test_MZData2.reshape(-1,1)\n",
    "\n",
    "Test_new_inverse2 = np.concatenate((Test_FXData2, Test_FYData2, Test_FZData2, Test_MXData2, Test_MYData2, Test_MZData2), axis=1)\n",
    "\n",
    "Test_FXData3 = Test_y_pred_inverse[:,0]*10\n",
    "Test_FXData3=  np.array(Test_FXData3)\n",
    "Test_FXData3 = Test_FXData3.reshape(-1,1)\n",
    "\n",
    "Test_FYData3 = Test_y_pred_inverse[:,1]*10\n",
    "Test_FYData3 =  np.array(Test_FYData3)\n",
    "Test_FYData3 = Test_FYData3.reshape(-1,1)\n",
    "\n",
    "Test_FZData3 = (Test_y_pred_inverse[:,2]*10)\n",
    "Test_FZData3 =  np.array(Test_FZData3)\n",
    "Test_FZData3 = Test_FZData3.reshape(-1,1)\n",
    "\n",
    "Test_MXData3 = (Test_y_pred_inverse[:,3]*1000)\n",
    "Test_MXData3 =  np.array(Test_MXData3)\n",
    "Test_MXData3 = Test_MXData3.reshape(-1,1)\n",
    "\n",
    "Test_MYData3 = (Test_y_pred_inverse[:,4]*10000)\n",
    "Test_MYData3 =  np.array(Test_MYData3)\n",
    "Test_MYData3 = Test_MYData3.reshape(-1,1)\n",
    "\n",
    "Test_MZData3 = (Test_y_pred_inverse[:,5]*100)\n",
    "Test_MZData3 =  np.array(Test_MZData3)\n",
    "Test_MZData3 = Test_MZData3.reshape(-1,1)\n",
    "\n",
    "Test_new_inverse3 = np.concatenate((Test_FXData3, Test_FYData3, Test_FZData3, Test_MXData3, Test_MYData3, Test_MZData3), axis=1)\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('CNN Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "Test_out_Fz = Test_new_inverse2[:,2]\n",
    "Test_out_Mx = Test_new_inverse2[:,3]\n",
    "Test_out_My = Test_new_inverse2[:,4]\n",
    "Test_Pred_Fz = Test_new_inverse3[:,2]\n",
    "Test_Pred_Mx = Test_new_inverse3[:,3]\n",
    "Test_Pred_My = Test_new_inverse3[:,4]\n",
    "\n",
    "Test_Pred_COPx=[]\n",
    "for i in range(0,len(Test_Pred_Fz)):\n",
    "  Test_Pred_COPx_temp=-(Test_Pred_My[i])/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPx_temp != Test_Pred_COPx_temp:\n",
    "    Test_Pred_COPx_temp=0\n",
    "  Test_Pred_COPx.append(Test_Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPx=[]\n",
    "for i in range(0,len(Test_out_Fz)):\n",
    "  Test_out_COPx_temp=-(Test_out_My[i])/Test_out_Fz[i]\n",
    "  if Test_out_COPx_temp != Test_out_COPx_temp:\n",
    "    Test_out_COPx_temp=0\n",
    "  Test_out_COPx.append(Test_out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_Pred_COPy=[]\n",
    "for i in range(0,len(Test_Pred_Mx)):\n",
    "  Test_Pred_COPy_temp=Test_Pred_Mx[i]/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPy_temp != Test_Pred_COPy_temp:\n",
    "    Test_Pred_COPy_temp=0\n",
    "  Test_Pred_COPy.append(Test_Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPy=[]\n",
    "for i in range(0,len(Test_out_Mx)):\n",
    "  Test_out_COPy_temp=Test_out_Mx[i]/Test_out_Fz[i]\n",
    "  if Test_out_COPy_temp != Test_out_COPy_temp:\n",
    "    Test_out_COPy_temp=0\n",
    "  Test_out_COPy.append(Test_out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "Test_out_COPx = np.array(Test_out_COPx)\n",
    "Test_out_COPx= Test_out_COPx.reshape(-1,1)\n",
    "\n",
    "Test_out_COPy = np.array(Test_out_COPy)\n",
    "Test_out_COPy= Test_out_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPx = np.array(Test_Pred_COPx)\n",
    "Test_Pred_COPx= Test_Pred_COPx.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPy = np.array(Test_Pred_COPy)\n",
    "Test_Pred_COPy= Test_Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COP = np.concatenate((Test_Pred_COPx, Test_Pred_COPy), axis=1)\n",
    "Test_FC_COP = np.concatenate((Test_out_COPx, Test_out_COPy), axis=1)\n",
    "\n",
    "Test_col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000 \n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,Test_FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Test_Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Testing Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "Test_y1 = Test_FC_COP[50:100,0]\n",
    "Test_y2 = Test_FC_COP[50:100,1]\n",
    "Test_y3 = Test_Pred_COP[50:100,0]\n",
    "Test_y4 = Test_Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "# Test_data_filter = abs(y1) > 0\n",
    "# Test_data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(Test_y1[Test_data_filter], Test_y2[Test_data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(Test_y3[Test_data_filter2], Test_y4[Test_data_filter2 ], color='green')\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Testing Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
