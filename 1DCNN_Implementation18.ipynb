{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFyb0y7PUJOo"
   },
   "source": [
    "# ResNet Model Building Pipeline for 1D Signals with DEMO\n",
    "#### ResNet18, ResNet34, ResNet50, ResNet101, ResNet152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9vTr2NhcGAA"
   },
   "source": [
    "# Test GPU (Optional)\n",
    "Before Starting, kindly check the available GPU from the Google Server, GPU model and other related information. It might help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VUNJNtNxcFTF"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(\"Is CUDA enabled GPU Available?\", torch.cuda.is_available())\n",
    "# print(\"GPU Number:\", torch.cuda.device_count())\n",
    "# print(\"Current GPU Index:\", torch.cuda.current_device())\n",
    "# print(\"GPU Type:\", torch.cuda.get_device_name(device=None))\n",
    "# print(\"GPU Capability:\", torch.cuda.get_device_capability(device=None))\n",
    "# print(\"Is GPU Initialized yet?\", torch.cuda.is_initialized())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement adamw_optimizer (from versions: none)\n",
      "ERROR: No matching distribution found for adamw_optimizer\n"
     ]
    }
   ],
   "source": [
    "!pip install adamw_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgW7r0C9TuZk"
   },
   "source": [
    "#Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eMhBhz1CrMb3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from numpy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, BatchNormalization, Activation, add\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape, Flatten, Dense\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "# from tensorflow.keras.optimizers import AdamW\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "import pywt\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "466PncP2BqnH"
   },
   "outputs": [],
   "source": [
    "# Import ResNet1D Module\n",
    "from ResNet_1DCNN import ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL73Q1sxcL6S"
   },
   "source": [
    "# DEMO: Regression and Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRzYwYcMt7fF"
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV3rv02oyfds"
   },
   "source": [
    "### Import and Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_ijTp2G0qFo"
   },
   "source": [
    "Import Dataset from a CSV file using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Bok0QWTra3Pr"
   },
   "outputs": [],
   "source": [
    "columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "wavelet = 'db4'\n",
    "max_iter = 50\n",
    "iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1SybkeF4yjjK"
   },
   "outputs": [],
   "source": [
    "# ## Load Data\n",
    "# Insole1 = pd.read_csv('0310AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole2 = pd.read_csv('0310HudaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole3 = pd.read_csv('0311LalaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole4 = pd.read_csv('0311YunitaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole5 = pd.read_csv('0312AbelRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole6 = pd.read_csv('0312AbiRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole7 = pd.read_csv('0312AryaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole8 = pd.read_csv('0312HawaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole9 = pd.read_csv('0312NisaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole10 = pd.read_csv('0313ChenChengRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole11 = pd.read_csv('0313RezaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole12 = pd.read_csv('0313RilaniRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole13 = pd.read_csv('0313SariRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole14 = pd.read_csv('0313ShelbyRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole15 = pd.read_csv('0314HelenRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole16 = pd.read_csv('0315AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole17 = pd.read_csv('0315HappyRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole18 = pd.read_csv('0317HeniRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole19 = pd.read_csv('0317NadiaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole20 = pd.read_csv('0317VikaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole21 = pd.read_csv('0319AlfianRWalk5Min.txt', header=None, low_memory=False)\n",
    "# Insole22 = pd.read_csv('1225JakariaRWalk5Min.txt', header=None, low_memory=False)\n",
    "# SIData1 =  np.array(Insole1)\n",
    "# SIData2 =  np.array(Insole2)\n",
    "# SIData3 =  np.array(Insole3)\n",
    "# SIData4 =  np.array(Insole4)\n",
    "# SIData5 =  np.array(Insole5)\n",
    "# SIData6 =  np.array(Insole6)\n",
    "# SIData7 =  np.array(Insole7)\n",
    "# SIData8 =  np.array(Insole8)\n",
    "# SIData9 =  np.array(Insole9)\n",
    "# SIData10 =  np.array(Insole10)\n",
    "# SIData11 =  np.array(Insole11)\n",
    "# SIData12 =  np.array(Insole12)\n",
    "# SIData13 =  np.array(Insole13)\n",
    "# SIData14 =  np.array(Insole14)\n",
    "# SIData15 =  np.array(Insole15)\n",
    "# SIData16 =  np.array(Insole16)\n",
    "# SIData17 =  np.array(Insole17)\n",
    "# SIData18 =  np.array(Insole18)\n",
    "# SIData19 =  np.array(Insole19)\n",
    "# SIData20 =  np.array(Insole20)\n",
    "# SIData21 =  np.array(Insole21)\n",
    "# SIData22 =  np.array(Insole22)\n",
    "\n",
    "# df1 = pd.read_csv('0310AyuRWalk5Min.csv', low_memory=False)\n",
    "# df2 = pd.read_csv('0310HudaRWalk5Min.csv', low_memory=False)\n",
    "# df3 = pd.read_csv('0311LalaRWalk5Min.csv', low_memory=False)\n",
    "# df4 = pd.read_csv('0311YunitaRWalk5Min.csv', low_memory=False)\n",
    "# df5 = pd.read_csv('0312AbelRWalk5Min.csv', low_memory=False)\n",
    "# df6 = pd.read_csv('0312AbiRWalk5Min.csv', low_memory=False)\n",
    "# df7 = pd.read_csv('0312AryaRWalk5Min.csv', low_memory=False)\n",
    "# df8 = pd.read_csv('0312HawaRWalk5Min.csv', low_memory=False)\n",
    "# df9 = pd.read_csv('0312NisaRWalk5Min.csv', low_memory=False)\n",
    "# df10 = pd.read_csv('0313ChenChengRWalk5Min.csv', low_memory=False)\n",
    "# df11 = pd.read_csv('0313RezaRWalk5Min.csv', low_memory=False)\n",
    "# df12 = pd.read_csv('0313RilaniRWalk5Min.csv', low_memory=False)\n",
    "# df13 = pd.read_csv('0313SariRWalk5Min.csv', low_memory=False)\n",
    "# df14 = pd.read_csv('0313ShelbyRWalk5Min.csv', low_memory=False)\n",
    "# df15 = pd.read_csv('0314HelenRWalk5Min.csv', low_memory=False)\n",
    "# df16 = pd.read_csv('0315AyuRWalk5Min.csv', low_memory=False)\n",
    "# df17 = pd.read_csv('0315HappyRWalk5Min.csv', low_memory=False)\n",
    "# df18 = pd.read_csv('0317HeniRWalk5Min.csv', low_memory=False)\n",
    "# df19 = pd.read_csv('0317NadiaRWalk5Min.csv', low_memory=False)\n",
    "# df20 = pd.read_csv('0317VikaRWalk5Min.csv', low_memory=False)\n",
    "# df21 = pd.read_csv('0319AlfianRWalk5Min.csv', low_memory=False)\n",
    "# df22 = pd.read_csv('1225JakariaRWalk5Min.csv', low_memory=False)\n",
    "\n",
    "# selected_df1 = df1[columns]\n",
    "# selected_df2 = df2[columns]\n",
    "# selected_df3 = df3[columns]\n",
    "# selected_df4 = df4[columns]\n",
    "# selected_df5 = df5[columns]\n",
    "# selected_df6 = df6[columns]\n",
    "# selected_df7 = df7[columns]\n",
    "# selected_df8 = df8[columns]\n",
    "# selected_df9 = df9[columns]\n",
    "# selected_df10 = df10[columns]\n",
    "# selected_df11 = df11[columns]\n",
    "# selected_df12 = df12[columns]\n",
    "# selected_df13 = df13[columns]\n",
    "# selected_df14 = df14[columns]\n",
    "# selected_df15 = df15[columns]\n",
    "# selected_df16 = df16[columns]\n",
    "# selected_df17 = df17[columns]\n",
    "# selected_df18 = df18[columns]\n",
    "# selected_df19 = df19[columns]\n",
    "# selected_df20 = df20[columns]\n",
    "# selected_df21 = df21[columns]\n",
    "# selected_df22 = df22[columns]\n",
    "# FPDatas1 = selected_df1[:15000]\n",
    "# FPDatas2 = selected_df2[:15000]\n",
    "# FPDatas3 = selected_df3[:15000]\n",
    "# FPDatas4 = selected_df4[:15000]\n",
    "# FPDatas5 = selected_df5[:15000]\n",
    "# FPDatas6 = selected_df6[:15000]\n",
    "# FPDatas7 = selected_df7[:15000]\n",
    "# FPDatas8 = selected_df8[:15000]\n",
    "# FPDatas9 = selected_df9[:15000]\n",
    "# FPDatas10 = selected_df10[:15000]\n",
    "# FPDatas11 = selected_df11[:15000]\n",
    "# FPDatas12 = selected_df12[:15000]\n",
    "# FPDatas13 = selected_df13[:15000]\n",
    "# FPDatas14 = selected_df14[:15000]\n",
    "# FPDatas15 = selected_df15[:15000]\n",
    "# FPDatas16 = selected_df16[:15000]\n",
    "# FPDatas17 = selected_df17[:15000]\n",
    "# FPDatas18 = selected_df18[:15000]\n",
    "# FPDatas19 = selected_df19[:15000]\n",
    "# FPDatas20 = selected_df20[:15000]\n",
    "# FPDatas21 = selected_df21[:15000]\n",
    "# FPDatas22 = selected_df22[:15000]\n",
    "\n",
    "# SmartInsole1 = np.array(SIData1[:15000]).astype('float64')\n",
    "# SmartInsole2 = np.array(SIData2[:15000]).astype('float64')\n",
    "# SmartInsole3 = np.array(SIData3[:15000]).astype('float64')\n",
    "# SmartInsole4 = np.array(SIData4[:15000]).astype('float64')\n",
    "# SmartInsole5 = np.array(SIData5[:15000]).astype('float64')\n",
    "# SmartInsole6 = np.array(SIData6[:15000]).astype('float64')\n",
    "# SmartInsole7 = np.array(SIData7[:15000]).astype('float64')\n",
    "# SmartInsole8 = np.array(SIData8[:15000]).astype('float64')\n",
    "# SmartInsole9 = np.array(SIData9[:15000]).astype('float64')\n",
    "# SmartInsole10 = np.array(SIData10[:15000]).astype('float64')\n",
    "# SmartInsole11 = np.array(SIData11[:15000]).astype('float64')\n",
    "# SmartInsole12 = np.array(SIData12[:15000]).astype('float64')\n",
    "# SmartInsole13 = np.array(SIData13[:15000]).astype('float64')\n",
    "# SmartInsole14 = np.array(SIData14[:15000]).astype('float64')\n",
    "# SmartInsole15 = np.array(SIData15[:15000]).astype('float64')\n",
    "# SmartInsole16 = np.array(SIData16[:15000]).astype('float64')\n",
    "# SmartInsole17 = np.array(SIData17[:15000]).astype('float64')\n",
    "# SmartInsole18 = np.array(SIData18[:15000]).astype('float64')\n",
    "# SmartInsole19 = np.array(SIData19[:15000]).astype('float64')\n",
    "# SmartInsole20 = np.array(SIData20[:15000]).astype('float64')\n",
    "# SmartInsole21 = np.array(SIData21[:15000]).astype('float64')\n",
    "# SmartInsole22 = np.array(SIData22[:15000]).astype('float64')\n",
    "# FPData1 = np.array(FPDatas1).astype('float64')\n",
    "# FPData2 = np.array(FPDatas2).astype('float64')\n",
    "# FPData3= np.array(FPDatas3).astype('float64')\n",
    "# FPData4= np.array(FPDatas4).astype('float64')\n",
    "# FPData5= np.array(FPDatas5).astype('float64')\n",
    "# FPData6= np.array(FPDatas6).astype('float64')\n",
    "# FPData7= np.array(FPDatas7).astype('float64')\n",
    "# FPData8= np.array(FPDatas8).astype('float64')\n",
    "# FPData9= np.array(FPDatas9).astype('float64')\n",
    "# FPData10 = np.array(FPDatas10).astype('float64')\n",
    "# FPData11 = np.array(FPDatas11).astype('float64')\n",
    "# FPData12= np.array(FPDatas12).astype('float64')\n",
    "# FPData13= np.array(FPDatas13).astype('float64')\n",
    "# FPData14= np.array(FPDatas14).astype('float64')\n",
    "# FPData15= np.array(FPDatas15).astype('float64')\n",
    "# FPData16= np.array(FPDatas16).astype('float64')\n",
    "# FPData17= np.array(FPDatas17).astype('float64')\n",
    "# FPData18= np.array(FPDatas18).astype('float64')\n",
    "# FPData19= np.array(FPDatas19).astype('float64')\n",
    "# FPData20= np.array(FPDatas20).astype('float64')\n",
    "# FPData21= np.array(FPDatas21).astype('float64')\n",
    "# FPData22= np.array(FPDatas22).astype('float64')\n",
    "\n",
    "# # SIDataset = np.concatenate((SmartInsole1, SmartInsole2, SmartInsole3,\n",
    "# #                             SmartInsole4, SmartInsole5, SmartInsole6,\n",
    "# #                             SmartInsole7, SmartInsole8, SmartInsole9,\n",
    "# #                             SmartInsole10, SmartInsole11, SmartInsole12,\n",
    "# #                             SmartInsole13, SmartInsole14, SmartInsole15,\n",
    "# #                             SmartInsole16, SmartInsole17, SmartInsole18,\n",
    "# #                             SmartInsole19, SmartInsole20, SmartInsole21,\n",
    "# #                             SmartInsole22), axis=0)\n",
    "# # FPDataset = np.concatenate((FPData1, FPData2, FPData3,\n",
    "# #                             FPData4, FPData5, FPData6,\n",
    "# #                             FPData7, FPData8, FPData9,\n",
    "# #                             FPData10, FPData11, FPData12,\n",
    "# #                             FPData13, FPData14, FPData15,\n",
    "# #                             FPData16, FPData17, FPData18,\n",
    "# #                             FPData19, FPData20, FPData21,\n",
    "# #                             FPData22), axis=0)\n",
    "\n",
    "# SIDataset = SmartInsole22\n",
    "# FPDataset = FPData22\n",
    "\n",
    "# SIDataset = np.array(SIDataset).astype('float64')\n",
    "# FPDataset = np.array(FPDataset).astype('float64')\n",
    "\n",
    "# FXData = FPDataset[:,0]\n",
    "# FXData =  np.array(FXData)\n",
    "# FXData = FXData.reshape(-1,1)\n",
    "# FYData = FPDataset[:,1]\n",
    "# FYData =  np.array(FYData)\n",
    "# FYData = FYData.reshape(-1,1)\n",
    "# FZData = (FPDataset[:,2])/10\n",
    "# FZData =  np.array(FZData)\n",
    "# FZData = FZData.reshape(-1,1)\n",
    "# MXData = (FPDataset[:,3])/1000\n",
    "# MXData =  np.array(MXData)\n",
    "# MXData = MXData.reshape(-1,1)\n",
    "# MYData = (FPDataset[:,4])/10000\n",
    "# MYData =  np.array(MYData)\n",
    "# MYData = MYData.reshape(-1,1)\n",
    "# MZData = (FPDataset[:,5])/100\n",
    "# MZData =  np.array(MZData)\n",
    "# MZData = MZData.reshape(-1,1)\n",
    "\n",
    "# newFPDataset = np.concatenate((FXData, FYData, FZData, MXData, MYData, MZData), axis=1)\n",
    "# ## End Load Data\n",
    "\n",
    "# wavelet = 'db4'\n",
    "\n",
    "# SIDWTcoeffs = []\n",
    "# for i in range(89):\n",
    "#     coeffs = pywt.wavedec(SIDataset[:, i], wavelet)\n",
    "#     coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "#     # coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "#     # coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "#     # coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "#     # coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "#     # coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "#     SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "# SIData_filtered = np.zeros(SIDataset.shape)\n",
    "# for i in range(89):\n",
    "#     SIData_filtered[:, i] = pywt.waverec(SIDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "# max_iter = 50\n",
    "# iter = 0\n",
    "# for i in range(len(SIData_filtered)):\n",
    "#     SIData_filtered[i][0] = SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "#     iter += 1\n",
    "\n",
    "# for i in range(len(SIData_filtered)):\n",
    "#     SIData_filtered[i][np.abs(SIData_filtered[i]) < 1] = 0\n",
    "\n",
    "# # Data Normalization\n",
    "# minInsole = SIData_filtered.min()\n",
    "# maxInsole = SIData_filtered.max()\n",
    "# xscale = (SIData_filtered - minInsole) / ( maxInsole - minInsole )\n",
    "\n",
    "# FPmax = []\n",
    "# FPmin = []\n",
    "# yscale = []\n",
    "\n",
    "# for i in range(0,6):\n",
    "#     minFP = newFPDataset[:,i].min()\n",
    "#     maxFP = newFPDataset[:,i].max()\n",
    "#     FPmin.append(minFP)\n",
    "#     FPmax.append(maxFP)\n",
    "\n",
    "# FPmin = np.array(FPmin)\n",
    "# FPmax = np.array(FPmax)\n",
    "\n",
    "# for i in range(0,6):\n",
    "#   scale = (newFPDataset[:,i] - FPmin[i]) / ( FPmax[i] - FPmin[i] )\n",
    "#   yscale.append(scale)\n",
    "# yscale = np.array(yscale)\n",
    "# yscale = yscale.transpose()\n",
    "# #End Data Normalization\n",
    "\n",
    "# #Spliting Data\n",
    "# sample_size = xscale.shape[0] # number of samples in train set\n",
    "# time_steps  = xscale.shape[1] # number of features in train set\n",
    "# input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "# train_data_reshaped = xscale.reshape(sample_size,time_steps,input_dimension)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data_reshaped, yscale, test_size=0.20, random_state=2)\n",
    "# print(X_train.shape,X_test.shape)\n",
    "# print(y_train.shape,y_test.shape)\n",
    "# #End Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeR4-T_yKu00",
    "outputId": "96fc54d5-0b4d-4a64-b26a-71ba49a1f0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264000, 89, 1) (66000, 89, 1)\n",
      "(264000, 6) (66000, 6)\n"
     ]
    }
   ],
   "source": [
    "columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "wavelet = 'db4'\n",
    "max_iter = 50\n",
    "iter = 0\n",
    "\n",
    "# Walking Dataset\n",
    "InsoleWalking1 = pd.read_csv('0310AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking2 = pd.read_csv('0310HudaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking3 = pd.read_csv('0311LalaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking4 = pd.read_csv('0311YunitaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking5 = pd.read_csv('0312AbelRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking6 = pd.read_csv('0312AbiRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking7 = pd.read_csv('0312AryaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking8 = pd.read_csv('0312HawaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking9 = pd.read_csv('0312NisaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking10 = pd.read_csv('0313ChenChengRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking11 = pd.read_csv('0313RezaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking12 = pd.read_csv('0313RilaniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking13 = pd.read_csv('0313SariRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking14 = pd.read_csv('0313ShelbyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking15 = pd.read_csv('0314HelenRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking16 = pd.read_csv('0315AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking17 = pd.read_csv('0315HappyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking18 = pd.read_csv('0317HeniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking19 = pd.read_csv('0317NadiaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking20 = pd.read_csv('0317VikaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking21 = pd.read_csv('0319AlfianRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking22 = pd.read_csv('1225JakariaRWalk5Min.txt', header=None, low_memory=False)\n",
    "SIDatasWalking1 =  np.array(InsoleWalking1)\n",
    "SIDatasWalking2 =  np.array(InsoleWalking2)\n",
    "SIDatasWalking3 =  np.array(InsoleWalking3)\n",
    "SIDatasWalking4 =  np.array(InsoleWalking4)\n",
    "SIDatasWalking5 =  np.array(InsoleWalking5)\n",
    "SIDatasWalking6 =  np.array(InsoleWalking6)\n",
    "SIDatasWalking7 =  np.array(InsoleWalking7)\n",
    "SIDatasWalking8 =  np.array(InsoleWalking8)\n",
    "SIDatasWalking9 =  np.array(InsoleWalking9)\n",
    "SIDatasWalking10 =  np.array(InsoleWalking10)\n",
    "SIDatasWalking11 =  np.array(InsoleWalking11)\n",
    "SIDatasWalking12 =  np.array(InsoleWalking12)\n",
    "SIDatasWalking13 =  np.array(InsoleWalking13)\n",
    "SIDatasWalking14 =  np.array(InsoleWalking14)\n",
    "SIDatasWalking15 =  np.array(InsoleWalking15)\n",
    "SIDatasWalking16 =  np.array(InsoleWalking16)\n",
    "SIDatasWalking17 =  np.array(InsoleWalking17)\n",
    "SIDatasWalking18 =  np.array(InsoleWalking18)\n",
    "SIDatasWalking19 =  np.array(InsoleWalking19)\n",
    "SIDatasWalking20 =  np.array(InsoleWalking20)\n",
    "SIDatasWalking21 =  np.array(InsoleWalking21)\n",
    "SIDatasWalking22 =  np.array(InsoleWalking22)\n",
    "\n",
    "dfwalk1 = pd.read_csv('0310AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk2 = pd.read_csv('0310HudaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk3 = pd.read_csv('0311LalaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk4 = pd.read_csv('0311YunitaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk5 = pd.read_csv('0312AbelRWalk5Min.csv', low_memory=False)\n",
    "dfwalk6 = pd.read_csv('0312AbiRWalk5Min.csv', low_memory=False)\n",
    "dfwalk7 = pd.read_csv('0312AryaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk8 = pd.read_csv('0312HawaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk9 = pd.read_csv('0312NisaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk10 = pd.read_csv('0313ChenChengRWalk5Min.csv', low_memory=False)\n",
    "dfwalk11 = pd.read_csv('0313RezaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk12 = pd.read_csv('0313RilaniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk13 = pd.read_csv('0313SariRWalk5Min.csv', low_memory=False)\n",
    "dfwalk14 = pd.read_csv('0313ShelbyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk15 = pd.read_csv('0314HelenRWalk5Min.csv', low_memory=False)\n",
    "dfwalk16 = pd.read_csv('0315AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk17 = pd.read_csv('0315HappyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk18 = pd.read_csv('0317HeniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk19 = pd.read_csv('0317NadiaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk20 = pd.read_csv('0317VikaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk21 = pd.read_csv('0319AlfianRWalk5Min.csv', low_memory=False)\n",
    "dfwalk22 = pd.read_csv('1225JakariaRWalk5Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfwalks1 = dfwalk1[columns]\n",
    "selected_dfwalks2 = dfwalk2[columns]\n",
    "selected_dfwalks3 = dfwalk3[columns]\n",
    "selected_dfwalks4 = dfwalk4[columns]\n",
    "selected_dfwalks5 = dfwalk5[columns]\n",
    "selected_dfwalks6 = dfwalk6[columns]\n",
    "selected_dfwalks7 = dfwalk7[columns]\n",
    "selected_dfwalks8 = dfwalk8[columns]\n",
    "selected_dfwalks9 = dfwalk9[columns]\n",
    "selected_dfwalks10 = dfwalk10[columns]\n",
    "selected_dfwalks11 = dfwalk11[columns]\n",
    "selected_dfwalks12 = dfwalk12[columns]\n",
    "selected_dfwalks13 = dfwalk13[columns]\n",
    "selected_dfwalks14 = dfwalk14[columns]\n",
    "selected_dfwalks15 = dfwalk15[columns]\n",
    "selected_dfwalks16 = dfwalk16[columns]\n",
    "selected_dfwalks17 = dfwalk17[columns]\n",
    "selected_dfwalks18 = dfwalk18[columns]\n",
    "selected_dfwalks19 = dfwalk19[columns]\n",
    "selected_dfwalks20 = dfwalk20[columns]\n",
    "selected_dfwalks21 = dfwalk21[columns]\n",
    "selected_dfwalks22 = dfwalk22[columns]\n",
    "FPDatasWalking1 = selected_dfwalks1[:15000]\n",
    "FPDatasWalking2 = selected_dfwalks2[:15000]\n",
    "FPDatasWalking3 = selected_dfwalks3[:15000]\n",
    "FPDatasWalking4 = selected_dfwalks4[:15000]\n",
    "FPDatasWalking5 = selected_dfwalks5[:15000]\n",
    "FPDatasWalking6 = selected_dfwalks6[:15000]\n",
    "FPDatasWalking7 = selected_dfwalks7[:15000]\n",
    "FPDatasWalking8 = selected_dfwalks8[:15000]\n",
    "FPDatasWalking9 = selected_dfwalks9[:15000]\n",
    "FPDatasWalking10 = selected_dfwalks10[:15000]\n",
    "FPDatasWalking11 = selected_dfwalks11[:15000]\n",
    "FPDatasWalking12 = selected_dfwalks12[:15000]\n",
    "FPDatasWalking13 = selected_dfwalks13[:15000]\n",
    "FPDatasWalking14 = selected_dfwalks14[:15000]\n",
    "FPDatasWalking15 = selected_dfwalks15[:15000]\n",
    "FPDatasWalking16 = selected_dfwalks16[:15000]\n",
    "FPDatasWalking17 = selected_dfwalks17[:15000]\n",
    "FPDatasWalking18 = selected_dfwalks18[:15000]\n",
    "FPDatasWalking19 = selected_dfwalks19[:15000]\n",
    "FPDatasWalking20 = selected_dfwalks20[:15000]\n",
    "FPDatasWalking21 = selected_dfwalks21[:15000]\n",
    "FPDatasWalking22 = selected_dfwalks22[:15000]\n",
    "\n",
    "SIDataWalking1 = np.array(SIDatasWalking1[:15000]).astype('float32')\n",
    "SIDataWalking2 = np.array(SIDatasWalking2[:15000]).astype('float32')\n",
    "SIDataWalking3 = np.array(SIDatasWalking3[:15000]).astype('float32')\n",
    "SIDataWalking4 = np.array(SIDatasWalking4[:15000]).astype('float32')\n",
    "SIDataWalking5 = np.array(SIDatasWalking5[:15000]).astype('float32')\n",
    "SIDataWalking6 = np.array(SIDatasWalking6[:15000]).astype('float32')\n",
    "SIDataWalking7 = np.array(SIDatasWalking7[:15000]).astype('float32')\n",
    "SIDataWalking8 = np.array(SIDatasWalking8[:15000]).astype('float32')\n",
    "SIDataWalking9 = np.array(SIDatasWalking9[:15000]).astype('float32')\n",
    "SIDataWalking10 = np.array(SIDatasWalking10[:15000]).astype('float32')\n",
    "SIDataWalking11 = np.array(SIDatasWalking11[:15000]).astype('float32')\n",
    "SIDataWalking12 = np.array(SIDatasWalking12[:15000]).astype('float32')\n",
    "SIDataWalking13 = np.array(SIDatasWalking13[:15000]).astype('float32')\n",
    "SIDataWalking14 = np.array(SIDatasWalking14[:15000]).astype('float32')\n",
    "SIDataWalking15 = np.array(SIDatasWalking15[:15000]).astype('float32')\n",
    "SIDataWalking16 = np.array(SIDatasWalking16[:15000]).astype('float32')\n",
    "SIDataWalking17 = np.array(SIDatasWalking17[:15000]).astype('float32')\n",
    "SIDataWalking18 = np.array(SIDatasWalking18[:15000]).astype('float32')\n",
    "SIDataWalking19 = np.array(SIDatasWalking19[:15000]).astype('float32')\n",
    "SIDataWalking20 = np.array(SIDatasWalking20[:15000]).astype('float32')\n",
    "SIDataWalking21 = np.array(SIDatasWalking21[:15000]).astype('float32')\n",
    "SIDataWalking22 = np.array(SIDatasWalking22[:15000]).astype('float32')\n",
    "FPDataWalking1 = np.array(FPDatasWalking1).astype('float32')\n",
    "FPDataWalking2 = np.array(FPDatasWalking2).astype('float32')\n",
    "FPDataWalking3= np.array(FPDatasWalking3).astype('float32')\n",
    "FPDataWalking4= np.array(FPDatasWalking4).astype('float32')\n",
    "FPDataWalking5= np.array(FPDatasWalking5).astype('float32')\n",
    "FPDataWalking6= np.array(FPDatasWalking6).astype('float32')\n",
    "FPDataWalking7= np.array(FPDatasWalking7).astype('float32')\n",
    "FPDataWalking8= np.array(FPDatasWalking8).astype('float32')\n",
    "FPDataWalking9= np.array(FPDatasWalking9).astype('float32')\n",
    "FPDataWalking10 = np.array(FPDatasWalking10).astype('float32')\n",
    "FPDataWalking11 = np.array(FPDatasWalking11).astype('float32')\n",
    "FPDataWalking12= np.array(FPDatasWalking12).astype('float32')\n",
    "FPDataWalking13= np.array(FPDatasWalking13).astype('float32')\n",
    "FPDataWalking14= np.array(FPDatasWalking14).astype('float32')\n",
    "FPDataWalking15= np.array(FPDatasWalking15).astype('float32')\n",
    "FPDataWalking16= np.array(FPDatasWalking16).astype('float32')\n",
    "FPDataWalking17= np.array(FPDatasWalking17).astype('float32')\n",
    "FPDataWalking18= np.array(FPDatasWalking18).astype('float32')\n",
    "FPDataWalking19= np.array(FPDatasWalking19).astype('float32')\n",
    "FPDataWalking20= np.array(FPDatasWalking20).astype('float32')\n",
    "FPDataWalking21= np.array(FPDatasWalking21).astype('float32')\n",
    "FPDataWalking22= np.array(FPDatasWalking22).astype('float32')\n",
    "\n",
    "SIDatasetWalking = np.concatenate((SIDataWalking1, SIDataWalking2, SIDataWalking3,\n",
    "                            SIDataWalking4, SIDataWalking5, SIDataWalking6,\n",
    "                            SIDataWalking7, SIDataWalking8, SIDataWalking9,\n",
    "                            SIDataWalking10, SIDataWalking11, SIDataWalking12,\n",
    "                            SIDataWalking13, SIDataWalking14, SIDataWalking15,\n",
    "                            SIDataWalking16, SIDataWalking17, SIDataWalking18,\n",
    "                            SIDataWalking19, SIDataWalking20, SIDataWalking21,\n",
    "                            SIDataWalking22), axis=0)\n",
    "                            \n",
    "FPDatasetWalking = np.concatenate((FPDataWalking1, FPDataWalking2, FPDataWalking3,\n",
    "                            FPDataWalking4, FPDataWalking5, FPDataWalking6,\n",
    "                            FPDataWalking7, FPDataWalking8, FPDataWalking9,\n",
    "                            FPDataWalking10, FPDataWalking11, FPDataWalking12,\n",
    "                            FPDataWalking13, FPDataWalking14, FPDataWalking15,\n",
    "                            FPDataWalking16, FPDataWalking17, FPDataWalking18,\n",
    "                            FPDataWalking19, FPDataWalking20, FPDataWalking21,\n",
    "                            FPDataWalking22), axis=0)\n",
    "\n",
    "# SIDatasetWalking = SIDataWalking1\n",
    "# FPDatasetWalking = FPDataWalking1\n",
    "\n",
    "# SIDatasetWalking = np.array(SIDatasetWalking).astype('float64')\n",
    "# FPDatasetWalking = np.array(FPDatasetWalking).astype('float64')\n",
    "\n",
    "# Standing Dataset\n",
    "InsoleStanding1 = pd.read_csv('0310AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding2 = pd.read_csv('0310HudaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding3 = pd.read_csv('0311LalaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding4 = pd.read_csv('0311YunitaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding5 = pd.read_csv('0312AbelStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding6 = pd.read_csv('0312AbiStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding7 = pd.read_csv('0312AryaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding8 = pd.read_csv('0312HawaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding9 = pd.read_csv('0312NisaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding10 = pd.read_csv('0313ChenChengStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding11 = pd.read_csv('0313RezaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding12 = pd.read_csv('0313RilaniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding13 = pd.read_csv('0313SariStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding14 = pd.read_csv('0313ShelbyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding15 = pd.read_csv('0314HelenStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding16 = pd.read_csv('0315AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding17 = pd.read_csv('0315HappyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding18 = pd.read_csv('0317HeniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding19 = pd.read_csv('0317NadiaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding20 = pd.read_csv('0317VikaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding21 = pd.read_csv('0319AlfianStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding22 = pd.read_csv('0310JakaStand2Min.txt', header=None, low_memory=False)\n",
    "SIDatasStanding1 =  np.array(InsoleStanding1)\n",
    "SIDatasStanding2 =  np.array(InsoleStanding2)\n",
    "SIDatasStanding3 =  np.array(InsoleStanding3)\n",
    "SIDatasStanding4 =  np.array(InsoleStanding4)\n",
    "SIDatasStanding5 =  np.array(InsoleStanding5)\n",
    "SIDatasStanding6 =  np.array(InsoleStanding6)\n",
    "SIDatasStanding7 =  np.array(InsoleStanding7)\n",
    "SIDatasStanding8 =  np.array(InsoleStanding8)\n",
    "SIDatasStanding9 =  np.array(InsoleStanding9)\n",
    "SIDatasStanding10 =  np.array(InsoleStanding10)\n",
    "SIDatasStanding11 =  np.array(InsoleStanding11)\n",
    "SIDatasStanding12 =  np.array(InsoleStanding12)\n",
    "SIDatasStanding13 =  np.array(InsoleStanding13)\n",
    "SIDatasStanding14 =  np.array(InsoleStanding14)\n",
    "SIDatasStanding15 =  np.array(InsoleStanding15)\n",
    "SIDatasStanding16 =  np.array(InsoleStanding16)\n",
    "SIDatasStanding17 =  np.array(InsoleStanding17)\n",
    "SIDatasStanding18 =  np.array(InsoleStanding18)\n",
    "SIDatasStanding19 =  np.array(InsoleStanding19)\n",
    "SIDatasStanding20 =  np.array(InsoleStanding20)\n",
    "SIDatasStanding21 =  np.array(InsoleStanding21)\n",
    "SIDatasStanding22 =  np.array(InsoleStanding22)\n",
    "\n",
    "dfStanding1 = pd.read_csv('0310AyuStand5Min1.csv', low_memory=False)\n",
    "dfStanding2 = pd.read_csv('0310HudaStand5Min1.csv', low_memory=False)\n",
    "dfStanding3 = pd.read_csv('0311LalaStand5Min1.csv', low_memory=False)\n",
    "dfStanding4 = pd.read_csv('0311YunitaStand5Min1.csv', low_memory=False)\n",
    "dfStanding5 = pd.read_csv('0312AbelStand5Min1.csv', low_memory=False)\n",
    "dfStanding6 = pd.read_csv('0312AbiStand5Min1.csv', low_memory=False)\n",
    "dfStanding7 = pd.read_csv('0312AryaStand5Min1.csv', low_memory=False)\n",
    "dfStanding8 = pd.read_csv('0312HawaStand5Min1.csv', low_memory=False)\n",
    "dfStanding9 = pd.read_csv('0312NisaStand5Min1.csv', low_memory=False)\n",
    "dfStanding10 = pd.read_csv('0313ChenChengStand5Min1.csv', low_memory=False)\n",
    "dfStanding11 = pd.read_csv('0313RezaStand5Min1.csv', low_memory=False)\n",
    "dfStanding12 = pd.read_csv('0313RilaniStand5Min1.csv', low_memory=False)\n",
    "dfStanding13 = pd.read_csv('0313SariStand5Min1.csv', low_memory=False)\n",
    "dfStanding14 = pd.read_csv('0313ShelbyStand5Min1.csv', low_memory=False)\n",
    "dfStanding15 = pd.read_csv('0314HelenStand5Min1.csv', low_memory=False)\n",
    "dfStanding16 = pd.read_csv('0315AyuStand5Min1.csv', low_memory=False)\n",
    "dfStanding17 = pd.read_csv('0315HappyStand5Min1.csv', low_memory=False)\n",
    "dfStanding18 = pd.read_csv('0317HeniStand5Min1.csv', low_memory=False)\n",
    "dfStanding19 = pd.read_csv('0317NadiaStand5Min1.csv', low_memory=False)\n",
    "dfStanding20 = pd.read_csv('0317VikaStand5Min1.csv', low_memory=False)\n",
    "dfStanding21 = pd.read_csv('0319AlfianStand5Min1.csv', low_memory=False)\n",
    "dfStanding22 = pd.read_csv('0310JakaStand2Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfStandings1 = dfStanding1[columns]\n",
    "selected_dfStandings2 = dfStanding2[columns]\n",
    "selected_dfStandings3 = dfStanding3[columns]\n",
    "selected_dfStandings4 = dfStanding4[columns]\n",
    "selected_dfStandings5 = dfStanding5[columns]\n",
    "selected_dfStandings6 = dfStanding6[columns]\n",
    "selected_dfStandings7 = dfStanding7[columns]\n",
    "selected_dfStandings8 = dfStanding8[columns]\n",
    "selected_dfStandings9 = dfStanding9[columns]\n",
    "selected_dfStandings10 = dfStanding10[columns]\n",
    "selected_dfStandings11 = dfStanding11[columns]\n",
    "selected_dfStandings12 = dfStanding12[columns]\n",
    "selected_dfStandings13 = dfStanding13[columns]\n",
    "selected_dfStandings14 = dfStanding14[columns]\n",
    "selected_dfStandings15 = dfStanding15[columns]\n",
    "selected_dfStandings16 = dfStanding16[columns]\n",
    "selected_dfStandings17 = dfStanding17[columns]\n",
    "selected_dfStandings18 = dfStanding18[columns]\n",
    "selected_dfStandings19 = dfStanding19[columns]\n",
    "selected_dfStandings20 = dfStanding20[columns]\n",
    "selected_dfStandings21 = dfStanding21[columns]\n",
    "selected_dfStandings22 = dfStanding22[columns]\n",
    "FPDataStandings1 = selected_dfStandings1[:6000]\n",
    "FPDataStandings2 = selected_dfStandings2[:6000]\n",
    "FPDataStandings3 = selected_dfStandings3[:6000]\n",
    "FPDataStandings4 = selected_dfStandings4[:6000]\n",
    "FPDataStandings5 = selected_dfStandings5[:6000]\n",
    "FPDataStandings6 = selected_dfStandings6[:6000]\n",
    "FPDataStandings7 = selected_dfStandings7[:6000]\n",
    "FPDataStandings8 = selected_dfStandings8[:6000]\n",
    "FPDataStandings9 = selected_dfStandings9[:6000]\n",
    "FPDataStandings10 = selected_dfStandings10[:6000]\n",
    "FPDataStandings11 = selected_dfStandings11[:6000]\n",
    "FPDataStandings12 = selected_dfStandings12[:6000]\n",
    "FPDataStandings13 = selected_dfStandings13[:6000]\n",
    "FPDataStandings14 = selected_dfStandings14[:6000]\n",
    "FPDataStandings15 = selected_dfStandings15[:6000]\n",
    "FPDataStandings16 = selected_dfStandings16[:6000]\n",
    "FPDataStandings17 = selected_dfStandings17[:6000]\n",
    "FPDataStandings18 = selected_dfStandings18[:6000]\n",
    "FPDataStandings19 = selected_dfStandings19[:6000]\n",
    "FPDataStandings20 = selected_dfStandings20[:6000]\n",
    "FPDataStandings21 = selected_dfStandings21[:6000]\n",
    "FPDataStandings22 = selected_dfStandings22[:6000]\n",
    "\n",
    "SIDataStanding1 = np.array(SIDatasStanding1[:6000]).astype('float32')\n",
    "SIDataStanding2 = np.array(SIDatasStanding2[:6000]).astype('float32')\n",
    "SIDataStanding3 = np.array(SIDatasStanding3[:6000]).astype('float32')\n",
    "SIDataStanding4 = np.array(SIDatasStanding4[:6000]).astype('float32')\n",
    "SIDataStanding5 = np.array(SIDatasStanding5[:6000]).astype('float32')\n",
    "SIDataStanding6 = np.array(SIDatasStanding6[:6000]).astype('float32')\n",
    "SIDataStanding7 = np.array(SIDatasStanding7[:6000]).astype('float32')\n",
    "SIDataStanding8 = np.array(SIDatasStanding8[:6000]).astype('float32')\n",
    "SIDataStanding9 = np.array(SIDatasStanding9[:6000]).astype('float32')\n",
    "SIDataStanding10 = np.array(SIDatasStanding10[:6000]).astype('float32')\n",
    "SIDataStanding11 = np.array(SIDatasStanding11[:6000]).astype('float32')\n",
    "SIDataStanding12 = np.array(SIDatasStanding12[:6000]).astype('float32')\n",
    "SIDataStanding13 = np.array(SIDatasStanding13[:6000]).astype('float32')\n",
    "SIDataStanding14 = np.array(SIDatasStanding14[:6000]).astype('float32')\n",
    "SIDataStanding15 = np.array(SIDatasStanding15[:6000]).astype('float32')\n",
    "SIDataStanding16 = np.array(SIDatasStanding16[:6000]).astype('float32')\n",
    "SIDataStanding17 = np.array(SIDatasStanding17[:6000]).astype('float32')\n",
    "SIDataStanding18 = np.array(SIDatasStanding18[:6000]).astype('float32')\n",
    "SIDataStanding19 = np.array(SIDatasStanding19[:6000]).astype('float32')\n",
    "SIDataStanding20 = np.array(SIDatasStanding20[:6000]).astype('float32')\n",
    "SIDataStanding21 = np.array(SIDatasStanding21[:6000]).astype('float32')\n",
    "SIDataStanding22 = np.array(SIDatasStanding22[:6000]).astype('float32')\n",
    "FPDataStanding1 = np.array(FPDataStandings1).astype('float32')\n",
    "FPDataStanding2 = np.array(FPDataStandings2).astype('float32')\n",
    "FPDataStanding3= np.array(FPDataStandings3).astype('float32')\n",
    "FPDataStanding4= np.array(FPDataStandings4).astype('float32')\n",
    "FPDataStanding5= np.array(FPDataStandings5).astype('float32')\n",
    "FPDataStanding6= np.array(FPDataStandings6).astype('float32')\n",
    "FPDataStanding7= np.array(FPDataStandings7).astype('float32')\n",
    "FPDataStanding8= np.array(FPDataStandings8).astype('float32')\n",
    "FPDataStanding9= np.array(FPDataStandings9).astype('float32')\n",
    "FPDataStanding10 = np.array(FPDataStandings10).astype('float32')\n",
    "FPDataStanding11 = np.array(FPDataStandings11).astype('float32')\n",
    "FPDataStanding12= np.array(FPDataStandings12).astype('float32')\n",
    "FPDataStanding13= np.array(FPDataStandings13).astype('float32')\n",
    "FPDataStanding14= np.array(FPDataStandings14).astype('float32')\n",
    "FPDataStanding15= np.array(FPDataStandings15).astype('float32')\n",
    "FPDataStanding16= np.array(FPDataStandings16).astype('float32')\n",
    "FPDataStanding17= np.array(FPDataStandings17).astype('float32')\n",
    "FPDataStanding18= np.array(FPDataStandings18).astype('float32')\n",
    "FPDataStanding19= np.array(FPDataStandings19).astype('float32')\n",
    "FPDataStanding20= np.array(FPDataStandings20).astype('float32')\n",
    "FPDataStanding21= np.array(FPDataStandings21).astype('float32')\n",
    "FPDataStanding22= np.array(FPDataStandings22).astype('float32')\n",
    "\n",
    "SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3,\n",
    "                            SIDataStanding4, SIDataStanding5, SIDataStanding6,\n",
    "                            SIDataStanding7, SIDataStanding8, SIDataStanding9,\n",
    "                            SIDataStanding10, SIDataStanding11, SIDataStanding12,\n",
    "                            SIDataStanding13, SIDataStanding14, SIDataStanding15,\n",
    "                            SIDataStanding16, SIDataStanding17, SIDataStanding18,\n",
    "                            SIDataStanding19, SIDataStanding20, SIDataStanding21,\n",
    "                            SIDataStanding22), axis=0)\n",
    "\n",
    "# SIDatasetStanding = np.concatenate((SIDataStanding1, SIDataStanding2, SIDataStanding3), axis=0)\n",
    "# FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3), axis=0)\n",
    "                            \n",
    "FPDatasetStanding = np.concatenate((FPDataStanding1, FPDataStanding2, FPDataStanding3,\n",
    "                            FPDataStanding4, FPDataStanding5, FPDataStanding6,\n",
    "                            FPDataStanding7, FPDataStanding8, FPDataStanding9,\n",
    "                            FPDataStanding10, FPDataStanding11, FPDataStanding12,\n",
    "                            FPDataStanding13, FPDataStanding14, FPDataStanding15,\n",
    "                            FPDataStanding16, FPDataStanding17, FPDataStanding18,\n",
    "                            FPDataStanding19, FPDataStanding20, FPDataStanding21,\n",
    "                            FPDataStanding22), axis=0)\n",
    "\n",
    "# SIDatasetStanding = SIDataStanding1\n",
    "# FPDatasetStanding = FPDataStanding1\n",
    "\n",
    "SIDatasetStanding = np.array(SIDatasetStanding).astype('float32')\n",
    "FPDatasetStanding = np.array(FPDatasetStanding).astype('float32')\n",
    "\n",
    "# Concat Standing and Walking\n",
    "# SIDataset = np.concatenate((SIDatasetWalking,SIDatasetStanding), axis=0)\n",
    "# FPDataset = np.concatenate((FPDatasetWalking,FPDatasetStanding), axis=0)\n",
    "SIDataset = SIDatasetWalking\n",
    "FPDataset = FPDatasetWalking\n",
    "\n",
    "# SIDataset = SIDatasetStanding\n",
    "# FPDataset = FPDatasetStanding\n",
    "\n",
    "FXData = FPDataset[:,0]/10\n",
    "FXData =  np.array(FXData)\n",
    "FXData = FXData.reshape(-1,1)\n",
    "FYData = FPDataset[:,1]/5\n",
    "FYData =  np.array(FYData)\n",
    "FYData = FYData.reshape(-1,1)\n",
    "FZData = (FPDataset[:,2])/10\n",
    "FZData =  np.array(FZData)\n",
    "FZData = FZData.reshape(-1,1)\n",
    "MXData = (FPDataset[:,3])/1000\n",
    "MXData =  np.array(MXData)\n",
    "MXData = MXData.reshape(-1,1)\n",
    "MYData = (FPDataset[:,4])/10000\n",
    "MYData =  np.array(MYData)\n",
    "MYData = MYData.reshape(-1,1)\n",
    "MZData = (FPDataset[:,5])/100\n",
    "MZData =  np.array(MZData)\n",
    "MZData = MZData.reshape(-1,1)\n",
    "\n",
    "newFPDataset = np.concatenate((FXData, FYData, FZData, MXData, MYData, MZData), axis=1)\n",
    "newFPDataset = np.round(newFPDataset[:],2)\n",
    "## End Load Data\n",
    "\n",
    "wavelet = 'db4'\n",
    "\n",
    "SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(SIDataset[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "#     coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "    # coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "    # coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "    # coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "    # coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "SIData_filtered = np.zeros(SIDataset.shape)\n",
    "for i in range(89):\n",
    "    SIData_filtered[:, i] = pywt.waverec(SIDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "# max_iter = 50\n",
    "# iter = 0\n",
    "# for i in range(len(SIData_filtered)):\n",
    "#     SIData_filtered[i][0] = SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "#     iter += 1\n",
    "\n",
    "for i in range(len(SIDataset)):\n",
    "    if i < len(SIDatasetWalking):\n",
    "        SIData_filtered[i][0] = SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "        iter += 1\n",
    "    else:\n",
    "        SIData_filtered[i][0] = 0\n",
    "        # SIData_filtered[i][0] = i-314999\n",
    "\n",
    "for i in range(len(SIData_filtered)):\n",
    "    SIData_filtered[i][np.abs(SIData_filtered[i]) < 1] = 0\n",
    "\n",
    "# Data Normalization\n",
    "minInsole = SIData_filtered.min()\n",
    "maxInsole = SIData_filtered.max()\n",
    "xscale = (SIData_filtered - minInsole) / ( maxInsole - minInsole )\n",
    "\n",
    "FPmax = []\n",
    "FPmin = []\n",
    "yscale = []\n",
    "\n",
    "for i in range(0,6):\n",
    "    minFP = newFPDataset[:,i].min()\n",
    "    maxFP = newFPDataset[:,i].max()\n",
    "    FPmin.append(minFP)\n",
    "    FPmax.append(maxFP)\n",
    "\n",
    "FPmin = np.array(FPmin)\n",
    "FPmax = np.array(FPmax)\n",
    "\n",
    "for i in range(0,6):\n",
    "  scale = (newFPDataset[:,i] - FPmin[i]) / ( FPmax[i] - FPmin[i] )\n",
    "  yscale.append(scale)\n",
    "yscale = np.array(yscale)\n",
    "yscale = yscale.transpose()\n",
    "#End Data Normalization\n",
    "\n",
    "#Spliting Data\n",
    "sample_size = xscale.shape[0] # number of samples in train set\n",
    "time_steps  = xscale.shape[1] # number of features in train set\n",
    "input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "train_data_reshaped = xscale.reshape(sample_size,time_steps,input_dimension)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_reshaped, yscale, test_size=0.20, random_state=2)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n",
    "#End Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VzoiWHFxvYWl",
    "outputId": "e7d62376-729c-4c50-a90b-eede7cd8290f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  63.,\n",
       "       124.,   0.,   0.,  31.,   0.,   0.,   0.,   0.,   0.,   0.,  77.,\n",
       "        71.,   0.,   0.,   0.,   0.,   0.,   6.,  69., 129., 100.,  15.,\n",
       "       101.,   0.,   0.,   0.,   0.,   0.,   0., 110., 103.,   0.,   0.,\n",
       "         0.,   0.,   0.,   3.,  60., 126.,  84.,   0.,   0.,   3.,   0.,\n",
       "         0.,   0.,   0., 112.,  82.,   0.,   0.,  18.,  42.,  56.,  92.,\n",
       "        67., 123.,  86.,   0.,  79.,  50.,   0.,   0.,  89., 111.,  86.,\n",
       "       126.,  12.,   6.,  10.,   0.,   0.,  88.,  40.,   0.,   0.,   0.,\n",
       "         0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIDataset[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z42vOnjv_1cE",
    "outputId": "3ad41fd3-be4f-4ed8-da7b-3605e519d555"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03,  0.38, -2.17, -1.97, -0.36, -8.15], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newFPDataset[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PHpFKkVyj0I"
   },
   "source": [
    "### Build and Train Imported Data using the ResNet based Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6IOf_sFx5Dm"
   },
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tFqNbe_vch4u"
   },
   "outputs": [],
   "source": [
    "\"Configurations for ResNet in Regression Mode\"\n",
    "length = X_train.shape[1]   # Number of Features (or length of the signal)\n",
    "model_width = 64           # Number of Filter or Kernel in the Input Layer\n",
    "num_channel = 1             # Number of Input Channels\n",
    "problem_type = 'Regression' # Regression or Classification\n",
    "output_number = 6           # Number of Outputs in the Regression Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1L543Qc_x7AB"
   },
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nq-4BfWjcSHf"
   },
   "outputs": [],
   "source": [
    "class AdamW(Adam):\n",
    "    def __init__(self, learning_rate=0.0001, weight_decay=0.01, **kwargs):\n",
    "        super(AdamW, self).__init__(learning_rate, **kwargs)\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def get_gradients(self, loss, params):\n",
    "        gradients = super(AdamW, self).get_gradients(loss, params)\n",
    "        if self.weight_decay > 0.0:\n",
    "            for i in range(len(gradients)):\n",
    "                if gradients[i] is not None:\n",
    "                    gradients[i] += self.weight_decay * params[i]\n",
    "        return gradients\n",
    "\n",
    "Regression_Model = ResNet(length, num_channel, model_width, problem_type=problem_type, output_nums=output_number).ResNet18() # Build Model\n",
    "# ResNet Models supported: ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, \n",
    "Regression_Model.compile(loss='mse', optimizer=AdamW(learning_rate=0.0001, weight_decay=0.01), metrics= ['mse']) # Compile Model\n",
    "# Here, Model validation metric is set as Mean Squared Error or MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nu7h2qmWx-Jg"
   },
   "source": [
    "Model_Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLz469jDhJWx",
    "outputId": "02cb590d-f078-4069-99e0-bd5e8765305f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 89, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 45, 64)       512         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 45, 64)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 22, 64)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 22, 64)       12352       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 22, 64)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 22, 64)       12352       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 22, 64)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 22, 64)       0           ['activation_2[0][0]',           \n",
      "                                                                  'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 22, 64)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 22, 64)       12352       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 22, 64)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 22, 64)       12352       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 22, 64)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 22, 64)       0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 22, 64)       0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 11, 128)      24704       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 11, 128)      0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 11, 128)      49280       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 11, 128)      0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 11, 128)      49280       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 11, 128)      0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 11, 128)      49280       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 11, 128)      0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 11, 128)      0           ['activation_10[0][0]',          \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 11, 128)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 6, 256)       98560       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 6, 256)       0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 6, 256)       196864      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 6, 256)       0           ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 6, 256)       196864      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 6, 256)       0           ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 6, 256)       196864      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 6, 256)       0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 6, 256)       0           ['activation_15[0][0]',          \n",
      "                                                                  'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 6, 256)       0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 3, 512)       393728      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 3, 512)       0           ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_14 (Conv1D)             (None, 3, 512)       786944      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 3, 512)       0           ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 3, 512)       786944      ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 3, 512)       0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 3, 512)       786944      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 3, 512)       0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 3, 512)       0           ['activation_20[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 3, 512)       0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['activation_21[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            3078        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,669,254\n",
      "Trainable params: 3,669,254\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Regression_Model.summary() # Summary of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vHdlpJFx_14"
   },
   "source": [
    "Upload Past Weights if available (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SSW2BfUMqs7A"
   },
   "outputs": [],
   "source": [
    "# Regression_Model.load_weights('Saved_Model.h5') # Load Previously Trained Weights for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSicHIFzyCky"
   },
   "source": [
    "Train Model for 'n' number of Epochs with Batch size of 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuaVIjBviw7n",
    "outputId": "ede225a1-4e02-4b38-977a-a6dfb4c5ba4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1721/13200 [==>...........................] - ETA: 1:43 - loss: 0.0129 - mse: 0.0129"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Early Stopping and Model_Checkpoints are optional parameters\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Early Stopping is to stop the training based on certain condition set by the user\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Model Checkpoint is to save a model in a directory based on certain conditions so that it can be used later for Transfer Learning or avoiding retraining\u001b[39;00m\n\u001b[0;32m      4\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m), ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaved_Model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mRegression_Model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Save 'History' of the model for model performance analysis performed later\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jakss_TF_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jakss_TF_GPU\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jakss_TF_GPU\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jakss_TF_GPU\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jakss_TF_GPU\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jakss_TF_GPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jakss_TF_GPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jakss_TF_GPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jakss_TF_GPU\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Early Stopping and Model_Checkpoints are optional parameters\n",
    "# Early Stopping is to stop the training based on certain condition set by the user\n",
    "# Model Checkpoint is to save a model in a directory based on certain conditions so that it can be used later for Transfer Learning or avoiding retraining\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=50, mode='min'), ModelCheckpoint('Saved_Model.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
    "history = Regression_Model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1, validation_split=0.2, shuffle=True, callbacks=callbacks)\n",
    "# Save 'History' of the model for model performance analysis performed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3ydNmIKFJqv"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.keras.models.save_model(Regression_Model, 'Resnet50_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rejbOtGN-ixL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rTwvEAos2fB"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Evaluate Model\n",
    "Regression_Model.evaluate(train_data_reshaped, yscale)\n",
    "ypred = Regression_Model.predict(train_data_reshaped)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.show()\n",
    "plt.savefig('Loss Result.png')\n",
    "\n",
    "print('MSE: ',mean_squared_error(yscale, ypred))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(yscale, ypred)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(yscale, ypred))\n",
    "\n",
    "\n",
    "#Inverse\n",
    "y_inverse = []\n",
    "y_pred_inverse = []\n",
    "\n",
    "for i in range(0,6):\n",
    "  Y_inver =  yscale[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Pred_inver = ypred[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  y_inverse.append(Y_inver)\n",
    "  y_pred_inverse.append(Pred_inver)\n",
    "y_inverse = np.array(y_inverse)\n",
    "y_inverse = y_inverse.transpose()\n",
    "y_pred_inverse = np.array(y_pred_inverse)\n",
    "y_pred_inverse = y_pred_inverse.transpose()\n",
    "\n",
    "for i in range(len(y_pred_inverse)):\n",
    "    if (np.abs(y_pred_inverse[i]) < 1).all():\n",
    "        y_pred_inverse[i] = 0\n",
    "\n",
    "for i in range(0, y_pred_inverse.shape[0], 50):\n",
    "    zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "    non_zero_rows = np.count_nonzero(y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "    if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "        y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "print('MSE: ',mean_squared_error(y_inverse, y_pred_inverse))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(y_inverse, y_pred_inverse)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(y_inverse, y_pred_inverse))\n",
    "\n",
    "y_inverse = np.round(y_inverse[:],2)\n",
    "y_pred_inverse = np.round(y_pred_inverse[:],2)\n",
    "\n",
    "# restore to original Data\n",
    "FXData2 = y_inverse[:,0]*10\n",
    "FXData2=  np.array(FXData2)\n",
    "FXData2 = FXData2.reshape(-1,1)\n",
    "\n",
    "FYData2 = y_inverse[:,1]*5\n",
    "FYData2 =  np.array(FYData2)\n",
    "FYData2 = FYData2.reshape(-1,1)\n",
    "\n",
    "FZData2 = (y_inverse[:,2]*10)\n",
    "FZData2 =  np.array(FZData2)\n",
    "FZData2 = FZData2.reshape(-1,1)\n",
    "\n",
    "MXData2 = (y_inverse[:,3]*1000)\n",
    "MXData2 =  np.array(MXData2)\n",
    "MXData2 = MXData2.reshape(-1,1)\n",
    "\n",
    "MYData2 = (y_inverse[:,4]*10000)\n",
    "MYData2 =  np.array(MYData2)\n",
    "MYData2 = MYData2.reshape(-1,1\n",
    "                          )\n",
    "MZData2 = (y_inverse[:,5]*100)\n",
    "MZData2 =  np.array(MZData2)\n",
    "MZData2 = MZData2.reshape(-1,1)\n",
    "\n",
    "new_inverse2 = np.concatenate((FXData2, FYData2, FZData2, MXData2, MYData2, MZData2), axis=1)\n",
    "\n",
    "FXData3 = y_pred_inverse[:,0]*10\n",
    "FXData3=  np.array(FXData3)\n",
    "FXData3 = FXData3.reshape(-1,1)\n",
    "\n",
    "FYData3 = y_pred_inverse[:,1]*5\n",
    "FYData3 =  np.array(FYData3)\n",
    "FYData3 = FYData3.reshape(-1,1)\n",
    "\n",
    "FZData3 = (y_pred_inverse[:,2]*10)\n",
    "FZData3 =  np.array(FZData3)\n",
    "FZData3 = FZData3.reshape(-1,1)\n",
    "\n",
    "MXData3 = (y_pred_inverse[:,3]*1000)\n",
    "MXData3 =  np.array(MXData3)\n",
    "MXData3 = MXData3.reshape(-1,1)\n",
    "\n",
    "MYData3 = (y_pred_inverse[:,4]*10000)\n",
    "MYData3 =  np.array(MYData3)\n",
    "MYData3 = MYData3.reshape(-1,1)\n",
    "\n",
    "MZData3 = (y_pred_inverse[:,5]*100)\n",
    "MZData3 =  np.array(MZData3)\n",
    "MZData3 = MZData3.reshape(-1,1)\n",
    "\n",
    "new_inverse3 = np.concatenate((FXData3, FYData3, FZData3, MXData3, MYData3, MZData3), axis=1)\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('CNN Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Real value', 'Predicted Value'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "out_Fz = new_inverse2[:,2]\n",
    "out_Mx = new_inverse2[:,3]\n",
    "out_My = new_inverse2[:,4]\n",
    "Pred_Fz = new_inverse3[:,2]\n",
    "Pred_Mx = new_inverse3[:,3]\n",
    "Pred_My = new_inverse3[:,4]\n",
    "\n",
    "Pred_COPx=[]\n",
    "for i in range(0,len(Pred_Fz)):\n",
    "  Pred_COPx_temp=-(Pred_My[i])/Pred_Fz[i]\n",
    "  # print(temp)\n",
    "  if Pred_COPx_temp != Pred_COPx_temp:\n",
    "    Pred_COPx_temp=0\n",
    "  Pred_COPx.append(Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "out_COPx=[]\n",
    "for i in range(0,len(out_Fz)):\n",
    "  out_COPx_temp=-(out_My[i])/out_Fz[i]\n",
    "  # print(temp)\n",
    "  if out_COPx_temp != out_COPx_temp:\n",
    "    out_COPx_temp=0\n",
    "  out_COPx.append(out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Pred_COPy=[]\n",
    "for i in range(0,len(Pred_Mx)):\n",
    "  Pred_COPy_temp=Pred_Mx[i]/Pred_Fz[i]\n",
    "  # print(temp)\n",
    "  if Pred_COPy_temp != Pred_COPy_temp:\n",
    "    Pred_COPy_temp=0\n",
    "  Pred_COPy.append(Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "out_COPy=[]\n",
    "for i in range(0,len(out_Mx)):\n",
    "  out_COPy_temp=out_Mx[i]/out_Fz[i]\n",
    "  # print(temp)\n",
    "  if out_COPy_temp != out_COPy_temp:\n",
    "    out_COPy_temp=0\n",
    "  out_COPy.append(out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "# out_COPx = -(out_My)/out_Fz\n",
    "out_COPx = np.array(out_COPx)\n",
    "out_COPx= out_COPx.reshape(-1,1)\n",
    "\n",
    "# out_COPy = out_Mx/out_Fz\n",
    "out_COPy = np.array(out_COPy)\n",
    "out_COPy= out_COPy.reshape(-1,1)\n",
    "\n",
    "# Pred_COPx = -(Pred_My)/Pred_Fz\n",
    "Pred_COPx = np.array(Pred_COPx)\n",
    "Pred_COPx= Pred_COPx.reshape(-1,1)\n",
    "\n",
    "# Pred_COPy = Pred_Mx/Pred_Fz\n",
    "Pred_COPy = np.array(Pred_COPy)\n",
    "Pred_COPy= Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Pred_COP = np.concatenate((Pred_COPx, Pred_COPy), axis=1)\n",
    "FC_COP = np.concatenate((out_COPx, out_COPy), axis=1)\n",
    "\n",
    "col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000 \n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Training Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "y1 = FC_COP[50:100,0]\n",
    "y2 = FC_COP[50:100,1]\n",
    "y3 = Pred_COP[50:100,0]\n",
    "y4 = Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "data_filter = abs(y1) > 0\n",
    "data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1[data_filter], y2[data_filter ], color='red', alpha=0.3)\n",
    "pyplot.plot(y3[data_filter2], y4[data_filter2 ], color='green')\n",
    "# pyplot.plot(y1, y2, color='red')\n",
    "# pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHhYv7LpNRTb"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[0:100,0]\n",
    "y2 = FC_COP[0:100,1]\n",
    "y3 = Pred_COP[0:100,0]\n",
    "y4 = Pred_COP[0:100,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3fg6ZDwNNLd"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[100:200,0]\n",
    "y2 = FC_COP[100:200,1]\n",
    "y3 = Pred_COP[100:200,0]\n",
    "y4 = Pred_COP[100:200,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qxieSZKNVlT"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y1 = FC_COP[200:300,0]\n",
    "y2 = FC_COP[200:300,1]\n",
    "y3 = Pred_COP[200:300,0]\n",
    "y4 = Pred_COP[200:300,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(y1, y2, color='red')\n",
    "pyplot.plot(y3, y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Axx3FDcMsYAm"
   },
   "outputs": [],
   "source": [
    "new_inverse2[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlZwHomDsZ5R"
   },
   "outputs": [],
   "source": [
    "new_inverse3[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8Cnd-RuHso4"
   },
   "outputs": [],
   "source": [
    "new_inverse2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4I2lr9yfHuJA"
   },
   "outputs": [],
   "source": [
    "new_inverse3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oa_UQq_v1atq"
   },
   "outputs": [],
   "source": [
    "y_inverse[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsSpiSOY1dQ-"
   },
   "outputs": [],
   "source": [
    "y_pred_inverse[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw0HsDDtyEuv"
   },
   "source": [
    "Test and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_ov3Oh5nUx0"
   },
   "outputs": [],
   "source": [
    "## Model Validation\n",
    "Test_Insole = pd.read_csv('0310AyuRWalk2Min.txt', header=None, low_memory=False)\n",
    "TestSIData =  np.asarray(Test_Insole)\n",
    "\n",
    "Test_df = pd.read_csv('0310AyuRWalk2Min.csv', low_memory=False)\n",
    "Test_columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "Test_selected_df = Test_df[Test_columns]\n",
    "Test_FPDatas = Test_selected_df[:6000]\n",
    "\n",
    "\n",
    "test_SmartInsole = np.array(TestSIData[:6000]).astype('float32')\n",
    "Test_FPData = np.array(Test_FPDatas).astype('float32')\n",
    "\n",
    "Test_FXData = Test_FPData[:,0]/10\n",
    "Test_FXData =  np.array(Test_FXData)\n",
    "Test_FXData = Test_FXData.reshape(-1,1)\n",
    "Test_FYData = Test_FPData[:,1]/5\n",
    "Test_FYData =  np.array(Test_FYData)\n",
    "Test_FYData = Test_FYData.reshape(-1,1)\n",
    "Test_FZData = (Test_FPData[:,2])/10\n",
    "Test_FZData =  np.array(Test_FZData)\n",
    "Test_FZData = Test_FZData.reshape(-1,1)\n",
    "Test_MXData = (Test_FPData[:,3])/1000\n",
    "Test_MXData =  np.array(Test_MXData)\n",
    "Test_MXData = Test_MXData.reshape(-1,1)\n",
    "Test_MYData = (Test_FPData[:,4])/10000\n",
    "Test_MYData =  np.array(Test_MYData)\n",
    "Test_MYData =Test_MYData.reshape(-1,1)\n",
    "Test_MZData = (Test_FPData[:,5])/100\n",
    "Test_MZData =  np.array(Test_MZData)\n",
    "Test_MZData = Test_MZData.reshape(-1,1)\n",
    "\n",
    "Test_newFPData = np.concatenate((Test_FXData, Test_FYData, Test_FZData, Test_MXData, Test_MYData, Test_MZData), axis=1)\n",
    "Test_newFPData = np.round(Test_newFPData,2)\n",
    "## End Load Data\n",
    "\n",
    "Test_SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(test_SmartInsole[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    # coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "    # coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "    # coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "    # coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "    # coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    # coeffs[-7] = np.zeros_like(coeffs[-7])\n",
    "    Test_SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_SIData_filtered = np.zeros(test_SmartInsole.shape)\n",
    "for i in range(89):\n",
    "    Test_SIData_filtered[:, i] = pywt.waverec(Test_SIDWTcoeffs[i], 'db4', mode='symmetric', axis=0)\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    if i < len(Test_SIData_filtered):\n",
    "#         Test_SIData_filtered[i][0] = 0\n",
    "        Test_SIData_filtered[i][0] = Test_SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "        iter += 1\n",
    "    else:\n",
    "        Test_SIData_filtered[i][0] = 0\n",
    "\n",
    "# for i in range(len(Test_SIData_filtered)):\n",
    "#     Test_SIData_filtered[i][0] = i-1\n",
    "#     iter += 1\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    Test_SIData_filtered[i][np.abs(Test_SIData_filtered[i]) < 1] = 0\n",
    "\n",
    "Test_xscale = (Test_SIData_filtered - minInsole) / ( maxInsole - minInsole )\n",
    "\n",
    "Test_yscale = []\n",
    "for i in range(0,6):\n",
    "  Test_scale = (Test_newFPData[:,i] - FPmin[i]) / ( FPmax[i] - FPmin[i] )\n",
    "  Test_yscale.append(Test_scale)\n",
    "Test_yscale = np.array(Test_yscale)\n",
    "Test_yscale = Test_yscale.transpose()\n",
    "\n",
    "test_sample_size = Test_xscale.shape[0] # number of samples in train set\n",
    "test_time_steps  = Test_xscale.shape[1] # number of features in train set\n",
    "test_input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "test_train_data_reshaped = Test_xscale.reshape(test_sample_size,test_time_steps,test_input_dimension)\n",
    "\n",
    "Regression_Model.evaluate(test_train_data_reshaped, Test_yscale)\n",
    "Test_xX_model = Regression_Model.predict(test_train_data_reshaped)\n",
    "\n",
    "#invert normalize\n",
    "Test_y_inverse = []\n",
    "Test_y_pred_inverse = []\n",
    "\n",
    "for i in range(0,6):\n",
    "  Test_Y_inver =  Test_yscale[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_Pred_inver = Test_xX_model[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_y_inverse.append(Test_Y_inver)\n",
    "  Test_y_pred_inverse.append(Test_Pred_inver)\n",
    "Test_y_inverse = np.array(Test_y_inverse)\n",
    "Test_y_inverse = Test_y_inverse.transpose()\n",
    "Test_y_pred_inverse = np.array(Test_y_pred_inverse)\n",
    "Test_y_pred_inverse = Test_y_pred_inverse.transpose()\n",
    "\n",
    "for i in range(len(Test_y_pred_inverse)):\n",
    "    if (np.abs(Test_y_pred_inverse[i]) < 1).all():\n",
    "        Test_y_pred_inverse[i] = 0\n",
    "\n",
    "for i in range(0, Test_y_pred_inverse.shape[0], 50):\n",
    "    zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "    non_zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "    if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "        Test_y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "# make to original Data\n",
    "Test_FXData2 = Test_y_inverse[:,0]*10\n",
    "Test_FXData2=  np.array(Test_FXData2)\n",
    "Test_FXData2 = Test_FXData2.reshape(-1,1)\n",
    "\n",
    "Test_FYData2 = Test_y_inverse[:,1]*5\n",
    "Test_FYData2 =  np.array(Test_FYData2)\n",
    "Test_FYData2 = Test_FYData2.reshape(-1,1)\n",
    "\n",
    "Test_FZData2 = (Test_y_inverse[:,2]*10)\n",
    "Test_FZData2 =  np.array(Test_FZData2)\n",
    "Test_FZData2 = Test_FZData2.reshape(-1,1)\n",
    "\n",
    "Test_MXData2 = (Test_y_inverse[:,3]*1000)\n",
    "Test_MXData2 =  np.array(Test_MXData2)\n",
    "Test_MXData2 = Test_MXData2.reshape(-1,1)\n",
    "\n",
    "Test_MYData2 = (Test_y_inverse[:,4]*10000)\n",
    "Test_MYData2 =  np.array(Test_MYData2)\n",
    "Test_MYData2 = Test_MYData2.reshape(-1,1\n",
    "                          )\n",
    "Test_MZData2 = (Test_y_inverse[:,5]*100)\n",
    "Test_MZData2 =  np.array(Test_MZData2)\n",
    "Test_MZData2 = Test_MZData2.reshape(-1,1)\n",
    "\n",
    "\n",
    "Test_new_inverse2 = np.concatenate((Test_FXData2, Test_FYData2, Test_FZData2, Test_MXData2, Test_MYData2, Test_MZData2), axis=1)\n",
    "\n",
    "Test_FXData3 = Test_y_pred_inverse[:,0]*10\n",
    "Test_FXData3=  np.array(Test_FXData3)\n",
    "Test_FXData3 = Test_FXData3.reshape(-1,1)\n",
    "\n",
    "Test_FYData3 = Test_y_pred_inverse[:,1]*5\n",
    "Test_FYData3 =  np.array(Test_FYData3)\n",
    "Test_FYData3 = Test_FYData3.reshape(-1,1)\n",
    "\n",
    "Test_FZData3 = (Test_y_pred_inverse[:,2]*10)\n",
    "Test_FZData3 =  np.array(Test_FZData3)\n",
    "Test_FZData3 = Test_FZData3.reshape(-1,1)\n",
    "\n",
    "Test_MXData3 = (Test_y_pred_inverse[:,3]*1000)\n",
    "Test_MXData3 =  np.array(Test_MXData3)\n",
    "Test_MXData3 = Test_MXData3.reshape(-1,1)\n",
    "\n",
    "Test_MYData3 = (Test_y_pred_inverse[:,4]*10000)\n",
    "Test_MYData3 =  np.array(Test_MYData3)\n",
    "Test_MYData3 = Test_MYData3.reshape(-1,1)\n",
    "\n",
    "Test_MZData3 = (Test_y_pred_inverse[:,5]*100)\n",
    "Test_MZData3 =  np.array(Test_MZData3)\n",
    "Test_MZData3 = Test_MZData3.reshape(-1,1)\n",
    "\n",
    "Test_new_inverse3 = np.concatenate((Test_FXData3, Test_FYData3, Test_FZData3, Test_MXData3, Test_MYData3, Test_MZData3), axis=1)\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('CNN Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "Test_out_Fz = Test_new_inverse2[:,2]\n",
    "Test_out_Mx = Test_new_inverse2[:,3]\n",
    "Test_out_My = Test_new_inverse2[:,4]\n",
    "Test_Pred_Fz = Test_new_inverse3[:,2]\n",
    "Test_Pred_Mx = Test_new_inverse3[:,3]\n",
    "Test_Pred_My = Test_new_inverse3[:,4]\n",
    "\n",
    "Test_Pred_COPx=[]\n",
    "for i in range(0,len(Test_Pred_Fz)):\n",
    "  Test_Pred_COPx_temp=-(Test_Pred_My[i])/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPx_temp != Test_Pred_COPx_temp:\n",
    "    Test_Pred_COPx_temp=0\n",
    "  Test_Pred_COPx.append(Test_Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPx=[]\n",
    "for i in range(0,len(Test_out_Fz)):\n",
    "  Test_out_COPx_temp=-(Test_out_My[i])/Test_out_Fz[i]\n",
    "  if Test_out_COPx_temp != Test_out_COPx_temp:\n",
    "    Test_out_COPx_temp=0\n",
    "  Test_out_COPx.append(Test_out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_Pred_COPy=[]\n",
    "for i in range(0,len(Test_Pred_Mx)):\n",
    "  Test_Pred_COPy_temp=Test_Pred_Mx[i]/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPy_temp != Test_Pred_COPy_temp:\n",
    "    Test_Pred_COPy_temp=0\n",
    "  Test_Pred_COPy.append(Test_Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPy=[]\n",
    "for i in range(0,len(Test_out_Mx)):\n",
    "  Test_out_COPy_temp=Test_out_Mx[i]/Test_out_Fz[i]\n",
    "  if Test_out_COPy_temp != Test_out_COPy_temp:\n",
    "    Test_out_COPy_temp=0\n",
    "  Test_out_COPy.append(Test_out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "Test_out_COPx = np.array(Test_out_COPx)\n",
    "Test_out_COPx= Test_out_COPx.reshape(-1,1)\n",
    "\n",
    "Test_out_COPy = np.array(Test_out_COPy)\n",
    "Test_out_COPy= Test_out_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPx = np.array(Test_Pred_COPx)\n",
    "Test_Pred_COPx= Test_Pred_COPx.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPy = np.array(Test_Pred_COPy)\n",
    "Test_Pred_COPy= Test_Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COP = np.concatenate((Test_Pred_COPx, Test_Pred_COPy), axis=1)\n",
    "Test_FC_COP = np.concatenate((Test_out_COPx, Test_out_COPy), axis=1)\n",
    "\n",
    "Test_col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000 \n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,Test_FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Test_Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Testing Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "Test_y1 = Test_FC_COP[50:100,0]\n",
    "Test_y2 = Test_FC_COP[50:100,1]\n",
    "Test_y3 = Test_Pred_COP[50:100,0]\n",
    "Test_y4 = Test_Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "# Test_data_filter = abs(y1) > 0\n",
    "# Test_data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(Test_y1[Test_data_filter], Test_y2[Test_data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(Test_y3[Test_data_filter2], Test_y4[Test_data_filter2 ], color='green')\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Testing Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7qd6uS3OBZs"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[0:100,0]\n",
    "Test_y2 = Test_FC_COP[0:100,1]\n",
    "Test_y3 = Test_Pred_COP[0:100,0]\n",
    "Test_y4 = Test_Pred_COP[0:100,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-fQqEiDOEDM"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[100:200,0]\n",
    "Test_y2 = Test_FC_COP[100:200,1]\n",
    "Test_y3 = Test_Pred_COP[100:200,0]\n",
    "Test_y4 = Test_Pred_COP[100:200,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Isay2TbVOG6F"
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "Test_y1 = Test_FC_COP[200:300,0]\n",
    "Test_y2 = Test_FC_COP[200:300,1]\n",
    "Test_y3 = Test_Pred_COP[200:300,0]\n",
    "Test_y4 = Test_Pred_COP[200:300,1]\n",
    "\n",
    "pyplot.figure(figsize=(15,6))\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Training Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlIfrOihUGt7"
   },
   "outputs": [],
   "source": [
    "## Model Validation\n",
    "Test_Insole = pd.read_csv('0312AryaStand5Min2.txt', header=None, low_memory=False)\n",
    "TestSIData =  np.asarray(Test_Insole)\n",
    "\n",
    "Test_df = pd.read_csv('0312AryaStand5Min2.csv', low_memory=False)\n",
    "Test_columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "Test_selected_df = Test_df[Test_columns]\n",
    "Test_FPDatas = Test_selected_df[:6000]\n",
    "\n",
    "\n",
    "test_SmartInsole = np.array(TestSIData[:6000]).astype('float64')\n",
    "Test_FPData = np.array(Test_FPDatas).astype('float64')\n",
    "\n",
    "Test_FXData = Test_FPData[:,0]/10\n",
    "Test_FXData =  np.array(Test_FXData)\n",
    "Test_FXData = Test_FXData.reshape(-1,1)\n",
    "Test_FYData = Test_FPData[:,1]/5\n",
    "Test_FYData =  np.array(Test_FYData)\n",
    "Test_FYData = Test_FYData.reshape(-1,1)\n",
    "Test_FZData = (Test_FPData[:,2])/10\n",
    "Test_FZData =  np.array(Test_FZData)\n",
    "Test_FZData = Test_FZData.reshape(-1,1)\n",
    "Test_MXData = (Test_FPData[:,3])/1000\n",
    "Test_MXData =  np.array(Test_MXData)\n",
    "Test_MXData = Test_MXData.reshape(-1,1)\n",
    "Test_MYData = (Test_FPData[:,4])/10000\n",
    "Test_MYData =  np.array(Test_MYData)\n",
    "Test_MYData =Test_MYData.reshape(-1,1)\n",
    "Test_MZData = (Test_FPData[:,5])/100\n",
    "Test_MZData =  np.array(Test_MZData)\n",
    "Test_MZData = Test_MZData.reshape(-1,1)\n",
    "\n",
    "Test_newFPData = np.concatenate((Test_FXData, Test_FYData, Test_FZData, Test_MXData, Test_MYData, Test_MZData), axis=1)\n",
    "## End Load Data\n",
    "Test_newFPData = abs(Test_newFPData)\n",
    "\n",
    "Test_SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(test_SmartInsole[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    # coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "    # coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "    # coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "    # coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "    # coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    # coeffs[-7] = np.zeros_like(coeffs[-7])\n",
    "    Test_SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_SIData_filtered = np.zeros(test_SmartInsole.shape)\n",
    "for i in range(89):\n",
    "    Test_SIData_filtered[:, i] = pywt.waverec(Test_SIDWTcoeffs[i], 'db4', mode='symmetric', axis=0)\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    if i < len(Test_SIData_filtered):\n",
    "        Test_SIData_filtered[i][0] = 0\n",
    "        # Test_SIData_filtered[i][0] = Test_SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "        iter += 1\n",
    "    else:\n",
    "        Test_SIData_filtered[i][0] = 0\n",
    "\n",
    "# for i in range(len(Test_SIData_filtered)):\n",
    "#     Test_SIData_filtered[i][0] = i-1\n",
    "#     iter += 1\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    Test_SIData_filtered[i][np.abs(Test_SIData_filtered[i]) < 1] = 0\n",
    "\n",
    "Test_xscale = (Test_SIData_filtered - minInsole) / ( maxInsole - minInsole )\n",
    "\n",
    "Test_yscale = []\n",
    "for i in range(0,6):\n",
    "  Test_scale = (Test_newFPData[:,i] - FPmin[i]) / ( FPmax[i] - FPmin[i] )\n",
    "  Test_yscale.append(Test_scale)\n",
    "Test_yscale = np.array(Test_yscale)\n",
    "Test_yscale = Test_yscale.transpose()\n",
    "\n",
    "test_sample_size = Test_xscale.shape[0] # number of samples in train set\n",
    "test_time_steps  = Test_xscale.shape[1] # number of features in train set\n",
    "test_input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "test_train_data_reshaped = Test_xscale.reshape(test_sample_size,test_time_steps,test_input_dimension)\n",
    "\n",
    "Regression_Model.evaluate(test_train_data_reshaped, Test_yscale)\n",
    "Test_xX_model = Regression_Model.predict(test_train_data_reshaped)\n",
    "\n",
    "#invert normalize\n",
    "Test_y_inverse = []\n",
    "Test_y_pred_inverse = []\n",
    "\n",
    "for i in range(0,6):\n",
    "  Test_Y_inver =  Test_yscale[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_Pred_inver = Test_xX_model[:, i]*( FPmax[i] - FPmin[i] )+FPmin[i]\n",
    "  Test_y_inverse.append(Test_Y_inver)\n",
    "  Test_y_pred_inverse.append(Test_Pred_inver)\n",
    "Test_y_inverse = np.array(Test_y_inverse)\n",
    "Test_y_inverse = Test_y_inverse.transpose()\n",
    "Test_y_pred_inverse = np.array(Test_y_pred_inverse)\n",
    "Test_y_pred_inverse = Test_y_pred_inverse.transpose()\n",
    "\n",
    "for i in range(len(Test_y_pred_inverse)):\n",
    "    if (np.abs(Test_y_pred_inverse[i]) < 1).all():\n",
    "        Test_y_pred_inverse[i] = 0\n",
    "\n",
    "for i in range(0, Test_y_pred_inverse.shape[0], 50):\n",
    "    zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) == 0\n",
    "    non_zero_rows = np.count_nonzero(Test_y_pred_inverse[i:i+50, :], axis=1) > 0\n",
    "    if np.sum(zero_rows) > np.sum(non_zero_rows):\n",
    "        Test_y_pred_inverse[i:i+50, :][non_zero_rows] = 0.0\n",
    "\n",
    "# make to original Data\n",
    "Test_FXData2 = Test_y_inverse[:,0]*10\n",
    "Test_FXData2=  np.array(Test_FXData2)\n",
    "Test_FXData2 = Test_FXData2.reshape(-1,1)\n",
    "\n",
    "Test_FYData2 = Test_y_inverse[:,1]*10\n",
    "Test_FYData2 =  np.array(Test_FYData2)\n",
    "Test_FYData2 = Test_FYData2.reshape(-1,1)\n",
    "\n",
    "Test_FZData2 = (Test_y_inverse[:,2]*10)\n",
    "Test_FZData2 =  np.array(Test_FZData2)\n",
    "Test_FZData2 = Test_FZData2.reshape(-1,1)\n",
    "\n",
    "Test_MXData2 = (Test_y_inverse[:,3]*1000)\n",
    "Test_MXData2 =  np.array(Test_MXData2)\n",
    "Test_MXData2 = Test_MXData2.reshape(-1,1)\n",
    "\n",
    "Test_MYData2 = (Test_y_inverse[:,4]*10000)\n",
    "Test_MYData2 =  np.array(Test_MYData2)\n",
    "Test_MYData2 = Test_MYData2.reshape(-1,1\n",
    "                          )\n",
    "Test_MZData2 = (Test_y_inverse[:,5]*100)\n",
    "Test_MZData2 =  np.array(Test_MZData2)\n",
    "Test_MZData2 = Test_MZData2.reshape(-1,1)\n",
    "\n",
    "Test_new_inverse2 = np.concatenate((Test_FXData2, Test_FYData2, Test_FZData2, Test_MXData2, Test_MYData2, Test_MZData2), axis=1)\n",
    "\n",
    "Test_FXData3 = Test_y_pred_inverse[:,0]*10\n",
    "Test_FXData3=  np.array(Test_FXData3)\n",
    "Test_FXData3 = Test_FXData3.reshape(-1,1)\n",
    "\n",
    "Test_FYData3 = Test_y_pred_inverse[:,1]*10\n",
    "Test_FYData3 =  np.array(Test_FYData3)\n",
    "Test_FYData3 = Test_FYData3.reshape(-1,1)\n",
    "\n",
    "Test_FZData3 = (Test_y_pred_inverse[:,2]*10)\n",
    "Test_FZData3 =  np.array(Test_FZData3)\n",
    "Test_FZData3 = Test_FZData3.reshape(-1,1)\n",
    "\n",
    "Test_MXData3 = (Test_y_pred_inverse[:,3]*1000)\n",
    "Test_MXData3 =  np.array(Test_MXData3)\n",
    "Test_MXData3 = Test_MXData3.reshape(-1,1)\n",
    "\n",
    "Test_MYData3 = (Test_y_pred_inverse[:,4]*10000)\n",
    "Test_MYData3 =  np.array(Test_MYData3)\n",
    "Test_MYData3 = Test_MYData3.reshape(-1,1)\n",
    "\n",
    "Test_MZData3 = (Test_y_pred_inverse[:,5]*100)\n",
    "Test_MZData3 =  np.array(Test_MZData3)\n",
    "Test_MZData3 = Test_MZData3.reshape(-1,1)\n",
    "\n",
    "Test_new_inverse3 = np.concatenate((Test_FXData3, Test_FYData3, Test_FZData3, Test_MXData3, Test_MYData3, Test_MZData3), axis=1)\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_new_inverse2[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_new_inverse3[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('CNN Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# COP\n",
    "from math import*\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "Test_out_Fz = Test_new_inverse2[:,2]\n",
    "Test_out_Mx = Test_new_inverse2[:,3]\n",
    "Test_out_My = Test_new_inverse2[:,4]\n",
    "Test_Pred_Fz = Test_new_inverse3[:,2]\n",
    "Test_Pred_Mx = Test_new_inverse3[:,3]\n",
    "Test_Pred_My = Test_new_inverse3[:,4]\n",
    "\n",
    "Test_Pred_COPx=[]\n",
    "for i in range(0,len(Test_Pred_Fz)):\n",
    "  Test_Pred_COPx_temp=-(Test_Pred_My[i])/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPx_temp != Test_Pred_COPx_temp:\n",
    "    Test_Pred_COPx_temp=0\n",
    "  Test_Pred_COPx.append(Test_Pred_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPx=[]\n",
    "for i in range(0,len(Test_out_Fz)):\n",
    "  Test_out_COPx_temp=-(Test_out_My[i])/Test_out_Fz[i]\n",
    "  if Test_out_COPx_temp != Test_out_COPx_temp:\n",
    "    Test_out_COPx_temp=0\n",
    "  Test_out_COPx.append(Test_out_COPx_temp)\n",
    "  # break\n",
    "\n",
    "Test_Pred_COPy=[]\n",
    "for i in range(0,len(Test_Pred_Mx)):\n",
    "  Test_Pred_COPy_temp=Test_Pred_Mx[i]/Test_Pred_Fz[i]\n",
    "  if Test_Pred_COPy_temp != Test_Pred_COPy_temp:\n",
    "    Test_Pred_COPy_temp=0\n",
    "  Test_Pred_COPy.append(Test_Pred_COPy_temp)\n",
    "  # break\n",
    "\n",
    "Test_out_COPy=[]\n",
    "for i in range(0,len(Test_out_Mx)):\n",
    "  Test_out_COPy_temp=Test_out_Mx[i]/Test_out_Fz[i]\n",
    "  if Test_out_COPy_temp != Test_out_COPy_temp:\n",
    "    Test_out_COPy_temp=0\n",
    "  Test_out_COPy.append(Test_out_COPy_temp)\n",
    "  # break\n",
    "\n",
    "\n",
    "Test_out_COPx = np.array(Test_out_COPx)\n",
    "Test_out_COPx= Test_out_COPx.reshape(-1,1)\n",
    "\n",
    "Test_out_COPy = np.array(Test_out_COPy)\n",
    "Test_out_COPy= Test_out_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPx = np.array(Test_Pred_COPx)\n",
    "Test_Pred_COPx= Test_Pred_COPx.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COPy = np.array(Test_Pred_COPy)\n",
    "Test_Pred_COPy= Test_Pred_COPy.reshape(-1,1)\n",
    "\n",
    "Test_Pred_COP = np.concatenate((Test_Pred_COPx, Test_Pred_COPy), axis=1)\n",
    "Test_FC_COP = np.concatenate((Test_out_COPx, Test_out_COPy), axis=1)\n",
    "\n",
    "Test_col_COP = 'COPx', 'COPy'\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,2000)*40/2000 \n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(x,Test_FC_COP[0:2000,i], color='red')\n",
    "    plt.plot(x,Test_Pred_COP[0:2000,i],markerfacecolor='none',color='green')\n",
    "    plt.title('COP Calculation (Testing Data)')\n",
    "    plt.ylabel(col_COP[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.savefig('Regression Result.png'[i])\n",
    "    plt.show()\n",
    "\n",
    "# Trajectory\n",
    "from matplotlib import pyplot\n",
    "\n",
    "x = range(50)\n",
    "Test_y1 = Test_FC_COP[50:100,0]\n",
    "Test_y2 = Test_FC_COP[50:100,1]\n",
    "Test_y3 = Test_Pred_COP[50:100,0]\n",
    "Test_y4 = Test_Pred_COP[50:100,1]\n",
    "\n",
    "# pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(FC_COP[:,0],FC_COP[:,1])\n",
    "# pyplot.show()\n",
    "\n",
    "# Test_data_filter = abs(y1) > 0\n",
    "# Test_data_filter2 = abs(y3) > 0\n",
    "pyplot.figure(figsize=(15,6))\n",
    "# pyplot.plot(Test_y1[Test_data_filter], Test_y2[Test_data_filter ], color='red', alpha=0.3)\n",
    "# pyplot.plot(Test_y3[Test_data_filter2], Test_y4[Test_data_filter2 ], color='green')\n",
    "pyplot.plot(Test_y1, Test_y2, color='red')\n",
    "pyplot.plot(Test_y3, Test_y4, color='green')\n",
    "plt.title('COP Trajectory (Testing Data)')\n",
    "pyplot.ylabel('COPy (mm)')\n",
    "pyplot.xlabel('COPx (mm)')\n",
    "pyplot.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
