{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFyb0y7PUJOo"
   },
   "source": [
    "# ResNet Model Building Pipeline for 1D Signals with DEMO\n",
    "#### ResNet18, ResNet34, ResNet50, ResNet101, ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import tornado.iostream\n",
    "\n",
    "# Create a TCP connection to a server running on localhost at port 8000\n",
    "sock = socket.create_connection(('localhost', 8888))\n",
    "\n",
    "# Create an IOStream object with a large buffer size\n",
    "stream = tornado.iostream.IOStream(sock, max_buffer_size=1073741824)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eMhBhz1CrMb3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from numpy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, BatchNormalization, Activation, add\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape, Flatten, Dense\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "# from tensorflow.keras.optimizers import AdamW\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import Normalizer,MinMaxScaler,StandardScaler, RobustScaler, QuantileTransformer, PowerTransformer\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "import pywt\n",
    "np.set_printoptions(suppress=True)\n",
    "# Import ResNet1D Module\n",
    "from ResNet_1DCNN import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Fx','Fy','Fz','Mx','My','Mz']\n",
    "# columns = ['Fx']\n",
    "wavelet = 'db4'\n",
    "max_iter = 50\n",
    "iter = 0\n",
    "\n",
    "# Walking Dataset\n",
    "InsoleWalking1 = pd.read_csv('0310AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking2 = pd.read_csv('0310HudaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking3 = pd.read_csv('0311LalaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking4 = pd.read_csv('0311YunitaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking5 = pd.read_csv('0312AbelRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking6 = pd.read_csv('0312AbiRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking7 = pd.read_csv('0312AryaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking8 = pd.read_csv('0312HawaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking9 = pd.read_csv('0312NisaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking10 = pd.read_csv('0313ChenChengRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking11 = pd.read_csv('0313RezaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking12 = pd.read_csv('0313RilaniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking13 = pd.read_csv('0313SariRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking14 = pd.read_csv('0313ShelbyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking15 = pd.read_csv('0314HelenRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking16 = pd.read_csv('0315AyuRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking17 = pd.read_csv('0315HappyRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking18 = pd.read_csv('0317HeniRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking19 = pd.read_csv('0317NadiaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking20 = pd.read_csv('0317VikaRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking21 = pd.read_csv('0319AlfianRWalk5Min.txt', header=None, low_memory=False)\n",
    "InsoleWalking22 = pd.read_csv('1225JakariaRWalk5Min.txt', header=None, low_memory=False)\n",
    "SIDatasWalking1 =  np.array(InsoleWalking1)\n",
    "SIDatasWalking2 =  np.array(InsoleWalking2)\n",
    "SIDatasWalking3 =  np.array(InsoleWalking3)\n",
    "SIDatasWalking4 =  np.array(InsoleWalking4)\n",
    "SIDatasWalking5 =  np.array(InsoleWalking5)\n",
    "SIDatasWalking6 =  np.array(InsoleWalking6)\n",
    "SIDatasWalking7 =  np.array(InsoleWalking7)\n",
    "SIDatasWalking8 =  np.array(InsoleWalking8)\n",
    "SIDatasWalking9 =  np.array(InsoleWalking9)\n",
    "SIDatasWalking10 =  np.array(InsoleWalking10)\n",
    "SIDatasWalking11 =  np.array(InsoleWalking11)\n",
    "SIDatasWalking12 =  np.array(InsoleWalking12)\n",
    "SIDatasWalking13 =  np.array(InsoleWalking13)\n",
    "SIDatasWalking14 =  np.array(InsoleWalking14)\n",
    "SIDatasWalking15 =  np.array(InsoleWalking15)\n",
    "SIDatasWalking16 =  np.array(InsoleWalking16)\n",
    "SIDatasWalking17 =  np.array(InsoleWalking17)\n",
    "SIDatasWalking18 =  np.array(InsoleWalking18)\n",
    "SIDatasWalking19 =  np.array(InsoleWalking19)\n",
    "SIDatasWalking20 =  np.array(InsoleWalking20)\n",
    "SIDatasWalking21 =  np.array(InsoleWalking21)\n",
    "SIDatasWalking22 =  np.array(InsoleWalking22)\n",
    "\n",
    "dfwalk1 = pd.read_csv('0310AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk2 = pd.read_csv('0310HudaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk3 = pd.read_csv('0311LalaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk4 = pd.read_csv('0311YunitaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk5 = pd.read_csv('0312AbelRWalk5Min.csv', low_memory=False)\n",
    "dfwalk6 = pd.read_csv('0312AbiRWalk5Min.csv', low_memory=False)\n",
    "dfwalk7 = pd.read_csv('0312AryaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk8 = pd.read_csv('0312HawaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk9 = pd.read_csv('0312NisaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk10 = pd.read_csv('0313ChenChengRWalk5Min.csv', low_memory=False)\n",
    "dfwalk11 = pd.read_csv('0313RezaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk12 = pd.read_csv('0313RilaniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk13 = pd.read_csv('0313SariRWalk5Min.csv', low_memory=False)\n",
    "dfwalk14 = pd.read_csv('0313ShelbyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk15 = pd.read_csv('0314HelenRWalk5Min.csv', low_memory=False)\n",
    "dfwalk16 = pd.read_csv('0315AyuRWalk5Min.csv', low_memory=False)\n",
    "dfwalk17 = pd.read_csv('0315HappyRWalk5Min.csv', low_memory=False)\n",
    "dfwalk18 = pd.read_csv('0317HeniRWalk5Min.csv', low_memory=False)\n",
    "dfwalk19 = pd.read_csv('0317NadiaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk20 = pd.read_csv('0317VikaRWalk5Min.csv', low_memory=False)\n",
    "dfwalk21 = pd.read_csv('0319AlfianRWalk5Min.csv', low_memory=False)\n",
    "dfwalk22 = pd.read_csv('1225JakariaRWalk5Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfwalks1 = dfwalk1[columns]\n",
    "selected_dfwalks2 = dfwalk2[columns]\n",
    "selected_dfwalks3 = dfwalk3[columns]\n",
    "selected_dfwalks4 = dfwalk4[columns]\n",
    "selected_dfwalks5 = dfwalk5[columns]\n",
    "selected_dfwalks6 = dfwalk6[columns]\n",
    "selected_dfwalks7 = dfwalk7[columns]\n",
    "selected_dfwalks8 = dfwalk8[columns]\n",
    "selected_dfwalks9 = dfwalk9[columns]\n",
    "selected_dfwalks10 = dfwalk10[columns]\n",
    "selected_dfwalks11 = dfwalk11[columns]\n",
    "selected_dfwalks12 = dfwalk12[columns]\n",
    "selected_dfwalks13 = dfwalk13[columns]\n",
    "selected_dfwalks14 = dfwalk14[columns]\n",
    "selected_dfwalks15 = dfwalk15[columns]\n",
    "selected_dfwalks16 = dfwalk16[columns]\n",
    "selected_dfwalks17 = dfwalk17[columns]\n",
    "selected_dfwalks18 = dfwalk18[columns]\n",
    "selected_dfwalks19 = dfwalk19[columns]\n",
    "selected_dfwalks20 = dfwalk20[columns]\n",
    "selected_dfwalks21 = dfwalk21[columns]\n",
    "selected_dfwalks22 = dfwalk22[columns]\n",
    "FPDatasWalking1 = selected_dfwalks1[:15000]\n",
    "FPDatasWalking2 = selected_dfwalks2[:15000]\n",
    "FPDatasWalking3 = selected_dfwalks3[:15000]\n",
    "FPDatasWalking4 = selected_dfwalks4[:15000]\n",
    "FPDatasWalking5 = selected_dfwalks5[:15000]\n",
    "FPDatasWalking6 = selected_dfwalks6[:15000]\n",
    "FPDatasWalking7 = selected_dfwalks7[:15000]\n",
    "FPDatasWalking8 = selected_dfwalks8[:15000]\n",
    "FPDatasWalking9 = selected_dfwalks9[:15000]\n",
    "FPDatasWalking10 = selected_dfwalks10[:15000]\n",
    "FPDatasWalking11 = selected_dfwalks11[:15000]\n",
    "FPDatasWalking12 = selected_dfwalks12[:15000]\n",
    "FPDatasWalking13 = selected_dfwalks13[:15000]\n",
    "FPDatasWalking14 = selected_dfwalks14[:15000]\n",
    "FPDatasWalking15 = selected_dfwalks15[:15000]\n",
    "FPDatasWalking16 = selected_dfwalks16[:15000]\n",
    "FPDatasWalking17 = selected_dfwalks17[:15000]\n",
    "FPDatasWalking18 = selected_dfwalks18[:15000]\n",
    "FPDatasWalking19 = selected_dfwalks19[:15000]\n",
    "FPDatasWalking20 = selected_dfwalks20[:15000]\n",
    "FPDatasWalking21 = selected_dfwalks21[:15000]\n",
    "FPDatasWalking22 = selected_dfwalks22[:15000]\n",
    "\n",
    "SIDataWalking1 = np.array(SIDatasWalking1[:15000]).astype('float32')\n",
    "SIDataWalking2 = np.array(SIDatasWalking2[:15000]).astype('float32')\n",
    "SIDataWalking3 = np.array(SIDatasWalking3[:15000]).astype('float32')\n",
    "SIDataWalking4 = np.array(SIDatasWalking4[:15000]).astype('float32')\n",
    "SIDataWalking5 = np.array(SIDatasWalking5[:15000]).astype('float32')\n",
    "SIDataWalking6 = np.array(SIDatasWalking6[:15000]).astype('float32')\n",
    "SIDataWalking7 = np.array(SIDatasWalking7[:15000]).astype('float32')\n",
    "SIDataWalking8 = np.array(SIDatasWalking8[:15000]).astype('float32')\n",
    "SIDataWalking9 = np.array(SIDatasWalking9[:15000]).astype('float32')\n",
    "SIDataWalking10 = np.array(SIDatasWalking10[:15000]).astype('float32')\n",
    "SIDataWalking11 = np.array(SIDatasWalking11[:15000]).astype('float32')\n",
    "SIDataWalking12 = np.array(SIDatasWalking12[:15000]).astype('float32')\n",
    "SIDataWalking13 = np.array(SIDatasWalking13[:15000]).astype('float32')\n",
    "SIDataWalking14 = np.array(SIDatasWalking14[:15000]).astype('float32')\n",
    "SIDataWalking15 = np.array(SIDatasWalking15[:15000]).astype('float32')\n",
    "SIDataWalking16 = np.array(SIDatasWalking16[:15000]).astype('float32')\n",
    "SIDataWalking17 = np.array(SIDatasWalking17[:15000]).astype('float32')\n",
    "SIDataWalking18 = np.array(SIDatasWalking18[:15000]).astype('float32')\n",
    "SIDataWalking19 = np.array(SIDatasWalking19[:15000]).astype('float32')\n",
    "SIDataWalking20 = np.array(SIDatasWalking20[:15000]).astype('float32')\n",
    "SIDataWalking21 = np.array(SIDatasWalking21[:15000]).astype('float32')\n",
    "SIDataWalking22 = np.array(SIDatasWalking22[:15000]).astype('float32')\n",
    "FPDataWalking1 = np.array(FPDatasWalking1).astype('float32')\n",
    "FPDataWalking2 = np.array(FPDatasWalking2).astype('float32')\n",
    "FPDataWalking3= np.array(FPDatasWalking3).astype('float32')\n",
    "FPDataWalking4= np.array(FPDatasWalking4).astype('float32')\n",
    "FPDataWalking5= np.array(FPDatasWalking5).astype('float32')\n",
    "FPDataWalking6= np.array(FPDatasWalking6).astype('float32')\n",
    "FPDataWalking7= np.array(FPDatasWalking7).astype('float32')\n",
    "FPDataWalking8= np.array(FPDatasWalking8).astype('float32')\n",
    "FPDataWalking9= np.array(FPDatasWalking9).astype('float32')\n",
    "FPDataWalking10 = np.array(FPDatasWalking10).astype('float32')\n",
    "FPDataWalking11 = np.array(FPDatasWalking11).astype('float32')\n",
    "FPDataWalking12= np.array(FPDatasWalking12).astype('float32')\n",
    "FPDataWalking13= np.array(FPDatasWalking13).astype('float32')\n",
    "FPDataWalking14= np.array(FPDatasWalking14).astype('float32')\n",
    "FPDataWalking15= np.array(FPDatasWalking15).astype('float32')\n",
    "FPDataWalking16= np.array(FPDatasWalking16).astype('float32')\n",
    "FPDataWalking17= np.array(FPDatasWalking17).astype('float32')\n",
    "FPDataWalking18= np.array(FPDatasWalking18).astype('float32')\n",
    "FPDataWalking19= np.array(FPDatasWalking19).astype('float32')\n",
    "FPDataWalking20= np.array(FPDatasWalking20).astype('float32')\n",
    "FPDataWalking21= np.array(FPDatasWalking21).astype('float32')\n",
    "FPDataWalking22= np.array(FPDatasWalking22).astype('float32')\n",
    "\n",
    "SIDatasetWalkingTrain = np.concatenate((SIDataWalking1[:10000], SIDataWalking2[:10000], SIDataWalking3[:10000],\n",
    "                            SIDataWalking4[:10000], SIDataWalking5[:10000], SIDataWalking6[:10000],\n",
    "                            SIDataWalking7[:10000], SIDataWalking8[:10000], SIDataWalking9[:10000],\n",
    "                            SIDataWalking10[:10000], SIDataWalking11[:10000], SIDataWalking12[:10000],\n",
    "                            SIDataWalking13[:10000], SIDataWalking14[:10000], SIDataWalking15[:10000],\n",
    "                            SIDataWalking16[:10000], SIDataWalking17[:10000], SIDataWalking18[:10000],\n",
    "                            SIDataWalking19[:10000], SIDataWalking20[:10000], SIDataWalking21[:10000],\n",
    "                            SIDataWalking22[:10000]), axis=0)\n",
    "                            \n",
    "FPDatasetWalkingTrain = np.concatenate((FPDataWalking1[:10000], FPDataWalking2[:10000], FPDataWalking3[:10000],\n",
    "                            FPDataWalking4[:10000], FPDataWalking5[:10000], FPDataWalking6[:10000],\n",
    "                            FPDataWalking7[:10000], FPDataWalking8[:10000], FPDataWalking9[:10000],\n",
    "                            FPDataWalking10[:10000], FPDataWalking11[:10000], FPDataWalking12[:10000],\n",
    "                            FPDataWalking13[:10000], FPDataWalking14[:10000], FPDataWalking15[:10000],\n",
    "                            FPDataWalking16[:10000], FPDataWalking17[:10000], FPDataWalking18[:10000],\n",
    "                            FPDataWalking19[:10000], FPDataWalking20[:10000], FPDataWalking21[:10000],\n",
    "                            FPDataWalking22[:10000]), axis=0)\n",
    "\n",
    "SIDatasetWalkingTest = np.concatenate((SIDataWalking1[10000:], SIDataWalking2[10000:], SIDataWalking3[10000:],\n",
    "                            SIDataWalking4[10000:], SIDataWalking5[10000:], SIDataWalking6[10000:],\n",
    "                            SIDataWalking7[10000:], SIDataWalking8[10000:], SIDataWalking9[10000:],\n",
    "                            SIDataWalking10[10000:], SIDataWalking11[10000:], SIDataWalking12[10000:],\n",
    "                            SIDataWalking13[10000:], SIDataWalking14[10000:], SIDataWalking15[10000:],\n",
    "                            SIDataWalking16[10000:], SIDataWalking17[10000:], SIDataWalking18[10000:],\n",
    "                            SIDataWalking19[10000:], SIDataWalking20[10000:], SIDataWalking21[10000:],\n",
    "                            SIDataWalking22[10000:]), axis=0)\n",
    "                            \n",
    "FPDatasetWalkingTest = np.concatenate((FPDataWalking1[10000:], FPDataWalking2[10000:], FPDataWalking3[10000:],\n",
    "                            FPDataWalking4[10000:], FPDataWalking5[10000:], FPDataWalking6[10000:],\n",
    "                            FPDataWalking7[10000:], FPDataWalking8[10000:], FPDataWalking9[10000:],\n",
    "                            FPDataWalking10[10000:], FPDataWalking11[10000:], FPDataWalking12[10000:],\n",
    "                            FPDataWalking13[10000:], FPDataWalking14[10000:], FPDataWalking15[10000:],\n",
    "                            FPDataWalking16[10000:], FPDataWalking17[10000:], FPDataWalking18[10000:],\n",
    "                            FPDataWalking19[10000:], FPDataWalking20[10000:], FPDataWalking21[10000:],\n",
    "                            FPDataWalking22[10000:]), axis=0)\n",
    "\n",
    "# SIDatasetWalking = SIDataWalking1\n",
    "# FPDatasetWalking = FPDataWalking1\n",
    "\n",
    "# SIDatasetWalking = np.array(SIDatasetWalking).astype('float64')\n",
    "# FPDatasetWalking = np.array(FPDatasetWalking).astype('float64')\n",
    "\n",
    "# Standing Dataset\n",
    "InsoleStanding1 = pd.read_csv('0310AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding2 = pd.read_csv('0310HudaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding3 = pd.read_csv('0311LalaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding4 = pd.read_csv('0311YunitaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding5 = pd.read_csv('0312AbelStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding6 = pd.read_csv('0312AbiStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding7 = pd.read_csv('0312AryaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding8 = pd.read_csv('0312HawaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding9 = pd.read_csv('0312NisaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding10 = pd.read_csv('0313ChenChengStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding11 = pd.read_csv('0313RezaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding12 = pd.read_csv('0313RilaniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding13 = pd.read_csv('0313SariStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding14 = pd.read_csv('0313ShelbyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding15 = pd.read_csv('0314HelenStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding16 = pd.read_csv('0315AyuStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding17 = pd.read_csv('0315HappyStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding18 = pd.read_csv('0317HeniStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding19 = pd.read_csv('0317NadiaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding20 = pd.read_csv('0317VikaStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding21 = pd.read_csv('0319AlfianStand5Min1.txt', header=None, low_memory=False)\n",
    "InsoleStanding22 = pd.read_csv('0310JakaStand2Min.txt', header=None, low_memory=False)\n",
    "SIDatasStanding1 =  np.array(InsoleStanding1)\n",
    "SIDatasStanding2 =  np.array(InsoleStanding2)\n",
    "SIDatasStanding3 =  np.array(InsoleStanding3)\n",
    "SIDatasStanding4 =  np.array(InsoleStanding4)\n",
    "SIDatasStanding5 =  np.array(InsoleStanding5)\n",
    "SIDatasStanding6 =  np.array(InsoleStanding6)\n",
    "SIDatasStanding7 =  np.array(InsoleStanding7)\n",
    "SIDatasStanding8 =  np.array(InsoleStanding8)\n",
    "SIDatasStanding9 =  np.array(InsoleStanding9)\n",
    "SIDatasStanding10 =  np.array(InsoleStanding10)\n",
    "SIDatasStanding11 =  np.array(InsoleStanding11)\n",
    "SIDatasStanding12 =  np.array(InsoleStanding12)\n",
    "SIDatasStanding13 =  np.array(InsoleStanding13)\n",
    "SIDatasStanding14 =  np.array(InsoleStanding14)\n",
    "SIDatasStanding15 =  np.array(InsoleStanding15)\n",
    "SIDatasStanding16 =  np.array(InsoleStanding16)\n",
    "SIDatasStanding17 =  np.array(InsoleStanding17)\n",
    "SIDatasStanding18 =  np.array(InsoleStanding18)\n",
    "SIDatasStanding19 =  np.array(InsoleStanding19)\n",
    "SIDatasStanding20 =  np.array(InsoleStanding20)\n",
    "SIDatasStanding21 =  np.array(InsoleStanding21)\n",
    "SIDatasStanding22 =  np.array(InsoleStanding22)\n",
    "\n",
    "dfStanding1 = pd.read_csv('0310AyuStand5Min1.csv', low_memory=False)\n",
    "dfStanding2 = pd.read_csv('0310HudaStand5Min1.csv', low_memory=False)\n",
    "dfStanding3 = pd.read_csv('0311LalaStand5Min1.csv', low_memory=False)\n",
    "dfStanding4 = pd.read_csv('0311YunitaStand5Min1.csv', low_memory=False)\n",
    "dfStanding5 = pd.read_csv('0312AbelStand5Min1.csv', low_memory=False)\n",
    "dfStanding6 = pd.read_csv('0312AbiStand5Min1.csv', low_memory=False)\n",
    "dfStanding7 = pd.read_csv('0312AryaStand5Min1.csv', low_memory=False)\n",
    "dfStanding8 = pd.read_csv('0312HawaStand5Min1.csv', low_memory=False)\n",
    "dfStanding9 = pd.read_csv('0312NisaStand5Min1.csv', low_memory=False)\n",
    "dfStanding10 = pd.read_csv('0313ChenChengStand5Min1.csv', low_memory=False)\n",
    "dfStanding11 = pd.read_csv('0313RezaStand5Min1.csv', low_memory=False)\n",
    "dfStanding12 = pd.read_csv('0313RilaniStand5Min1.csv', low_memory=False)\n",
    "dfStanding13 = pd.read_csv('0313SariStand5Min1.csv', low_memory=False)\n",
    "dfStanding14 = pd.read_csv('0313ShelbyStand5Min1.csv', low_memory=False)\n",
    "dfStanding15 = pd.read_csv('0314HelenStand5Min1.csv', low_memory=False)\n",
    "dfStanding16 = pd.read_csv('0315AyuStand5Min1.csv', low_memory=False)\n",
    "dfStanding17 = pd.read_csv('0315HappyStand5Min1.csv', low_memory=False)\n",
    "dfStanding18 = pd.read_csv('0317HeniStand5Min1.csv', low_memory=False)\n",
    "dfStanding19 = pd.read_csv('0317NadiaStand5Min1.csv', low_memory=False)\n",
    "dfStanding20 = pd.read_csv('0317VikaStand5Min1.csv', low_memory=False)\n",
    "dfStanding21 = pd.read_csv('0319AlfianStand5Min1.csv', low_memory=False)\n",
    "dfStanding22 = pd.read_csv('0310JakaStand2Min.csv', low_memory=False)\n",
    "\n",
    "selected_dfStandings1 = dfStanding1[columns]\n",
    "selected_dfStandings2 = dfStanding2[columns]\n",
    "selected_dfStandings3 = dfStanding3[columns]\n",
    "selected_dfStandings4 = dfStanding4[columns]\n",
    "selected_dfStandings5 = dfStanding5[columns]\n",
    "selected_dfStandings6 = dfStanding6[columns]\n",
    "selected_dfStandings7 = dfStanding7[columns]\n",
    "selected_dfStandings8 = dfStanding8[columns]\n",
    "selected_dfStandings9 = dfStanding9[columns]\n",
    "selected_dfStandings10 = dfStanding10[columns]\n",
    "selected_dfStandings11 = dfStanding11[columns]\n",
    "selected_dfStandings12 = dfStanding12[columns]\n",
    "selected_dfStandings13 = dfStanding13[columns]\n",
    "selected_dfStandings14 = dfStanding14[columns]\n",
    "selected_dfStandings15 = dfStanding15[columns]\n",
    "selected_dfStandings16 = dfStanding16[columns]\n",
    "selected_dfStandings17 = dfStanding17[columns]\n",
    "selected_dfStandings18 = dfStanding18[columns]\n",
    "selected_dfStandings19 = dfStanding19[columns]\n",
    "selected_dfStandings20 = dfStanding20[columns]\n",
    "selected_dfStandings21 = dfStanding21[columns]\n",
    "selected_dfStandings22 = dfStanding22[columns]\n",
    "FPDataStandings1 = selected_dfStandings1[:15000]\n",
    "FPDataStandings2 = selected_dfStandings2[:15000]\n",
    "FPDataStandings3 = selected_dfStandings3[:15000]\n",
    "FPDataStandings4 = selected_dfStandings4[:15000]\n",
    "FPDataStandings5 = selected_dfStandings5[:15000]\n",
    "FPDataStandings6 = selected_dfStandings6[:15000]\n",
    "FPDataStandings7 = selected_dfStandings7[:15000]\n",
    "FPDataStandings8 = selected_dfStandings8[:15000]\n",
    "FPDataStandings9 = selected_dfStandings9[:15000]\n",
    "FPDataStandings10 = selected_dfStandings10[:15000]\n",
    "FPDataStandings11 = selected_dfStandings11[:15000]\n",
    "FPDataStandings12 = selected_dfStandings12[:15000]\n",
    "FPDataStandings13 = selected_dfStandings13[:15000]\n",
    "FPDataStandings14 = selected_dfStandings14[:15000]\n",
    "FPDataStandings15 = selected_dfStandings15[:15000]\n",
    "FPDataStandings16 = selected_dfStandings16[:15000]\n",
    "FPDataStandings17 = selected_dfStandings17[:15000]\n",
    "FPDataStandings18 = selected_dfStandings18[:15000]\n",
    "FPDataStandings19 = selected_dfStandings19[:15000]\n",
    "FPDataStandings20 = selected_dfStandings20[:15000]\n",
    "FPDataStandings21 = selected_dfStandings21[:15000]\n",
    "FPDataStandings22 = selected_dfStandings22[:15000]\n",
    "\n",
    "SIDataStanding1 = np.array(SIDatasStanding1[:15000]).astype('float32')\n",
    "SIDataStanding2 = np.array(SIDatasStanding2[:15000]).astype('float32')\n",
    "SIDataStanding3 = np.array(SIDatasStanding3[:15000]).astype('float32')\n",
    "SIDataStanding4 = np.array(SIDatasStanding4[:15000]).astype('float32')\n",
    "SIDataStanding5 = np.array(SIDatasStanding5[:15000]).astype('float32')\n",
    "SIDataStanding6 = np.array(SIDatasStanding6[:15000]).astype('float32')\n",
    "SIDataStanding7 = np.array(SIDatasStanding7[:15000]).astype('float32')\n",
    "SIDataStanding8 = np.array(SIDatasStanding8[:15000]).astype('float32')\n",
    "SIDataStanding9 = np.array(SIDatasStanding9[:15000]).astype('float32')\n",
    "SIDataStanding10 = np.array(SIDatasStanding10[:15000]).astype('float32')\n",
    "SIDataStanding11 = np.array(SIDatasStanding11[:15000]).astype('float32')\n",
    "SIDataStanding12 = np.array(SIDatasStanding12[:15000]).astype('float32')\n",
    "SIDataStanding13 = np.array(SIDatasStanding13[:15000]).astype('float32')\n",
    "SIDataStanding14 = np.array(SIDatasStanding14[:15000]).astype('float32')\n",
    "SIDataStanding15 = np.array(SIDatasStanding15[:15000]).astype('float32')\n",
    "SIDataStanding16 = np.array(SIDatasStanding16[:15000]).astype('float32')\n",
    "SIDataStanding17 = np.array(SIDatasStanding17[:15000]).astype('float32')\n",
    "SIDataStanding18 = np.array(SIDatasStanding18[:15000]).astype('float32')\n",
    "SIDataStanding19 = np.array(SIDatasStanding19[:15000]).astype('float32')\n",
    "SIDataStanding20 = np.array(SIDatasStanding20[:15000]).astype('float32')\n",
    "SIDataStanding21 = np.array(SIDatasStanding21[:15000]).astype('float32')\n",
    "SIDataStanding22 = np.array(SIDatasStanding22[:15000]).astype('float32')\n",
    "FPDataStanding1 = np.array(FPDataStandings1).astype('float32')\n",
    "FPDataStanding2 = np.array(FPDataStandings2).astype('float32')\n",
    "FPDataStanding3= np.array(FPDataStandings3).astype('float32')\n",
    "FPDataStanding4= np.array(FPDataStandings4).astype('float32')\n",
    "FPDataStanding5= np.array(FPDataStandings5).astype('float32')\n",
    "FPDataStanding6= np.array(FPDataStandings6).astype('float32')\n",
    "FPDataStanding7= np.array(FPDataStandings7).astype('float32')\n",
    "FPDataStanding8= np.array(FPDataStandings8).astype('float32')\n",
    "FPDataStanding9= np.array(FPDataStandings9).astype('float32')\n",
    "FPDataStanding10 = np.array(FPDataStandings10).astype('float32')\n",
    "FPDataStanding11 = np.array(FPDataStandings11).astype('float32')\n",
    "FPDataStanding12= np.array(FPDataStandings12).astype('float32')\n",
    "FPDataStanding13= np.array(FPDataStandings13).astype('float32')\n",
    "FPDataStanding14= np.array(FPDataStandings14).astype('float32')\n",
    "FPDataStanding15= np.array(FPDataStandings15).astype('float32')\n",
    "FPDataStanding16= np.array(FPDataStandings16).astype('float32')\n",
    "FPDataStanding17= np.array(FPDataStandings17).astype('float32')\n",
    "FPDataStanding18= np.array(FPDataStandings18).astype('float32')\n",
    "FPDataStanding19= np.array(FPDataStandings19).astype('float32')\n",
    "FPDataStanding20= np.array(FPDataStandings20).astype('float32')\n",
    "FPDataStanding21= np.array(FPDataStandings21).astype('float32')\n",
    "FPDataStanding22= np.array(FPDataStandings22).astype('float32')\n",
    "\n",
    "SIDatasetStandingTrain = np.concatenate((SIDataStanding1[:10000], SIDataStanding2[:10000], SIDataStanding3[:10000],\n",
    "                            SIDataStanding4[:10000], SIDataStanding5[:10000], SIDataStanding6[:10000],\n",
    "                            SIDataStanding7[:10000], SIDataStanding8[:10000], SIDataStanding9[:10000],\n",
    "                            SIDataStanding10[:10000], SIDataStanding11[:10000], SIDataStanding12[:10000],\n",
    "                            SIDataStanding13[:10000], SIDataStanding14[:10000], SIDataStanding15[:10000],\n",
    "                            SIDataStanding16[:10000], SIDataStanding17[:10000], SIDataStanding18[:10000],\n",
    "                            SIDataStanding19[:10000], SIDataStanding20[:10000], SIDataStanding21[:10000]), axis=0)\n",
    "\n",
    "                        \n",
    "FPDatasetStandingTrain = np.concatenate((FPDataStanding1[:10000], FPDataStanding2[:10000], FPDataStanding3[:10000],\n",
    "                            FPDataStanding4[:10000], FPDataStanding5[:10000], FPDataStanding6[:10000],\n",
    "                            FPDataStanding7[:10000], FPDataStanding8[:10000], FPDataStanding9[:10000],\n",
    "                            FPDataStanding10[:10000], FPDataStanding11[:10000], FPDataStanding12[:10000],\n",
    "                            FPDataStanding13[:10000], FPDataStanding14[:10000], FPDataStanding15[:10000],\n",
    "                            FPDataStanding16[:10000], FPDataStanding17[:10000], FPDataStanding18[:10000],\n",
    "                            FPDataStanding19[:10000], FPDataStanding20[:10000], FPDataStanding21[:10000]), axis=0)\n",
    "\n",
    "SIDatasetStandingTest = np.concatenate((SIDataStanding1[10000:], SIDataStanding2[10000:], SIDataStanding3[10000:],\n",
    "                            SIDataStanding4[10000:], SIDataStanding5[10000:], SIDataStanding6[10000:],\n",
    "                            SIDataStanding7[10000:], SIDataStanding8[10000:], SIDataStanding9[10000:],\n",
    "                            SIDataStanding10[10000:], SIDataStanding11[10000:], SIDataStanding12[10000:],\n",
    "                            SIDataStanding13[10000:], SIDataStanding14[10000:], SIDataStanding15[10000:],\n",
    "                            SIDataStanding16[10000:], SIDataStanding17[10000:], SIDataStanding18[10000:],\n",
    "                            SIDataStanding19[10000:], SIDataStanding20[10000:], SIDataStanding21[10000:]), axis=0)\n",
    "\n",
    "                        \n",
    "FPDatasetStandingTest = np.concatenate((FPDataStanding1[10000:], FPDataStanding2[10000:], FPDataStanding3[10000:],\n",
    "                            FPDataStanding4[10000:], FPDataStanding5[10000:], FPDataStanding6[10000:],\n",
    "                            FPDataStanding7[10000:], FPDataStanding8[10000:], FPDataStanding9[10000:],\n",
    "                            FPDataStanding10[10000:], FPDataStanding11[10000:], FPDataStanding12[10000:],\n",
    "                            FPDataStanding13[10000:], FPDataStanding14[10000:], FPDataStanding15[10000:],\n",
    "                            FPDataStanding16[10000:], FPDataStanding17[10000:], FPDataStanding18[10000:],\n",
    "                            FPDataStanding19[10000:], FPDataStanding20[10000:], FPDataStanding21[10000:]), axis=0)\n",
    "\n",
    "\n",
    "SIDatasetStandingTrain = np.array(SIDatasetStandingTrain).astype('float32')\n",
    "FPDatasetStandingTrain = np.array(FPDatasetStandingTrain).astype('float32')\n",
    "\n",
    "SIDatasetStandingTest = np.array(SIDatasetStandingTest).astype('float32')\n",
    "FPDatasetStandingTest = np.array(FPDatasetStandingTest).astype('float32')\n",
    "\n",
    "SIDatasetTrain = SIDatasetStandingTrain[:]\n",
    "FPDatasetTrain = FPDatasetStandingTrain\n",
    "\n",
    "SIDatasetTest = SIDatasetStandingTest\n",
    "FPDatasetTest = FPDatasetStandingTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6IOf_sFx5Dm"
   },
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168000, 89, 1) (42000, 89, 1)\n",
      "(168000, 6) (42000, 6)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 89, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 45, 64)       512         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 45, 64)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 22, 64)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 22, 64)       12352       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 22, 64)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 22, 64)       12352       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 22, 64)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 22, 64)       0           ['activation_2[0][0]',           \n",
      "                                                                  'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 22, 64)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 22, 64)       12352       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 22, 64)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 22, 64)       12352       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 22, 64)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 22, 64)       0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 22, 64)       0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 11, 128)      24704       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 11, 128)      0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 11, 128)      49280       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 11, 128)      0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 11, 128)      49280       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 11, 128)      0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 11, 128)      49280       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 11, 128)      0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 11, 128)      0           ['activation_10[0][0]',          \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 11, 128)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 6, 256)       98560       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 6, 256)       0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 6, 256)       196864      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 6, 256)       0           ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 6, 256)       196864      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 6, 256)       0           ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 6, 256)       196864      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 6, 256)       0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 6, 256)       0           ['activation_15[0][0]',          \n",
      "                                                                  'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 6, 256)       0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 3, 512)       393728      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 3, 512)       0           ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_14 (Conv1D)             (None, 3, 512)       786944      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 3, 512)       0           ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 3, 512)       786944      ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 3, 512)       0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 3, 512)       786944      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 3, 512)       0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 3, 512)       0           ['activation_20[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 3, 512)       0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['activation_21[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            3078        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,669,254\n",
      "Trainable params: 3,669,254\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 1: val_loss improved from inf to 0.00141, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 46s 10ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 2/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 2: val_loss improved from 0.00141 to 0.00135, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 3/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 3: val_loss improved from 0.00135 to 0.00120, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 4/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 4: val_loss improved from 0.00120 to 0.00102, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 5/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 5: val_loss did not improve from 0.00102\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 6/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 9.3358e-04 - mse: 9.3358e-04\n",
      "Epoch 6: val_loss improved from 0.00102 to 0.00088, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 9.3346e-04 - mse: 9.3346e-04 - val_loss: 8.7551e-04 - val_mse: 8.7551e-04\n",
      "Epoch 7/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 8.5729e-04 - mse: 8.5729e-04\n",
      "Epoch 7: val_loss improved from 0.00088 to 0.00077, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 8.5736e-04 - mse: 8.5736e-04 - val_loss: 7.7428e-04 - val_mse: 7.7428e-04\n",
      "Epoch 8/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 8.1173e-04 - mse: 8.1173e-04\n",
      "Epoch 8: val_loss did not improve from 0.00077\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 8.1173e-04 - mse: 8.1173e-04 - val_loss: 8.1909e-04 - val_mse: 8.1909e-04\n",
      "Epoch 9/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 7.8267e-04 - mse: 7.8267e-04\n",
      "Epoch 9: val_loss improved from 0.00077 to 0.00077, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 7.8260e-04 - mse: 7.8260e-04 - val_loss: 7.7152e-04 - val_mse: 7.7152e-04\n",
      "Epoch 10/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 7.3680e-04 - mse: 7.3680e-04\n",
      "Epoch 10: val_loss improved from 0.00077 to 0.00067, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 7.3674e-04 - mse: 7.3674e-04 - val_loss: 6.7447e-04 - val_mse: 6.7447e-04\n",
      "Epoch 11/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 7.2566e-04 - mse: 7.2566e-04\n",
      "Epoch 11: val_loss did not improve from 0.00067\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 7.2565e-04 - mse: 7.2565e-04 - val_loss: 7.0756e-04 - val_mse: 7.0756e-04\n",
      "Epoch 12/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 6.8143e-04 - mse: 6.8143e-04\n",
      "Epoch 12: val_loss did not improve from 0.00067\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 6.8139e-04 - mse: 6.8139e-04 - val_loss: 6.9479e-04 - val_mse: 6.9479e-04\n",
      "Epoch 13/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 6.6243e-04 - mse: 6.6243e-04\n",
      "Epoch 13: val_loss improved from 0.00067 to 0.00066, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 6.6245e-04 - mse: 6.6245e-04 - val_loss: 6.5772e-04 - val_mse: 6.5772e-04\n",
      "Epoch 14/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 6.4221e-04 - mse: 6.4221e-04\n",
      "Epoch 14: val_loss improved from 0.00066 to 0.00063, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 6.4222e-04 - mse: 6.4222e-04 - val_loss: 6.3088e-04 - val_mse: 6.3088e-04\n",
      "Epoch 15/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 6.2671e-04 - mse: 6.2671e-04\n",
      "Epoch 15: val_loss improved from 0.00063 to 0.00060, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 6.2664e-04 - mse: 6.2664e-04 - val_loss: 5.9659e-04 - val_mse: 5.9659e-04\n",
      "Epoch 16/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 6.0787e-04 - mse: 6.0787e-04\n",
      "Epoch 16: val_loss did not improve from 0.00060\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 6.0787e-04 - mse: 6.0787e-04 - val_loss: 6.0287e-04 - val_mse: 6.0287e-04\n",
      "Epoch 17/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 5.8827e-04 - mse: 5.8827e-04\n",
      "Epoch 17: val_loss did not improve from 0.00060\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 5.8822e-04 - mse: 5.8822e-04 - val_loss: 6.2840e-04 - val_mse: 6.2840e-04\n",
      "Epoch 18/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 5.7280e-04 - mse: 5.7280e-04\n",
      "Epoch 18: val_loss improved from 0.00060 to 0.00055, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 5.7281e-04 - mse: 5.7281e-04 - val_loss: 5.5469e-04 - val_mse: 5.5469e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 5.6717e-04 - mse: 5.6717e-04\n",
      "Epoch 19: val_loss did not improve from 0.00055\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 5.6717e-04 - mse: 5.6717e-04 - val_loss: 5.7601e-04 - val_mse: 5.7601e-04\n",
      "Epoch 20/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 5.4651e-04 - mse: 5.4651e-04\n",
      "Epoch 20: val_loss improved from 0.00055 to 0.00053, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 5.4651e-04 - mse: 5.4651e-04 - val_loss: 5.2875e-04 - val_mse: 5.2875e-04\n",
      "Epoch 21/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 5.3338e-04 - mse: 5.3338e-04\n",
      "Epoch 21: val_loss did not improve from 0.00053\n",
      "4200/4200 [==============================] - 44s 11ms/step - loss: 5.3338e-04 - mse: 5.3338e-04 - val_loss: 5.4490e-04 - val_mse: 5.4490e-04\n",
      "Epoch 22/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 5.2156e-04 - mse: 5.2156e-04\n",
      "Epoch 22: val_loss did not improve from 0.00053\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 5.2156e-04 - mse: 5.2156e-04 - val_loss: 5.2930e-04 - val_mse: 5.2930e-04\n",
      "Epoch 23/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 5.1177e-04 - mse: 5.1177e-04\n",
      "Epoch 23: val_loss improved from 0.00053 to 0.00050, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 5.1179e-04 - mse: 5.1179e-04 - val_loss: 5.0355e-04 - val_mse: 5.0355e-04\n",
      "Epoch 24/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 4.9544e-04 - mse: 4.9544e-04\n",
      "Epoch 24: val_loss improved from 0.00050 to 0.00048, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 4.9542e-04 - mse: 4.9542e-04 - val_loss: 4.8484e-04 - val_mse: 4.8484e-04\n",
      "Epoch 25/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 4.7891e-04 - mse: 4.7891e-04\n",
      "Epoch 25: val_loss did not improve from 0.00048\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 4.7891e-04 - mse: 4.7891e-04 - val_loss: 5.0208e-04 - val_mse: 5.0208e-04\n",
      "Epoch 26/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 4.7200e-04 - mse: 4.7200e-04\n",
      "Epoch 26: val_loss improved from 0.00048 to 0.00048, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 11ms/step - loss: 4.7200e-04 - mse: 4.7200e-04 - val_loss: 4.7533e-04 - val_mse: 4.7533e-04\n",
      "Epoch 27/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 4.5319e-04 - mse: 4.5319e-04\n",
      "Epoch 27: val_loss improved from 0.00048 to 0.00046, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 4.5317e-04 - mse: 4.5317e-04 - val_loss: 4.5734e-04 - val_mse: 4.5734e-04\n",
      "Epoch 28/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 4.4764e-04 - mse: 4.4764e-04\n",
      "Epoch 28: val_loss did not improve from 0.00046\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 4.4761e-04 - mse: 4.4761e-04 - val_loss: 4.6562e-04 - val_mse: 4.6562e-04\n",
      "Epoch 29/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 4.4444e-04 - mse: 4.4444e-04\n",
      "Epoch 29: val_loss improved from 0.00046 to 0.00045, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 4.4448e-04 - mse: 4.4448e-04 - val_loss: 4.4637e-04 - val_mse: 4.4637e-04\n",
      "Epoch 30/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 4.3121e-04 - mse: 4.3121e-04\n",
      "Epoch 30: val_loss did not improve from 0.00045\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 4.3121e-04 - mse: 4.3121e-04 - val_loss: 4.5349e-04 - val_mse: 4.5349e-04\n",
      "Epoch 31/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 4.1976e-04 - mse: 4.1976e-04\n",
      "Epoch 31: val_loss did not improve from 0.00045\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 4.1971e-04 - mse: 4.1971e-04 - val_loss: 4.4640e-04 - val_mse: 4.4640e-04\n",
      "Epoch 32/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 4.1323e-04 - mse: 4.1323e-04\n",
      "Epoch 32: val_loss improved from 0.00045 to 0.00040, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 4.1326e-04 - mse: 4.1326e-04 - val_loss: 4.0223e-04 - val_mse: 4.0223e-04\n",
      "Epoch 33/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 4.0465e-04 - mse: 4.0465e-04\n",
      "Epoch 33: val_loss did not improve from 0.00040\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 4.0473e-04 - mse: 4.0473e-04 - val_loss: 4.2739e-04 - val_mse: 4.2739e-04\n",
      "Epoch 34/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 3.9536e-04 - mse: 3.9536e-04\n",
      "Epoch 34: val_loss did not improve from 0.00040\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.9534e-04 - mse: 3.9534e-04 - val_loss: 4.0527e-04 - val_mse: 4.0527e-04\n",
      "Epoch 35/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 3.9215e-04 - mse: 3.9215e-04\n",
      "Epoch 35: val_loss did not improve from 0.00040\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.9210e-04 - mse: 3.9210e-04 - val_loss: 4.2031e-04 - val_mse: 4.2031e-04\n",
      "Epoch 36/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 3.8141e-04 - mse: 3.8141e-04\n",
      "Epoch 36: val_loss improved from 0.00040 to 0.00039, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.8141e-04 - mse: 3.8141e-04 - val_loss: 3.8815e-04 - val_mse: 3.8815e-04\n",
      "Epoch 37/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 3.6933e-04 - mse: 3.6933e-04\n",
      "Epoch 37: val_loss improved from 0.00039 to 0.00037, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.6930e-04 - mse: 3.6930e-04 - val_loss: 3.6816e-04 - val_mse: 3.6816e-04\n",
      "Epoch 38/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 3.7384e-04 - mse: 3.7384e-04\n",
      "Epoch 38: val_loss did not improve from 0.00037\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.7384e-04 - mse: 3.7384e-04 - val_loss: 4.1213e-04 - val_mse: 4.1213e-04\n",
      "Epoch 39/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 3.5949e-04 - mse: 3.5949e-04\n",
      "Epoch 39: val_loss improved from 0.00037 to 0.00037, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.5945e-04 - mse: 3.5945e-04 - val_loss: 3.6772e-04 - val_mse: 3.6772e-04\n",
      "Epoch 40/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 3.5461e-04 - mse: 3.5461e-04\n",
      "Epoch 40: val_loss improved from 0.00037 to 0.00036, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.5461e-04 - mse: 3.5461e-04 - val_loss: 3.6047e-04 - val_mse: 3.6047e-04\n",
      "Epoch 41/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 3.4514e-04 - mse: 3.4514e-04\n",
      "Epoch 41: val_loss did not improve from 0.00036\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.4509e-04 - mse: 3.4509e-04 - val_loss: 3.6509e-04 - val_mse: 3.6509e-04\n",
      "Epoch 42/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 3.4298e-04 - mse: 3.4298e-04\n",
      "Epoch 42: val_loss improved from 0.00036 to 0.00036, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.4290e-04 - mse: 3.4290e-04 - val_loss: 3.5755e-04 - val_mse: 3.5755e-04\n",
      "Epoch 43/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 3.4159e-04 - mse: 3.4159e-04\n",
      "Epoch 43: val_loss improved from 0.00036 to 0.00035, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.4159e-04 - mse: 3.4159e-04 - val_loss: 3.4804e-04 - val_mse: 3.4804e-04\n",
      "Epoch 44/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 3.3198e-04 - mse: 3.3198e-04\n",
      "Epoch 44: val_loss improved from 0.00035 to 0.00034, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.3198e-04 - mse: 3.3198e-04 - val_loss: 3.3670e-04 - val_mse: 3.3670e-04\n",
      "Epoch 45/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 3.3323e-04 - mse: 3.3323e-04\n",
      "Epoch 45: val_loss did not improve from 0.00034\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 3.3321e-04 - mse: 3.3321e-04 - val_loss: 3.7726e-04 - val_mse: 3.7726e-04\n",
      "Epoch 46/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 3.2703e-04 - mse: 3.2703e-04\n",
      "Epoch 46: val_loss did not improve from 0.00034\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 3.2703e-04 - mse: 3.2703e-04 - val_loss: 3.6192e-04 - val_mse: 3.6192e-04\n",
      "Epoch 47/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 3.1693e-04 - mse: 3.1693e-04\n",
      "Epoch 47: val_loss improved from 0.00034 to 0.00031, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 3.1689e-04 - mse: 3.1689e-04 - val_loss: 3.1375e-04 - val_mse: 3.1375e-04\n",
      "Epoch 48/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 3.0865e-04 - mse: 3.0865e-04\n",
      "Epoch 48: val_loss did not improve from 0.00031\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 3.0865e-04 - mse: 3.0865e-04 - val_loss: 4.0035e-04 - val_mse: 4.0035e-04\n",
      "Epoch 49/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 3.0864e-04 - mse: 3.0864e-04\n",
      "Epoch 49: val_loss did not improve from 0.00031\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 3.0864e-04 - mse: 3.0864e-04 - val_loss: 3.2267e-04 - val_mse: 3.2267e-04\n",
      "Epoch 50/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 3.0143e-04 - mse: 3.0143e-04\n",
      "Epoch 50: val_loss improved from 0.00031 to 0.00031, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 3.0143e-04 - mse: 3.0143e-04 - val_loss: 3.1048e-04 - val_mse: 3.1048e-04\n",
      "Epoch 51/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 3.0471e-04 - mse: 3.0471e-04\n",
      "Epoch 51: val_loss did not improve from 0.00031\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 3.0470e-04 - mse: 3.0470e-04 - val_loss: 3.1455e-04 - val_mse: 3.1455e-04\n",
      "Epoch 52/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 2.9339e-04 - mse: 2.9339e-04\n",
      "Epoch 52: val_loss did not improve from 0.00031\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.9339e-04 - mse: 2.9339e-04 - val_loss: 3.2649e-04 - val_mse: 3.2649e-04\n",
      "Epoch 53/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 2.8605e-04 - mse: 2.8605e-04\n",
      "Epoch 53: val_loss did not improve from 0.00031\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.8613e-04 - mse: 2.8613e-04 - val_loss: 3.3912e-04 - val_mse: 3.3912e-04\n",
      "Epoch 54/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 2.8806e-04 - mse: 2.8806e-04\n",
      "Epoch 54: val_loss improved from 0.00031 to 0.00030, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.8804e-04 - mse: 2.8804e-04 - val_loss: 2.9825e-04 - val_mse: 2.9825e-04\n",
      "Epoch 55/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 2.8535e-04 - mse: 2.8535e-04\n",
      "Epoch 55: val_loss did not improve from 0.00030\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.8547e-04 - mse: 2.8547e-04 - val_loss: 3.7871e-04 - val_mse: 3.7871e-04\n",
      "Epoch 56/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 2.7750e-04 - mse: 2.7750e-04\n",
      "Epoch 56: val_loss improved from 0.00030 to 0.00029, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.7752e-04 - mse: 2.7752e-04 - val_loss: 2.9146e-04 - val_mse: 2.9146e-04\n",
      "Epoch 57/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 2.8241e-04 - mse: 2.8241e-04\n",
      "Epoch 57: val_loss did not improve from 0.00029\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.8239e-04 - mse: 2.8239e-04 - val_loss: 2.9567e-04 - val_mse: 2.9567e-04\n",
      "Epoch 58/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 2.6490e-04 - mse: 2.6490e-04\n",
      "Epoch 58: val_loss did not improve from 0.00029\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.6487e-04 - mse: 2.6487e-04 - val_loss: 3.0038e-04 - val_mse: 3.0038e-04\n",
      "Epoch 59/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 2.7228e-04 - mse: 2.7228e-04\n",
      "Epoch 59: val_loss improved from 0.00029 to 0.00029, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.7227e-04 - mse: 2.7227e-04 - val_loss: 2.8947e-04 - val_mse: 2.8947e-04\n",
      "Epoch 60/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 2.6961e-04 - mse: 2.6961e-04\n",
      "Epoch 60: val_loss did not improve from 0.00029\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.6960e-04 - mse: 2.6960e-04 - val_loss: 3.0282e-04 - val_mse: 3.0282e-04\n",
      "Epoch 61/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 2.5918e-04 - mse: 2.5918e-04\n",
      "Epoch 61: val_loss did not improve from 0.00029\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.5916e-04 - mse: 2.5916e-04 - val_loss: 2.9502e-04 - val_mse: 2.9502e-04\n",
      "Epoch 62/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 2.5701e-04 - mse: 2.5701e-04\n",
      "Epoch 62: val_loss improved from 0.00029 to 0.00028, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.5701e-04 - mse: 2.5701e-04 - val_loss: 2.8000e-04 - val_mse: 2.8000e-04\n",
      "Epoch 63/500\n",
      "4194/4200 [============================>.] - ETA: 0s - loss: 2.5735e-04 - mse: 2.5735e-04\n",
      "Epoch 63: val_loss improved from 0.00028 to 0.00027, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.5731e-04 - mse: 2.5731e-04 - val_loss: 2.6739e-04 - val_mse: 2.6739e-04\n",
      "Epoch 64/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 2.5013e-04 - mse: 2.5013e-04\n",
      "Epoch 64: val_loss improved from 0.00027 to 0.00026, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.5013e-04 - mse: 2.5013e-04 - val_loss: 2.6317e-04 - val_mse: 2.6317e-04\n",
      "Epoch 65/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 2.5064e-04 - mse: 2.5064e-04\n",
      "Epoch 65: val_loss did not improve from 0.00026\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.5064e-04 - mse: 2.5064e-04 - val_loss: 2.7372e-04 - val_mse: 2.7372e-04\n",
      "Epoch 66/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 2.4512e-04 - mse: 2.4512e-04\n",
      "Epoch 66: val_loss did not improve from 0.00026\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.4512e-04 - mse: 2.4512e-04 - val_loss: 3.5291e-04 - val_mse: 3.5291e-04\n",
      "Epoch 67/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 2.4864e-04 - mse: 2.4864e-04\n",
      "Epoch 67: val_loss did not improve from 0.00026\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.4858e-04 - mse: 2.4858e-04 - val_loss: 2.9073e-04 - val_mse: 2.9073e-04\n",
      "Epoch 68/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 2.4237e-04 - mse: 2.4237e-04\n",
      "Epoch 68: val_loss did not improve from 0.00026\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.4239e-04 - mse: 2.4239e-04 - val_loss: 2.6882e-04 - val_mse: 2.6882e-04\n",
      "Epoch 69/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 2.3585e-04 - mse: 2.3585e-04\n",
      "Epoch 69: val_loss did not improve from 0.00026\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.3584e-04 - mse: 2.3584e-04 - val_loss: 2.7388e-04 - val_mse: 2.7388e-04\n",
      "Epoch 70/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 2.4038e-04 - mse: 2.4038e-04\n",
      "Epoch 70: val_loss did not improve from 0.00026\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.4037e-04 - mse: 2.4037e-04 - val_loss: 2.9311e-04 - val_mse: 2.9311e-04\n",
      "Epoch 71/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 2.3235e-04 - mse: 2.3235e-04\n",
      "Epoch 71: val_loss did not improve from 0.00026\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.3233e-04 - mse: 2.3233e-04 - val_loss: 2.6600e-04 - val_mse: 2.6600e-04\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4195/4200 [============================>.] - ETA: 0s - loss: 2.2888e-04 - mse: 2.2888e-04\n",
      "Epoch 72: val_loss improved from 0.00026 to 0.00025, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.2888e-04 - mse: 2.2888e-04 - val_loss: 2.5445e-04 - val_mse: 2.5445e-04\n",
      "Epoch 73/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 2.3263e-04 - mse: 2.3263e-04\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.3262e-04 - mse: 2.3262e-04 - val_loss: 2.6360e-04 - val_mse: 2.6360e-04\n",
      "Epoch 74/500\n",
      "4194/4200 [============================>.] - ETA: 0s - loss: 2.2958e-04 - mse: 2.2958e-04\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.2957e-04 - mse: 2.2957e-04 - val_loss: 2.5718e-04 - val_mse: 2.5718e-04\n",
      "Epoch 75/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 2.2844e-04 - mse: 2.2844e-04\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.2843e-04 - mse: 2.2843e-04 - val_loss: 2.5600e-04 - val_mse: 2.5600e-04\n",
      "Epoch 76/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 2.2971e-04 - mse: 2.2971e-04\n",
      "Epoch 76: val_loss improved from 0.00025 to 0.00025, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.2968e-04 - mse: 2.2968e-04 - val_loss: 2.5282e-04 - val_mse: 2.5282e-04\n",
      "Epoch 77/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 2.2083e-04 - mse: 2.2083e-04\n",
      "Epoch 77: val_loss improved from 0.00025 to 0.00025, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.2083e-04 - mse: 2.2083e-04 - val_loss: 2.4728e-04 - val_mse: 2.4728e-04\n",
      "Epoch 78/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 2.2323e-04 - mse: 2.2323e-04\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.2334e-04 - mse: 2.2334e-04 - val_loss: 2.8728e-04 - val_mse: 2.8728e-04\n",
      "Epoch 79/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 2.1655e-04 - mse: 2.1655e-04\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.1655e-04 - mse: 2.1655e-04 - val_loss: 2.6851e-04 - val_mse: 2.6851e-04\n",
      "Epoch 80/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 2.2285e-04 - mse: 2.2285e-04\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.2284e-04 - mse: 2.2284e-04 - val_loss: 2.4840e-04 - val_mse: 2.4840e-04\n",
      "Epoch 81/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 2.0999e-04 - mse: 2.0999e-04\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.0999e-04 - mse: 2.0999e-04 - val_loss: 2.6701e-04 - val_mse: 2.6701e-04\n",
      "Epoch 82/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 2.1398e-04 - mse: 2.1398e-04\n",
      "Epoch 82: val_loss improved from 0.00025 to 0.00024, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.1397e-04 - mse: 2.1397e-04 - val_loss: 2.4417e-04 - val_mse: 2.4417e-04\n",
      "Epoch 83/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 2.1682e-04 - mse: 2.1682e-04\n",
      "Epoch 83: val_loss did not improve from 0.00024\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.1680e-04 - mse: 2.1680e-04 - val_loss: 2.5174e-04 - val_mse: 2.5174e-04\n",
      "Epoch 84/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 2.0886e-04 - mse: 2.0886e-04\n",
      "Epoch 84: val_loss did not improve from 0.00024\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.0911e-04 - mse: 2.0911e-04 - val_loss: 2.6727e-04 - val_mse: 2.6727e-04\n",
      "Epoch 85/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 2.0499e-04 - mse: 2.0499e-04\n",
      "Epoch 85: val_loss did not improve from 0.00024\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.0499e-04 - mse: 2.0499e-04 - val_loss: 2.7482e-04 - val_mse: 2.7482e-04\n",
      "Epoch 86/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 2.0204e-04 - mse: 2.0204e-04\n",
      "Epoch 86: val_loss improved from 0.00024 to 0.00024, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 2.0204e-04 - mse: 2.0204e-04 - val_loss: 2.3566e-04 - val_mse: 2.3566e-04\n",
      "Epoch 87/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 1.9983e-04 - mse: 1.9983e-04\n",
      "Epoch 87: val_loss did not improve from 0.00024\n",
      "4200/4200 [==============================] - 43s 10ms/step - loss: 1.9983e-04 - mse: 1.9983e-04 - val_loss: 2.6610e-04 - val_mse: 2.6610e-04\n",
      "Epoch 88/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 2.0749e-04 - mse: 2.0749e-04\n",
      "Epoch 88: val_loss did not improve from 0.00024\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 2.0750e-04 - mse: 2.0750e-04 - val_loss: 2.4282e-04 - val_mse: 2.4282e-04\n",
      "Epoch 89/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 1.9972e-04 - mse: 1.9972e-04\n",
      "Epoch 89: val_loss did not improve from 0.00024\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.9972e-04 - mse: 1.9972e-04 - val_loss: 2.4703e-04 - val_mse: 2.4703e-04\n",
      "Epoch 90/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 2.0041e-04 - mse: 2.0041e-04\n",
      "Epoch 90: val_loss improved from 0.00024 to 0.00023, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 2.0039e-04 - mse: 2.0039e-04 - val_loss: 2.3092e-04 - val_mse: 2.3092e-04\n",
      "Epoch 91/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 1.9446e-04 - mse: 1.9446e-04\n",
      "Epoch 91: val_loss did not improve from 0.00023\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.9445e-04 - mse: 1.9445e-04 - val_loss: 2.4537e-04 - val_mse: 2.4537e-04\n",
      "Epoch 92/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 1.9490e-04 - mse: 1.9490e-04\n",
      "Epoch 92: val_loss did not improve from 0.00023\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.9491e-04 - mse: 1.9491e-04 - val_loss: 3.1246e-04 - val_mse: 3.1246e-04\n",
      "Epoch 93/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 1.9045e-04 - mse: 1.9045e-04\n",
      "Epoch 93: val_loss did not improve from 0.00023\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.9045e-04 - mse: 1.9045e-04 - val_loss: 2.5013e-04 - val_mse: 2.5013e-04\n",
      "Epoch 94/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 1.9618e-04 - mse: 1.9618e-04\n",
      "Epoch 94: val_loss did not improve from 0.00023\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.9620e-04 - mse: 1.9620e-04 - val_loss: 2.8328e-04 - val_mse: 2.8328e-04\n",
      "Epoch 95/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 1.9449e-04 - mse: 1.9449e-04\n",
      "Epoch 95: val_loss improved from 0.00023 to 0.00023, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.9447e-04 - mse: 1.9447e-04 - val_loss: 2.2804e-04 - val_mse: 2.2804e-04\n",
      "Epoch 96/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 1.8986e-04 - mse: 1.8986e-04\n",
      "Epoch 96: val_loss did not improve from 0.00023\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.8985e-04 - mse: 1.8985e-04 - val_loss: 2.3656e-04 - val_mse: 2.3656e-04\n",
      "Epoch 97/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 1.8605e-04 - mse: 1.8605e-04\n",
      "Epoch 97: val_loss improved from 0.00023 to 0.00022, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.8606e-04 - mse: 1.8606e-04 - val_loss: 2.2479e-04 - val_mse: 2.2479e-04\n",
      "Epoch 98/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 1.8030e-04 - mse: 1.8030e-04\n",
      "Epoch 98: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.8030e-04 - mse: 1.8030e-04 - val_loss: 2.2785e-04 - val_mse: 2.2785e-04\n",
      "Epoch 99/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 1.8611e-04 - mse: 1.8611e-04\n",
      "Epoch 99: val_loss improved from 0.00022 to 0.00022, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.8608e-04 - mse: 1.8608e-04 - val_loss: 2.2247e-04 - val_mse: 2.2247e-04\n",
      "Epoch 100/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 1.8008e-04 - mse: 1.8008e-04\n",
      "Epoch 100: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.8011e-04 - mse: 1.8011e-04 - val_loss: 2.5778e-04 - val_mse: 2.5778e-04\n",
      "Epoch 101/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 1.8331e-04 - mse: 1.8331e-04\n",
      "Epoch 101: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.8331e-04 - mse: 1.8331e-04 - val_loss: 2.2909e-04 - val_mse: 2.2909e-04\n",
      "Epoch 102/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 1.8400e-04 - mse: 1.8400e-04\n",
      "Epoch 102: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.8399e-04 - mse: 1.8399e-04 - val_loss: 2.3909e-04 - val_mse: 2.3909e-04\n",
      "Epoch 103/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 1.8276e-04 - mse: 1.8276e-04\n",
      "Epoch 103: val_loss improved from 0.00022 to 0.00022, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.8275e-04 - mse: 1.8275e-04 - val_loss: 2.1661e-04 - val_mse: 2.1661e-04\n",
      "Epoch 104/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 1.7897e-04 - mse: 1.7897e-04\n",
      "Epoch 104: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.7897e-04 - mse: 1.7897e-04 - val_loss: 2.3435e-04 - val_mse: 2.3435e-04\n",
      "Epoch 105/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 1.7759e-04 - mse: 1.7759e-04\n",
      "Epoch 105: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.7759e-04 - mse: 1.7759e-04 - val_loss: 2.3856e-04 - val_mse: 2.3856e-04\n",
      "Epoch 106/500\n",
      "4196/4200 [============================>.] - ETA: 0s - loss: 1.7153e-04 - mse: 1.7153e-04\n",
      "Epoch 106: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.7153e-04 - mse: 1.7153e-04 - val_loss: 2.4444e-04 - val_mse: 2.4444e-04\n",
      "Epoch 107/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 1.8012e-04 - mse: 1.8012e-04\n",
      "Epoch 107: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.8011e-04 - mse: 1.8011e-04 - val_loss: 2.4467e-04 - val_mse: 2.4467e-04\n",
      "Epoch 108/500\n",
      "4198/4200 [============================>.] - ETA: 0s - loss: 1.6808e-04 - mse: 1.6808e-04\n",
      "Epoch 108: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.6810e-04 - mse: 1.6810e-04 - val_loss: 2.2182e-04 - val_mse: 2.2182e-04\n",
      "Epoch 109/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 1.6705e-04 - mse: 1.6705e-04\n",
      "Epoch 109: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.6705e-04 - mse: 1.6705e-04 - val_loss: 2.2101e-04 - val_mse: 2.2101e-04\n",
      "Epoch 110/500\n",
      "4195/4200 [============================>.] - ETA: 0s - loss: 1.6652e-04 - mse: 1.6652e-04\n",
      "Epoch 110: val_loss improved from 0.00022 to 0.00022, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.6651e-04 - mse: 1.6651e-04 - val_loss: 2.1544e-04 - val_mse: 2.1544e-04\n",
      "Epoch 111/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 1.7020e-04 - mse: 1.7020e-04\n",
      "Epoch 111: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.7020e-04 - mse: 1.7020e-04 - val_loss: 2.1654e-04 - val_mse: 2.1654e-04\n",
      "Epoch 112/500\n",
      "4199/4200 [============================>.] - ETA: 0s - loss: 1.7113e-04 - mse: 1.7113e-04\n",
      "Epoch 112: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.7111e-04 - mse: 1.7111e-04 - val_loss: 2.1971e-04 - val_mse: 2.1971e-04\n",
      "Epoch 113/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 1.7132e-04 - mse: 1.7132e-04\n",
      "Epoch 113: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.7132e-04 - mse: 1.7132e-04 - val_loss: 3.7061e-04 - val_mse: 3.7061e-04\n",
      "Epoch 114/500\n",
      "4200/4200 [==============================] - ETA: 0s - loss: 1.6964e-04 - mse: 1.6964e-04\n",
      "Epoch 114: val_loss did not improve from 0.00022\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.6964e-04 - mse: 1.6964e-04 - val_loss: 2.1874e-04 - val_mse: 2.1874e-04\n",
      "Epoch 115/500\n",
      "4197/4200 [============================>.] - ETA: 0s - loss: 1.6028e-04 - mse: 1.6028e-04\n",
      "Epoch 115: val_loss improved from 0.00022 to 0.00021, saving model to Saved_Model.h5\n",
      "4200/4200 [==============================] - 44s 10ms/step - loss: 1.6028e-04 - mse: 1.6028e-04 - val_loss: 2.1019e-04 - val_mse: 2.1019e-04\n",
      "Epoch 116/500\n",
      "2941/4200 [====================>.........] - ETA: 11s - loss: 1.6103e-04 - mse: 1.6103e-04"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Training Process\n",
    "SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(SIDatasetTrain[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "#     coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "#     coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "#     coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "#     coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "#     coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "SIData_filtered = np.zeros(SIDatasetTrain.shape)\n",
    "for i in range(89):\n",
    "    SIData_filtered[:, i] = pywt.waverec(SIDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "\n",
    "for i in range(len(SIData_filtered)):\n",
    "    SIData_filtered[i][0] = SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "    iter += 1\n",
    "\n",
    "# Scale the smart insole data\n",
    "minInsole = SIData_filtered.min()\n",
    "maxInsole = SIData_filtered.max()\n",
    "smart_insole_data_scaled = (SIData_filtered - minInsole) / ( maxInsole - minInsole )\n",
    "\n",
    "# Scale the force plate data\n",
    "minForcePlateFx = FPDatasetTrain[:,0].min()\n",
    "maxForcePlateFx = FPDatasetTrain[:,0].max()\n",
    "minForcePlateFy = FPDatasetTrain[:,1].min()\n",
    "maxForcePlateFy = FPDatasetTrain[:,1].max()\n",
    "minForcePlateFz = FPDatasetTrain[:,2].min()\n",
    "maxForcePlateFz = FPDatasetTrain[:,2].max()\n",
    "minForcePlateMx = FPDatasetTrain[:,3].min()\n",
    "maxForcePlateMx = FPDatasetTrain[:,3].max()\n",
    "minForcePlateMy = FPDatasetTrain[:,4].min()\n",
    "maxForcePlateMy = FPDatasetTrain[:,4].max()\n",
    "minForcePlateMz = FPDatasetTrain[:,5].min()\n",
    "maxForcePlateMz = FPDatasetTrain[:,5].max()\n",
    "force_plate_data_scaled_Fx = (FPDatasetTrain[:,0] - minForcePlateFx) / ( maxForcePlateFx - minForcePlateFx )\n",
    "force_plate_data_scaled_Fy = (FPDatasetTrain[:,1] - minForcePlateFy) / ( maxForcePlateFy - minForcePlateFy )\n",
    "force_plate_data_scaled_Fz = (FPDatasetTrain[:,2] - minForcePlateFz) / ( maxForcePlateFz - minForcePlateFz )\n",
    "force_plate_data_scaled_Mx = (FPDatasetTrain[:,3] - minForcePlateMx) / ( maxForcePlateMx - minForcePlateMx )\n",
    "force_plate_data_scaled_My = (FPDatasetTrain[:,4] - minForcePlateMy) / ( maxForcePlateMy - minForcePlateMy )\n",
    "force_plate_data_scaled_Mz = (FPDatasetTrain[:,5] - minForcePlateMz) / ( maxForcePlateMz - minForcePlateMz )\n",
    "force_plate_data_scaled = np.concatenate((force_plate_data_scaled_Fx.reshape(-1,1), force_plate_data_scaled_Fy.reshape(-1,1),\n",
    "                                          force_plate_data_scaled_Fz.reshape(-1,1), force_plate_data_scaled_Mx.reshape(-1,1), \n",
    "                                          force_plate_data_scaled_My.reshape(-1,1), force_plate_data_scaled_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "#Spliting Data\n",
    "sample_size = smart_insole_data_scaled.shape[0] # number of samples in train set\n",
    "time_steps  = smart_insole_data_scaled.shape[1] # number of features in train set\n",
    "input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "train_data_reshaped = smart_insole_data_scaled.reshape(sample_size,time_steps,input_dimension)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_reshaped, force_plate_data_scaled, test_size=0.20, random_state=2)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n",
    "\n",
    "\"Configurations for ResNet in Regression Mode\"\n",
    "length = X_train.shape[1]   # Number of Features (or length of the signal)\n",
    "model_width = 64           # Number of Filter or Kernel in the Input Layer\n",
    "num_channel = 1             # Number of Input Channels\n",
    "problem_type = 'Regression' # Regression or Classification\n",
    "output_number = 6           # Number of Outputs in the Regression Mode\n",
    "\n",
    "Regression_Model = ResNet(length, num_channel, model_width, problem_type=problem_type, \n",
    "                          output_nums=output_number).ResNet18()\n",
    "Regression_Model.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics= ['mse']) # Compile Model\n",
    "\n",
    "Regression_Model.summary()\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=30, mode='min'), ModelCheckpoint('Saved_Model.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
    "history = Regression_Model.fit(X_train, y_train, epochs=500, batch_size=32, verbose=1, validation_split=0.2, shuffle=True, callbacks=callbacks)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.show()\n",
    "plt.savefig('Loss Result.png')\n",
    "\n",
    "#Evaluate Model\n",
    "Regression_Model.evaluate(train_data_reshaped[:], force_plate_data_scaled[:])\n",
    "pred = Regression_Model.predict(train_data_reshaped[:])\n",
    "\n",
    "print('MSE: ',mean_squared_error(force_plate_data_scaled[:], pred))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(force_plate_data_scaled[:], pred)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(force_plate_data_scaled[:], pred))\n",
    "\n",
    "# Inverse transform the predictions and actual values\n",
    "y_real_Fx = (force_plate_data_scaled[:,0] * (maxForcePlateFx - minForcePlateFx)) + minForcePlateFx\n",
    "y_real_Fy = (force_plate_data_scaled[:,1] * (maxForcePlateFy - minForcePlateFy)) + minForcePlateFy\n",
    "y_real_Fz = (force_plate_data_scaled[:,2] * (maxForcePlateFz - minForcePlateFz)) + minForcePlateFz\n",
    "y_real_Mx = (force_plate_data_scaled[:,3] * (maxForcePlateMx - minForcePlateMx)) + minForcePlateMx\n",
    "y_real_My = (force_plate_data_scaled[:,4] * (maxForcePlateMy - minForcePlateMy)) + minForcePlateMy\n",
    "y_real_Mz = (force_plate_data_scaled[:,5] * (maxForcePlateMz - minForcePlateMz)) + minForcePlateMz\n",
    "y_real = np.concatenate((y_real_Fx.reshape(-1,1), y_real_Fy.reshape(-1,1), y_real_Fz.reshape(-1,1),\n",
    "                         y_real_Mx.reshape(-1,1), y_real_My.reshape(-1,1), y_real_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "y_pred_Fx = (pred[:,0] * (maxForcePlateFx - minForcePlateFx)) + minForcePlateFx\n",
    "y_pred_Fy = (pred[:,1] * (maxForcePlateFy - minForcePlateFy)) + minForcePlateFy\n",
    "y_pred_Fz = (pred[:,2] * (maxForcePlateFz - minForcePlateFz)) + minForcePlateFz\n",
    "y_pred_Mx = (pred[:,3] * (maxForcePlateMx - minForcePlateMx)) + minForcePlateMx\n",
    "y_pred_My = (pred[:,4] * (maxForcePlateMy - minForcePlateMy)) + minForcePlateMy\n",
    "y_pred_Mz = (pred[:,5] * (maxForcePlateMz - minForcePlateMz)) + minForcePlateMz\n",
    "y_pred = np.concatenate((y_pred_Fx.reshape(-1,1), y_pred_Fy.reshape(-1,1), y_pred_Fz.reshape(-1,1),\n",
    "                         y_pred_Mx.reshape(-1,1), y_pred_My.reshape(-1,1), y_pred_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "\n",
    "print('MSE: ',mean_squared_error(y_real, y_pred))\n",
    "print('RMSE: ',math.sqrt(mean_squared_error(y_real, y_pred)))\n",
    "print('Coefficient of determination (r2 Score): ', r2_score(y_real, y_pred))\n",
    "\n",
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,y_real[0:3000,i],color='red')\n",
    "    plt.plot(x,y_pred[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "tf.keras.models.save_model(Regression_Model, '1ouput.h5')\n",
    "#End Training Process\n",
    "\n",
    "# Load Model to Predict Real Data\n",
    "modelCoy = tf.keras.models.load_model('1ouput.h5')\n",
    "\n",
    "SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(SIDatasetTest[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "#     coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "#     coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "#     coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "#     coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "#     coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_SIData_filtered = np.zeros(SIDatasetTest.shape)\n",
    "for i in range(89):\n",
    "    Test_SIData_filtered[:, i] = pywt.waverec(SIDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    Test_SIData_filtered[i][0] = Test_SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "    iter += 1\n",
    "\n",
    "Test_smart_insole_data_scaled = (Test_SIData_filtered - minInsole) / ( maxInsole - minInsole )    \n",
    "Test_force_plate_data_scaled_Fx = (FPDatasetTest[:,0] - minForcePlateFx) / ( maxForcePlateFx - minForcePlateFx )\n",
    "Test_force_plate_data_scaled_Fy = (FPDatasetTest[:,1] - minForcePlateFy) / ( maxForcePlateFy - minForcePlateFy )\n",
    "Test_force_plate_data_scaled_Fz = (FPDatasetTest[:,2] - minForcePlateFz) / ( maxForcePlateFz - minForcePlateFz )\n",
    "Test_force_plate_data_scaled_Mx = (FPDatasetTest[:,3] - minForcePlateMx) / ( maxForcePlateMx - minForcePlateMx )\n",
    "Test_force_plate_data_scaled_My = (FPDatasetTest[:,4] - minForcePlateMy) / ( maxForcePlateMy - minForcePlateMy )\n",
    "Test_force_plate_data_scaled_Mz = (FPDatasetTest[:,5] - minForcePlateMz) / ( maxForcePlateMz - minForcePlateMz )\n",
    "Test_force_plate_data_scaled = np.concatenate((Test_force_plate_data_scaled_Fx.reshape(-1,1), Test_force_plate_data_scaled_Fy.reshape(-1,1), \n",
    "                                               Test_force_plate_data_scaled_Fz.reshape(-1,1), Test_force_plate_data_scaled_Mx.reshape(-1,1), \n",
    "                                               Test_force_plate_data_scaled_My.reshape(-1,1), Test_force_plate_data_scaled_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "Test_sample_size = Test_smart_insole_data_scaled.shape[0]\n",
    "Test_time_steps  = Test_smart_insole_data_scaled.shape[1]\n",
    "Test_input_dimension = 1\n",
    "\n",
    "Test_train_data_reshaped = Test_smart_insole_data_scaled.reshape(Test_sample_size,Test_time_steps,Test_input_dimension)\n",
    "\n",
    "modelCoy.evaluate(Test_train_data_reshaped, Test_force_plate_data_scaled)\n",
    "Test_Pred = modelCoy.predict(Test_train_data_reshaped)\n",
    "\n",
    "Test_y_real_Fx = (Test_force_plate_data_scaled[:,0] * (maxForcePlateFx - minForcePlateFx)) + minForcePlateFx\n",
    "Test_y_real_Fy = (Test_force_plate_data_scaled[:,1] * (maxForcePlateFy - minForcePlateFy)) + minForcePlateFy\n",
    "Test_y_real_Fz = (Test_force_plate_data_scaled[:,2] * (maxForcePlateFz - minForcePlateFz)) + minForcePlateFz\n",
    "Test_y_real_Mx = (Test_force_plate_data_scaled[:,3] * (maxForcePlateMx - minForcePlateMx)) + minForcePlateMx\n",
    "Test_y_real_My = (Test_force_plate_data_scaled[:,4] * (maxForcePlateMy - minForcePlateMy)) + minForcePlateMy\n",
    "Test_y_real_Mz = (Test_force_plate_data_scaled[:,5] * (maxForcePlateMz - minForcePlateMz)) + minForcePlateMz\n",
    "Test_y_real = np.concatenate((Test_y_real_Fx.reshape(-1,1), Test_y_real_Fy.reshape(-1,1), Test_y_real_Fz.reshape(-1,1),\n",
    "                              Test_y_real_Mx.reshape(-1,1), Test_y_real_My.reshape(-1,1), Test_y_real_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "Test_y_pred_Fx = (Test_Pred[:,0] * (maxForcePlateFx - minForcePlateFx)) + minForcePlateFx\n",
    "Test_y_pred_Fy = (Test_Pred[:,1] * (maxForcePlateFy - minForcePlateFy)) + minForcePlateFy\n",
    "Test_y_pred_Fz = (Test_Pred[:,2] * (maxForcePlateFz - minForcePlateFz)) + minForcePlateFz\n",
    "Test_y_pred_Mx = (Test_Pred[:,3] * (maxForcePlateMx - minForcePlateMx)) + minForcePlateMx\n",
    "Test_y_pred_My = (Test_Pred[:,4] * (maxForcePlateMy - minForcePlateMy)) + minForcePlateMy\n",
    "Test_y_pred_Mz = (Test_Pred[:,5] * (maxForcePlateMz - minForcePlateMz)) + minForcePlateMz\n",
    "Test_y_pred = np.concatenate((Test_y_pred_Fx.reshape(-1,1), Test_y_pred_Fy.reshape(-1,1), Test_y_pred_Fz.reshape(-1,1),\n",
    "                              Test_y_pred_Mx.reshape(-1,1), Test_y_pred_My.reshape(-1,1), Test_y_pred_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "x=[]\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_y_real[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_y_pred[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('ResNet Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "# please help me make normalization process manualy dont use the sickit-learn on this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=[]\n",
    "colors=['red','green','brown','teal','gray','black','maroon','orange','purple']\n",
    "colors2=['green','red','orange','black','maroon','teal','blue','gray','brown']\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,y_real[200000:203000,i],color='red')\n",
    "    plt.plot(x,y_pred[200000:203000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('Resnet Regression (Training Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted Value'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load Model to Predict Real Data\n",
    "SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(SIDatasetTest[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "#     coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "#     coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "#     coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "#     coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "#     coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_SIData_filtered = np.zeros(SIDatasetTest.shape)\n",
    "for i in range(89):\n",
    "    Test_SIData_filtered[:, i] = pywt.waverec(SIDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    Test_SIData_filtered[i][0] = Test_SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "    iter += 1\n",
    "\n",
    "Test_smart_insole_data_scaled = (Test_SIData_filtered - minInsole) / ( maxInsole - minInsole )   \n",
    "Test_force_plate_data_scaled_Fx = (FPDatasetTest[:,0] - minForcePlateFx) / ( maxForcePlateFx - minForcePlateFx )\n",
    "Test_force_plate_data_scaled_Fy = (FPDatasetTest[:,1] - minForcePlateFy) / ( maxForcePlateFy - minForcePlateFy )\n",
    "Test_force_plate_data_scaled_Fz = (FPDatasetTest[:,2] - minForcePlateFz) / ( maxForcePlateFz - minForcePlateFz )\n",
    "Test_force_plate_data_scaled_Mx = (FPDatasetTest[:,3] - minForcePlateMx) / ( maxForcePlateMx - minForcePlateMx )\n",
    "Test_force_plate_data_scaled_My = (FPDatasetTest[:,4] - minForcePlateMy) / ( maxForcePlateMy - minForcePlateMy )\n",
    "Test_force_plate_data_scaled_Mz = (FPDatasetTest[:,5] - minForcePlateMz) / ( maxForcePlateMz - minForcePlateMz )\n",
    "Test_force_plate_data_scaled = np.concatenate((Test_force_plate_data_scaled_Fx.reshape(-1,1), Test_force_plate_data_scaled_Fy.reshape(-1,1), \n",
    "                                               Test_force_plate_data_scaled_Fz.reshape(-1,1), Test_force_plate_data_scaled_Mx.reshape(-1,1), \n",
    "                                               Test_force_plate_data_scaled_My.reshape(-1,1), Test_force_plate_data_scaled_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "Test_sample_size = Test_smart_insole_data_scaled.shape[0]\n",
    "Test_time_steps  = Test_smart_insole_data_scaled.shape[1]\n",
    "Test_input_dimension = 1\n",
    "\n",
    "Test_train_data_reshaped = Test_smart_insole_data_scaled.reshape(Test_sample_size,Test_time_steps,Test_input_dimension)\n",
    "\n",
    "modelCoy.evaluate(Test_train_data_reshaped, Test_force_plate_data_scaled)\n",
    "Test_Pred = modelCoy.predict(Test_train_data_reshaped)\n",
    "\n",
    "Test_y_real_Fx = (Test_force_plate_data_scaled[:,0] * (maxForcePlateFx - minForcePlateFx)) + minForcePlateFx\n",
    "Test_y_real_Fy = (Test_force_plate_data_scaled[:,1] * (maxForcePlateFy - minForcePlateFy)) + minForcePlateFy\n",
    "Test_y_real_Fz = (Test_force_plate_data_scaled[:,2] * (maxForcePlateFz - minForcePlateFz)) + minForcePlateFz\n",
    "Test_y_real_Mx = (Test_force_plate_data_scaled[:,3] * (maxForcePlateMx - minForcePlateMx)) + minForcePlateMx\n",
    "Test_y_real_My = (Test_force_plate_data_scaled[:,4] * (maxForcePlateMy - minForcePlateMy)) + minForcePlateMy\n",
    "Test_y_real_Mz = (Test_force_plate_data_scaled[:,5] * (maxForcePlateMz - minForcePlateMz)) + minForcePlateMz\n",
    "Test_y_real = np.concatenate((Test_y_real_Fx.reshape(-1,1), Test_y_real_Fy.reshape(-1,1), Test_y_real_Fz.reshape(-1,1),\n",
    "                              Test_y_real_Mx.reshape(-1,1), Test_y_real_My.reshape(-1,1), Test_y_real_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "Test_y_pred_Fx = (Test_Pred[:,0] * (maxForcePlateFx - minForcePlateFx)) + minForcePlateFx\n",
    "Test_y_pred_Fy = (Test_Pred[:,1] * (maxForcePlateFy - minForcePlateFy)) + minForcePlateFy\n",
    "Test_y_pred_Fz = (Test_Pred[:,2] * (maxForcePlateFz - minForcePlateFz)) + minForcePlateFz\n",
    "Test_y_pred_Mx = (Test_Pred[:,3] * (maxForcePlateMx - minForcePlateMx)) + minForcePlateMx\n",
    "Test_y_pred_My = (Test_Pred[:,4] * (maxForcePlateMy - minForcePlateMy)) + minForcePlateMy\n",
    "Test_y_pred_Mz = (Test_Pred[:,5] * (maxForcePlateMz - minForcePlateMz)) + minForcePlateMz\n",
    "Test_y_pred = np.concatenate((Test_y_pred_Fx.reshape(-1,1), Test_y_pred_Fy.reshape(-1,1), Test_y_pred_Fz.reshape(-1,1),\n",
    "                              Test_y_pred_Mx.reshape(-1,1), Test_y_pred_My.reshape(-1,1), Test_y_pred_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "x=[]\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_y_real[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_y_pred[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('ResNet Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# please help me make normalization process manualy dont use the sickit-learn on this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model to Predict Real Data\n",
    "SIDWTcoeffs = []\n",
    "for i in range(89):\n",
    "    coeffs = pywt.wavedec(SIDatasetTest[:, i], wavelet)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "#     coeffs[-2] = np.zeros_like(coeffs[-2])\n",
    "#     coeffs[-3] = np.zeros_like(coeffs[-3])\n",
    "#     coeffs[-4] = np.zeros_like(coeffs[-4])\n",
    "#     coeffs[-5] = np.zeros_like(coeffs[-5])\n",
    "#     coeffs[-6] = np.zeros_like(coeffs[-6])\n",
    "    SIDWTcoeffs.append(coeffs)\n",
    "\n",
    "Test_SIData_filtered = np.zeros(SIDatasetTest.shape)\n",
    "for i in range(89):\n",
    "    Test_SIData_filtered[:, i] = pywt.waverec(SIDWTcoeffs[i], wavelet, mode='symmetric', axis=0)\n",
    "\n",
    "for i in range(len(Test_SIData_filtered)):\n",
    "    Test_SIData_filtered[i][0] = Test_SIData_filtered[i][0] + (iter % max_iter) + 1\n",
    "    iter += 1\n",
    "\n",
    "Test_smart_insole_data_scaled = (Test_SIData_filtered - minInsole) / ( maxInsole - minInsole )\n",
    "Test_force_plate_data_scaled_Fx = (FPDatasetTest[:,0] - minForcePlateFx) / ( maxForcePlateFx - minForcePlateFx )\n",
    "Test_force_plate_data_scaled_Fy = (FPDatasetTest[:,1] - minForcePlateFy) / ( maxForcePlateFy - minForcePlateFy )\n",
    "Test_force_plate_data_scaled_Fz = (FPDatasetTest[:,2] - minForcePlateFz) / ( maxForcePlateFz - minForcePlateFz )\n",
    "Test_force_plate_data_scaled_Mx = (FPDatasetTest[:,3] - minForcePlateMx) / ( maxForcePlateMx - minForcePlateMx )\n",
    "Test_force_plate_data_scaled_My = (FPDatasetTest[:,4] - minForcePlateMy) / ( maxForcePlateMy - minForcePlateMy )\n",
    "Test_force_plate_data_scaled_Mz = (FPDatasetTest[:,5] - minForcePlateMz) / ( maxForcePlateMz - minForcePlateMz )\n",
    "Test_force_plate_data_scaled = np.concatenate((Test_force_plate_data_scaled_Fx.reshape(-1,1), Test_force_plate_data_scaled_Fy.reshape(-1,1), \n",
    "                                               Test_force_plate_data_scaled_Fz.reshape(-1,1), Test_force_plate_data_scaled_Mx.reshape(-1,1), \n",
    "                                               Test_force_plate_data_scaled_My.reshape(-1,1), Test_force_plate_data_scaled_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "Test_sample_size = Test_smart_insole_data_scaled.shape[0]\n",
    "Test_time_steps  = Test_smart_insole_data_scaled.shape[1]\n",
    "Test_input_dimension = 1\n",
    "\n",
    "Test_train_data_reshaped = Test_smart_insole_data_scaled.reshape(Test_sample_size,Test_time_steps,Test_input_dimension)\n",
    "\n",
    "modelCoy.evaluate(Test_train_data_reshaped, Test_force_plate_data_scaled)\n",
    "Test_Pred = modelCoy.predict(Test_train_data_reshaped)\n",
    "\n",
    "Test_y_real_Fx = (Test_force_plate_data_scaled[:,0] * (maxForcePlateFx - minForcePlateFx)) + minForcePlateFx\n",
    "Test_y_real_Fy = (Test_force_plate_data_scaled[:,1] * (maxForcePlateFy - minForcePlateFy)) + minForcePlateFy\n",
    "Test_y_real_Fz = (Test_force_plate_data_scaled[:,2] * (maxForcePlateFz - minForcePlateFz)) + minForcePlateFz\n",
    "Test_y_real_Mx = (Test_force_plate_data_scaled[:,3] * (maxForcePlateMx - minForcePlateMx)) + minForcePlateMx\n",
    "Test_y_real_My = (Test_force_plate_data_scaled[:,4] * (maxForcePlateMy - minForcePlateMy)) + minForcePlateMy\n",
    "Test_y_real_Mz = (Test_force_plate_data_scaled[:,5] * (maxForcePlateMz - minForcePlateMz)) + minForcePlateMz\n",
    "Test_y_real = np.concatenate((Test_y_real_Fx.reshape(-1,1), Test_y_real_Fy.reshape(-1,1), Test_y_real_Fz.reshape(-1,1),\n",
    "                              Test_y_real_Mx.reshape(-1,1), Test_y_real_My.reshape(-1,1), Test_y_real_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "Test_y_pred_Fx = (Test_Pred[:,0] * (maxForcePlateFx - minForcePlateFx)) + minForcePlateFx\n",
    "Test_y_pred_Fy = (Test_Pred[:,1] * (maxForcePlateFy - minForcePlateFy)) + minForcePlateFy\n",
    "Test_y_pred_Fz = (Test_Pred[:,2] * (maxForcePlateFz - minForcePlateFz)) + minForcePlateFz\n",
    "Test_y_pred_Mx = (Test_Pred[:,3] * (maxForcePlateMx - minForcePlateMx)) + minForcePlateMx\n",
    "Test_y_pred_My = (Test_Pred[:,4] * (maxForcePlateMy - minForcePlateMy)) + minForcePlateMy\n",
    "Test_y_pred_Mz = (Test_Pred[:,5] * (maxForcePlateMz - minForcePlateMz)) + minForcePlateMz\n",
    "Test_y_pred = np.concatenate((Test_y_pred_Fx.reshape(-1,1), Test_y_pred_Fy.reshape(-1,1), Test_y_pred_Fz.reshape(-1,1),\n",
    "                              Test_y_pred_Mx.reshape(-1,1), Test_y_pred_My.reshape(-1,1), Test_y_pred_Mz.reshape(-1,1)), axis=1)\n",
    "\n",
    "x=[]\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_y_real[0:3000,i],color='red')\n",
    "    plt.plot(x,Test_y_pred[0:3000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('ResNet Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# please help me make normalization process manualy dont use the sickit-learn on this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=[]\n",
    "x = np.arange(0,3000)*60/3000 \n",
    "for i in range(0,6):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    # plt.figure()\n",
    "    plt.plot(x,Test_y_real[100000:103000,i],color='red')\n",
    "    plt.plot(x,Test_y_pred[100000:103000,i], markerfacecolor='none',color='green')\n",
    "    plt.title('ResNet Regression (Testing Data)')\n",
    "    if i < 3:\n",
    "      plt.ylabel('Force/'+columns[i])\n",
    "    else:\n",
    "      plt.ylabel('Moment/'+columns[i])\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.legend(['Groundtruth', 'Predicted'], loc='best')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
